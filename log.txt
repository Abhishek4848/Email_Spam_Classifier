21/11/26 20:00:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/26 20:00:02 INFO SparkContext: Running Spark version 3.1.2
21/11/26 20:00:02 INFO ResourceUtils: ==============================================================
21/11/26 20:00:02 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/26 20:00:02 INFO ResourceUtils: ==============================================================
21/11/26 20:00:02 INFO SparkContext: Submitted application: test
21/11/26 20:00:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/26 20:00:02 INFO ResourceProfile: Limiting resource is cpu
21/11/26 20:00:02 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/26 20:00:02 INFO SecurityManager: Changing view acls to: pes2ug19cs012
21/11/26 20:00:02 INFO SecurityManager: Changing modify acls to: pes2ug19cs012
21/11/26 20:00:02 INFO SecurityManager: Changing view acls groups to: 
21/11/26 20:00:02 INFO SecurityManager: Changing modify acls groups to: 
21/11/26 20:00:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pes2ug19cs012); groups with view permissions: Set(); users  with modify permissions: Set(pes2ug19cs012); groups with modify permissions: Set()
21/11/26 20:00:03 INFO Utils: Successfully started service 'sparkDriver' on port 43989.
21/11/26 20:00:03 INFO SparkEnv: Registering MapOutputTracker
21/11/26 20:00:03 INFO SparkEnv: Registering BlockManagerMaster
21/11/26 20:00:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/26 20:00:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/26 20:00:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/26 20:00:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0646958d-a1bd-46a7-8d86-77862291c274
21/11/26 20:00:03 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/11/26 20:00:03 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/26 20:00:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/26 20:00:03 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://pes2ug19cs012:4040
21/11/26 20:00:04 INFO Executor: Starting executor ID driver on host pes2ug19cs012
21/11/26 20:00:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38829.
21/11/26 20:00:04 INFO NettyBlockTransferService: Server created on pes2ug19cs012:38829
21/11/26 20:00:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/26 20:00:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, pes2ug19cs012, 38829, None)
21/11/26 20:00:04 INFO BlockManagerMasterEndpoint: Registering block manager pes2ug19cs012:38829 with 366.3 MiB RAM, BlockManagerId(driver, pes2ug19cs012, 38829, None)
21/11/26 20:00:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, pes2ug19cs012, 38829, None)
21/11/26 20:00:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, pes2ug19cs012, 38829, None)
21/11/26 20:00:05 INFO ReceiverTracker: Starting 1 receivers
21/11/26 20:00:05 INFO ReceiverTracker: ReceiverTracker started
21/11/26 20:00:05 INFO SocketInputDStream: Slide time = 1000 ms
21/11/26 20:00:05 INFO SocketInputDStream: Storage level = Serialized 1x Replicated
21/11/26 20:00:05 INFO SocketInputDStream: Checkpoint interval = null
21/11/26 20:00:05 INFO SocketInputDStream: Remember interval = 1000 ms
21/11/26 20:00:05 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@7fc3de80
21/11/26 20:00:05 INFO PythonTransformedDStream: Slide time = 1000 ms
21/11/26 20:00:05 INFO PythonTransformedDStream: Storage level = Serialized 1x Replicated
21/11/26 20:00:05 INFO PythonTransformedDStream: Checkpoint interval = null
21/11/26 20:00:05 INFO PythonTransformedDStream: Remember interval = 1000 ms
21/11/26 20:00:05 INFO PythonTransformedDStream: Initialized and validated org.apache.spark.streaming.api.python.PythonTransformedDStream@63a4833d
21/11/26 20:00:05 INFO ForEachDStream: Slide time = 1000 ms
21/11/26 20:00:05 INFO ForEachDStream: Storage level = Serialized 1x Replicated
21/11/26 20:00:05 INFO ForEachDStream: Checkpoint interval = null
21/11/26 20:00:05 INFO ForEachDStream: Remember interval = 1000 ms
21/11/26 20:00:05 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@3971a300
21/11/26 20:00:05 INFO RecurringTimer: Started timer for JobGenerator at time 1637937006000
21/11/26 20:00:05 INFO JobGenerator: Started JobGenerator at 1637937006000 ms
21/11/26 20:00:05 INFO JobScheduler: Started JobScheduler
21/11/26 20:00:05 INFO StreamingContext: StreamingContext started
21/11/26 20:00:06 INFO ReceiverTracker: Receiver 0 started
21/11/26 20:00:06 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/11/26 20:00:06 INFO DAGScheduler: Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)
21/11/26 20:00:06 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:06 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:06 INFO DAGScheduler: Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
21/11/26 20:00:06 INFO JobScheduler: Added jobs for time 1637937006000 ms
21/11/26 20:00:06 INFO JobScheduler: Starting job streaming job 1637937006000 ms.0 from job set of time 1637937006000 ms
21/11/26 20:00:06 INFO JobScheduler: Finished job streaming job 1637937006000 ms.0 from job set of time 1637937006000 ms
21/11/26 20:00:06 INFO JobScheduler: Total delay: 0.295 s for time 1637937006000 ms (execution: 0.030 s)
21/11/26 20:00:06 INFO ReceivedBlockTracker: Deleting batches: 
21/11/26 20:00:06 INFO InputInfoTracker: remove old batch metadata: 
21/11/26 20:00:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 81.3 KiB, free 366.2 MiB)
21/11/26 20:00:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 366.2 MiB)
21/11/26 20:00:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on pes2ug19cs012:38829 (size: 28.5 KiB, free: 366.3 MiB)
21/11/26 20:00:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
21/11/26 20:00:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 5478 bytes) taskResourceAssignments Map()
21/11/26 20:00:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/11/26 20:00:06 INFO RecurringTimer: Started timer for BlockGenerator at time 1637937007000
21/11/26 20:00:06 INFO BlockGenerator: Started BlockGenerator
21/11/26 20:00:06 INFO BlockGenerator: Started block pushing thread
21/11/26 20:00:06 INFO ReceiverTracker: Registered receiver for stream 0 from pes2ug19cs012:43989
21/11/26 20:00:06 INFO ReceiverSupervisorImpl: Starting receiver 0
21/11/26 20:00:06 INFO SocketReceiver: Connecting to localhost:6100
21/11/26 20:00:06 INFO SocketReceiver: Connected to localhost:6100
21/11/26 20:00:06 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/11/26 20:00:06 INFO ReceiverSupervisorImpl: Waiting for receiver to be stopped
21/11/26 20:00:07 INFO JobScheduler: Added jobs for time 1637937007000 ms
21/11/26 20:00:07 INFO JobScheduler: Starting job streaming job 1637937007000 ms.0 from job set of time 1637937007000 ms
21/11/26 20:00:07 INFO JobScheduler: Finished job streaming job 1637937007000 ms.0 from job set of time 1637937007000 ms
21/11/26 20:00:07 INFO JobScheduler: Total delay: 0.091 s for time 1637937007000 ms (execution: 0.028 s)
21/11/26 20:00:07 INFO PythonRDD: Removing RDD 2 from persistence list
21/11/26 20:00:07 INFO BlockRDD: Removing RDD 1 from persistence list
21/11/26 20:00:07 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[1] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937007000 ms
21/11/26 20:00:07 INFO ReceivedBlockTracker: Deleting batches: 
21/11/26 20:00:07 INFO InputInfoTracker: remove old batch metadata: 
21/11/26 20:00:07 INFO BlockManager: Removing RDD 2
21/11/26 20:00:07 INFO BlockManager: Removing RDD 1
21/11/26 20:00:08 INFO MemoryStore: Block input-0-1637937007600 stored as values in memory (estimated size 361.8 KiB, free 365.8 MiB)
21/11/26 20:00:08 INFO BlockManagerInfo: Added input-0-1637937007600 in memory on pes2ug19cs012:38829 (size: 361.8 KiB, free: 365.9 MiB)
21/11/26 20:00:08 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:08 WARN BlockManager: Block input-0-1637937007600 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:08 INFO BlockGenerator: Pushed block input-0-1637937007600
21/11/26 20:00:08 INFO JobScheduler: Added jobs for time 1637937008000 ms
21/11/26 20:00:08 INFO JobScheduler: Starting job streaming job 1637937008000 ms.0 from job set of time 1637937008000 ms
21/11/26 20:00:08 INFO JobScheduler: Finished job streaming job 1637937008000 ms.0 from job set of time 1637937008000 ms
21/11/26 20:00:08 INFO PythonRDD: Removing RDD 4 from persistence list
21/11/26 20:00:08 INFO JobScheduler: Total delay: 0.092 s for time 1637937008000 ms (execution: 0.041 s)
21/11/26 20:00:08 INFO BlockRDD: Removing RDD 3 from persistence list
21/11/26 20:00:08 INFO BlockManager: Removing RDD 4
21/11/26 20:00:08 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[3] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937008000 ms
21/11/26 20:00:08 INFO ReceivedBlockTracker: Deleting batches: 1637937006000 ms
21/11/26 20:00:08 INFO InputInfoTracker: remove old batch metadata: 1637937006000 ms
21/11/26 20:00:08 INFO BlockManager: Removing RDD 3
21/11/26 20:00:09 INFO JobScheduler: Added jobs for time 1637937009000 ms
21/11/26 20:00:09 INFO JobScheduler: Starting job streaming job 1637937009000 ms.0 from job set of time 1637937009000 ms
21/11/26 20:00:09 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:00:09 INFO DAGScheduler: Got job 1 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:00:09 INFO DAGScheduler: Final stage: ResultStage 1 (runJob at PythonRDD.scala:166)
21/11/26 20:00:09 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:09 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:09 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[9] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:00:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.9 KiB, free 365.8 MiB)
21/11/26 20:00:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 365.8 MiB)
21/11/26 20:00:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 365.9 MiB)
21/11/26 20:00:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
21/11/26 20:00:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:00:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/11/26 20:00:09 INFO BlockManager: Found block input-0-1637937007600 locally
21/11/26 20:00:10 INFO JobScheduler: Added jobs for time 1637937010000 ms
21/11/26 20:00:10 INFO PythonRunner: Times: total = 818, boot = 773, init = 39, finish = 6
21/11/26 20:00:10 INFO PythonRunner: Times: total = 96, boot = 30, init = 63, finish = 3
21/11/26 20:00:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 373653 bytes result sent to driver
21/11/26 20:00:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1025 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/11/26 20:00:10 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 48113
21/11/26 20:00:10 INFO DAGScheduler: ResultStage 1 (runJob at PythonRDD.scala:166) finished in 1.104 s
21/11/26 20:00:10 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/11/26 20:00:10 INFO DAGScheduler: Job 1 finished: runJob at PythonRDD.scala:166, took 1.161125 s
21/11/26 20:00:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:10 INFO DAGScheduler: Got job 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:00:10 INFO DAGScheduler: Final stage: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:10 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:10 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:10 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[8] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:00:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.6 KiB, free 365.8 MiB)
21/11/26 20:00:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 365.8 MiB)
21/11/26 20:00:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 365.9 MiB)
21/11/26 20:00:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (PythonRDD[8] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
21/11/26 20:00:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:00:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/11/26 20:00:10 INFO BlockManager: Found block input-0-1637937007600 locally
21/11/26 20:00:10 INFO PythonRunner: Times: total = 21, boot = -466, init = 483, finish = 4
21/11/26 20:00:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 373653 bytes result sent to driver
21/11/26 20:00:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 182 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:10 INFO DAGScheduler: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.207 s
21/11/26 20:00:10 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/11/26 20:00:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/11/26 20:00:10 INFO DAGScheduler: Job 2 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.221877 s
21/11/26 20:00:11 INFO JobScheduler: Added jobs for time 1637937011000 ms
21/11/26 20:00:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 365.9 MiB)
21/11/26 20:00:11 INFO BlockManagerInfo: Removed broadcast_2_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 365.9 MiB)
21/11/26 20:00:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/pes2ug19cs012/Documents/Machine-Learning-with-Spark-Streaming/spark-warehouse').
21/11/26 20:00:11 INFO SharedState: Warehouse path is 'file:/home/pes2ug19cs012/Documents/Machine-Learning-with-Spark-Streaming/spark-warehouse'.
21/11/26 20:00:12 INFO JobScheduler: Added jobs for time 1637937012000 ms
21/11/26 20:00:12 INFO MemoryStore: Block input-0-1637937012600 stored as values in memory (estimated size 137.8 KiB, free 365.7 MiB)
21/11/26 20:00:12 INFO BlockManagerInfo: Added input-0-1637937012600 in memory on pes2ug19cs012:38829 (size: 137.8 KiB, free: 365.8 MiB)
21/11/26 20:00:12 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:12 WARN BlockManager: Block input-0-1637937012600 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:12 INFO BlockGenerator: Pushed block input-0-1637937012600
21/11/26 20:00:13 INFO JobScheduler: Added jobs for time 1637937013000 ms
21/11/26 20:00:14 INFO JobScheduler: Added jobs for time 1637937014000 ms
21/11/26 20:00:15 INFO JobScheduler: Added jobs for time 1637937015000 ms
21/11/26 20:00:16 INFO JobScheduler: Added jobs for time 1637937016000 ms
21/11/26 20:00:17 INFO JobScheduler: Added jobs for time 1637937017000 ms
21/11/26 20:00:17 INFO CodeGenerator: Code generated in 355.796164 ms
21/11/26 20:00:17 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:00:17 INFO MemoryStore: Block input-0-1637937017600 stored as values in memory (estimated size 156.9 KiB, free 365.6 MiB)
21/11/26 20:00:17 INFO BlockManagerInfo: Added input-0-1637937017600 in memory on pes2ug19cs012:38829 (size: 156.9 KiB, free: 365.6 MiB)
21/11/26 20:00:17 INFO DAGScheduler: Registering RDD 33 (collect at StringIndexer.scala:204) as input to shuffle 0
21/11/26 20:00:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:17 WARN BlockManager: Block input-0-1637937017600 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:17 INFO BlockGenerator: Pushed block input-0-1637937017600
21/11/26 20:00:17 INFO DAGScheduler: Got job 3 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:00:17 INFO DAGScheduler: Final stage: ResultStage 4 (collect at StringIndexer.scala:204)
21/11/26 20:00:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
21/11/26 20:00:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
21/11/26 20:00:17 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:00:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 20.3 KiB, free 365.5 MiB)
21/11/26 20:00:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 365.5 MiB)
21/11/26 20:00:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 365.6 MiB)
21/11/26 20:00:17 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks resource profile 0
21/11/26 20:00:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 289013 bytes) taskResourceAssignments Map()
21/11/26 20:00:17 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/11/26 20:00:18 INFO JobScheduler: Added jobs for time 1637937018000 ms
21/11/26 20:00:18 INFO CodeGenerator: Code generated in 36.816613 ms
21/11/26 20:00:18 INFO CodeGenerator: Code generated in 16.509779 ms
21/11/26 20:00:18 INFO CodeGenerator: Code generated in 29.676904 ms
21/11/26 20:00:18 INFO CodeGenerator: Code generated in 23.578235 ms
21/11/26 20:00:18 INFO PythonRunner: Times: total = 53, boot = -7491, init = 7501, finish = 43
21/11/26 20:00:18 INFO CodeGenerator: Code generated in 35.411551 ms
21/11/26 20:00:18 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2314 bytes result sent to driver
21/11/26 20:00:18 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 82780 bytes) taskResourceAssignments Map()
21/11/26 20:00:18 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
21/11/26 20:00:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 958 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:18 INFO PythonRunner: Times: total = 17, boot = -710, init = 726, finish = 1
21/11/26 20:00:18 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 2271 bytes result sent to driver
21/11/26 20:00:18 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 88 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:18 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/11/26 20:00:18 INFO DAGScheduler: ShuffleMapStage 3 (collect at StringIndexer.scala:204) finished in 1.088 s
21/11/26 20:00:18 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:00:18 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:00:18 INFO DAGScheduler: waiting: Set(ResultStage 4)
21/11/26 20:00:18 INFO DAGScheduler: failed: Set()
21/11/26 20:00:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[36] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:00:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 20.8 KiB, free 365.5 MiB)
21/11/26 20:00:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 365.5 MiB)
21/11/26 20:00:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 365.6 MiB)
21/11/26 20:00:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[36] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:18 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
21/11/26 20:00:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:00:18 INFO Executor: Running task 0.0 in stage 4.0 (TID 5)
21/11/26 20:00:19 INFO BlockManagerInfo: Removed broadcast_3_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 365.6 MiB)
21/11/26 20:00:19 INFO JobScheduler: Added jobs for time 1637937019000 ms
21/11/26 20:00:19 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:00:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
21/11/26 20:00:19 INFO CodeGenerator: Code generated in 62.0708 ms
21/11/26 20:00:19 INFO Executor: Finished task 0.0 in stage 4.0 (TID 5). 3703 bytes result sent to driver
21/11/26 20:00:19 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 358 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:19 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/11/26 20:00:19 INFO DAGScheduler: ResultStage 4 (collect at StringIndexer.scala:204) finished in 0.376 s
21/11/26 20:00:19 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
21/11/26 20:00:19 INFO DAGScheduler: Job 3 finished: collect at StringIndexer.scala:204, took 1.570741 s
21/11/26 20:00:20 INFO JobScheduler: Added jobs for time 1637937020000 ms
21/11/26 20:00:21 INFO JobScheduler: Added jobs for time 1637937021000 ms
21/11/26 20:00:21 INFO CodeGenerator: Code generated in 144.636556 ms
21/11/26 20:00:21 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:21 INFO DAGScheduler: Got job 4 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:21 INFO DAGScheduler: Final stage: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:21 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:21 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:21 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[46] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 63.0 KiB, free 365.5 MiB)
21/11/26 20:00:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 365.4 MiB)
21/11/26 20:00:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 365.6 MiB)
21/11/26 20:00:21 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[46] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks resource profile 0
21/11/26 20:00:21 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 289024 bytes) taskResourceAssignments Map()
21/11/26 20:00:21 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
21/11/26 20:00:21 INFO CodeGenerator: Code generated in 62.808847 ms
21/11/26 20:00:21 INFO CodeGenerator: Code generated in 20.783921 ms
21/11/26 20:00:21 INFO CodeGenerator: Code generated in 11.859918 ms
21/11/26 20:00:21 INFO CodeGenerator: Code generated in 40.493413 ms
21/11/26 20:00:21 INFO CodeGenerator: Code generated in 21.06316 ms
21/11/26 20:00:21 INFO CodeGenerator: Code generated in 26.608361 ms
21/11/26 20:00:22 INFO JobScheduler: Added jobs for time 1637937022000 ms
21/11/26 20:00:22 INFO BlockManagerInfo: Removed broadcast_4_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 365.6 MiB)
21/11/26 20:00:22 INFO PythonRunner: Times: total = 4, boot = -2535, init = 2538, finish = 1
21/11/26 20:00:22 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 86735 bytes result sent to driver
21/11/26 20:00:22 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 82791 bytes) taskResourceAssignments Map()
21/11/26 20:00:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 1302 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:22 INFO Executor: Running task 1.0 in stage 5.0 (TID 7)
21/11/26 20:00:22 INFO MemoryStore: Block input-0-1637937022600 stored as values in memory (estimated size 201.7 KiB, free 357.2 MiB)
21/11/26 20:00:22 INFO BlockManagerInfo: Added input-0-1637937022600 in memory on pes2ug19cs012:38829 (size: 201.7 KiB, free: 365.4 MiB)
21/11/26 20:00:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:22 WARN BlockManager: Block input-0-1637937022600 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:22 INFO BlockGenerator: Pushed block input-0-1637937022600
21/11/26 20:00:22 INFO PythonRunner: Times: total = 10, boot = -1214, init = 1223, finish = 1
21/11/26 20:00:22 INFO Executor: Finished task 1.0 in stage 5.0 (TID 7). 19392 bytes result sent to driver
21/11/26 20:00:22 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 348 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/11/26 20:00:22 INFO DAGScheduler: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 1.678 s
21/11/26 20:00:22 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/11/26 20:00:22 INFO DAGScheduler: Job 4 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 1.692931 s
21/11/26 20:00:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 365.4 MiB)
21/11/26 20:00:23 INFO JobScheduler: Added jobs for time 1637937023000 ms
21/11/26 20:00:24 INFO JobScheduler: Added jobs for time 1637937024000 ms
21/11/26 20:00:25 INFO JobScheduler: Added jobs for time 1637937025000 ms
21/11/26 20:00:26 INFO JobScheduler: Added jobs for time 1637937026000 ms
21/11/26 20:00:27 INFO JobScheduler: Added jobs for time 1637937027000 ms
21/11/26 20:00:27 INFO MemoryStore: Block input-0-1637937027600 stored as values in memory (estimated size 161.6 KiB, free 365.2 MiB)
21/11/26 20:00:27 INFO BlockManagerInfo: Added input-0-1637937027600 in memory on pes2ug19cs012:38829 (size: 161.6 KiB, free: 365.3 MiB)
21/11/26 20:00:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:27 WARN BlockManager: Block input-0-1637937027600 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:27 INFO BlockGenerator: Pushed block input-0-1637937027600
21/11/26 20:00:28 INFO JobScheduler: Added jobs for time 1637937028000 ms
21/11/26 20:00:29 INFO JobScheduler: Added jobs for time 1637937029000 ms
21/11/26 20:00:30 INFO JobScheduler: Added jobs for time 1637937030000 ms
21/11/26 20:00:30 INFO CodeGenerator: Code generated in 138.789125 ms
21/11/26 20:00:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:30 INFO DAGScheduler: Got job 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:30 INFO DAGScheduler: Final stage: ResultStage 6 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:30 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:30 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:30 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[66] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 57.2 KiB, free 365.1 MiB)
21/11/26 20:00:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 365.1 MiB)
21/11/26 20:00:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 365.3 MiB)
21/11/26 20:00:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[66] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:30 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
21/11/26 20:00:30 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 289024 bytes) taskResourceAssignments Map()
21/11/26 20:00:30 INFO Executor: Running task 0.0 in stage 6.0 (TID 8)
21/11/26 20:00:31 INFO JobScheduler: Added jobs for time 1637937031000 ms
21/11/26 20:00:31 INFO PythonRunner: Times: total = 66, boot = -7798, init = 7820, finish = 44
21/11/26 20:00:31 INFO Executor: Finished task 0.0 in stage 6.0 (TID 8). 2204 bytes result sent to driver
21/11/26 20:00:31 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 82791 bytes) taskResourceAssignments Map()
21/11/26 20:00:31 INFO Executor: Running task 1.0 in stage 6.0 (TID 9)
21/11/26 20:00:31 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 691 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:31 INFO PythonRunner: Times: total = 5, boot = -573, init = 577, finish = 1
21/11/26 20:00:31 INFO Executor: Finished task 1.0 in stage 6.0 (TID 9). 2162 bytes result sent to driver
21/11/26 20:00:31 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 284 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:31 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/11/26 20:00:31 INFO DAGScheduler: ResultStage 6 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 1.019 s
21/11/26 20:00:31 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/11/26 20:00:31 INFO DAGScheduler: Job 5 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 1.057663 s
21/11/26 20:00:31 INFO CodeGenerator: Code generated in 70.570546 ms
21/11/26 20:00:31 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:31 INFO DAGScheduler: Got job 6 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:31 INFO DAGScheduler: Final stage: ResultStage 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:31 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:31 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:31 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[70] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:31 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 63.0 KiB, free 365.1 MiB)
21/11/26 20:00:31 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 365.0 MiB)
21/11/26 20:00:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 365.2 MiB)
21/11/26 20:00:31 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[70] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:31 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
21/11/26 20:00:31 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 289024 bytes) taskResourceAssignments Map()
21/11/26 20:00:31 INFO Executor: Running task 0.0 in stage 7.0 (TID 10)
21/11/26 20:00:32 INFO JobScheduler: Added jobs for time 1637937032000 ms
21/11/26 20:00:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 365.3 MiB)
21/11/26 20:00:32 INFO PythonRunner: Times: total = 5, boot = -581, init = 585, finish = 1
21/11/26 20:00:32 INFO Executor: Finished task 0.0 in stage 7.0 (TID 10). 12607 bytes result sent to driver
21/11/26 20:00:32 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 82791 bytes) taskResourceAssignments Map()
21/11/26 20:00:32 INFO Executor: Running task 1.0 in stage 7.0 (TID 11)
21/11/26 20:00:32 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 456 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:32 INFO PythonRunner: Times: total = 44, boot = -421, init = 423, finish = 42
21/11/26 20:00:32 INFO Executor: Finished task 1.0 in stage 7.0 (TID 11). 15884 bytes result sent to driver
21/11/26 20:00:32 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 194 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:32 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/11/26 20:00:32 INFO DAGScheduler: ResultStage 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.685 s
21/11/26 20:00:32 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/11/26 20:00:32 INFO DAGScheduler: Job 6 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.694767 s
21/11/26 20:00:32 INFO MemoryStore: Block input-0-1637937032600 stored as values in memory (estimated size 143.5 KiB, free 365.0 MiB)
21/11/26 20:00:32 INFO BlockManagerInfo: Added input-0-1637937032600 in memory on pes2ug19cs012:38829 (size: 143.5 KiB, free: 365.1 MiB)
21/11/26 20:00:32 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:32 WARN BlockManager: Block input-0-1637937032600 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:32 INFO BlockGenerator: Pushed block input-0-1637937032600
21/11/26 20:00:33 INFO JobScheduler: Added jobs for time 1637937033000 ms
21/11/26 20:00:34 INFO JobScheduler: Added jobs for time 1637937034000 ms
21/11/26 20:00:34 INFO CodeGenerator: Code generated in 51.164632 ms
21/11/26 20:00:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:35 INFO DAGScheduler: Got job 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:35 INFO DAGScheduler: Final stage: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:35 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:35 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:35 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[78] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 57.2 KiB, free 364.9 MiB)
21/11/26 20:00:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 364.9 MiB)
21/11/26 20:00:35 INFO JobScheduler: Added jobs for time 1637937035000 ms
21/11/26 20:00:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 365.1 MiB)
21/11/26 20:00:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[78] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:35 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
21/11/26 20:00:35 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 12) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 289024 bytes) taskResourceAssignments Map()
21/11/26 20:00:35 INFO Executor: Running task 0.0 in stage 8.0 (TID 12)
21/11/26 20:00:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 365.1 MiB)
21/11/26 20:00:35 INFO PythonRunner: Times: total = 15, boot = -2857, init = 2871, finish = 1
21/11/26 20:00:35 INFO Executor: Finished task 0.0 in stage 8.0 (TID 12). 2203 bytes result sent to driver
21/11/26 20:00:35 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 13) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 82791 bytes) taskResourceAssignments Map()
21/11/26 20:00:35 INFO Executor: Running task 1.0 in stage 8.0 (TID 13)
21/11/26 20:00:35 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 12) in 372 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:35 INFO PythonRunner: Times: total = 2, boot = -354, init = 356, finish = 0
21/11/26 20:00:35 INFO Executor: Finished task 1.0 in stage 8.0 (TID 13). 2160 bytes result sent to driver
21/11/26 20:00:35 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 13) in 184 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:35 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/11/26 20:00:35 INFO DAGScheduler: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.577 s
21/11/26 20:00:35 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/11/26 20:00:35 INFO DAGScheduler: Job 7 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.592151 s
21/11/26 20:00:35 INFO JobScheduler: Finished job streaming job 1637937009000 ms.0 from job set of time 1637937009000 ms
21/11/26 20:00:35 INFO JobScheduler: Total delay: 26.670 s for time 1637937009000 ms (execution: 26.637 s)
21/11/26 20:00:35 INFO JobScheduler: Starting job streaming job 1637937010000 ms.0 from job set of time 1637937010000 ms
21/11/26 20:00:35 INFO PythonRDD: Removing RDD 6 from persistence list
21/11/26 20:00:35 INFO BlockRDD: Removing RDD 5 from persistence list
21/11/26 20:00:35 INFO BlockManager: Removing RDD 6
21/11/26 20:00:35 INFO BlockManager: Removing RDD 5
21/11/26 20:00:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[5] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937009000 ms
21/11/26 20:00:35 INFO ReceivedBlockTracker: Deleting batches: 1637937007000 ms
21/11/26 20:00:35 INFO InputInfoTracker: remove old batch metadata: 1637937007000 ms
21/11/26 20:00:35 INFO JobScheduler: Finished job streaming job 1637937010000 ms.0 from job set of time 1637937010000 ms
21/11/26 20:00:35 INFO JobScheduler: Total delay: 25.747 s for time 1637937010000 ms (execution: 0.068 s)
21/11/26 20:00:35 INFO JobScheduler: Starting job streaming job 1637937011000 ms.0 from job set of time 1637937011000 ms
21/11/26 20:00:35 INFO PythonRDD: Removing RDD 8 from persistence list
21/11/26 20:00:35 INFO BlockManager: Removing RDD 8
21/11/26 20:00:35 INFO BlockRDD: Removing RDD 7 from persistence list
21/11/26 20:00:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[7] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937010000 ms
21/11/26 20:00:35 INFO ReceivedBlockTracker: Deleting batches: 1637937008000 ms
21/11/26 20:00:35 INFO InputInfoTracker: remove old batch metadata: 1637937008000 ms
21/11/26 20:00:35 INFO BlockManager: Removing RDD 7
21/11/26 20:00:35 INFO BlockManagerInfo: Removed input-0-1637937007600 on pes2ug19cs012:38829 in memory (size: 361.8 KiB, free: 365.5 MiB)
21/11/26 20:00:35 INFO JobScheduler: Finished job streaming job 1637937011000 ms.0 from job set of time 1637937011000 ms
21/11/26 20:00:35 INFO JobScheduler: Total delay: 24.793 s for time 1637937011000 ms (execution: 0.046 s)
21/11/26 20:00:35 INFO PythonRDD: Removing RDD 11 from persistence list
21/11/26 20:00:35 INFO BlockRDD: Removing RDD 10 from persistence list
21/11/26 20:00:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[10] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937011000 ms
21/11/26 20:00:35 INFO ReceivedBlockTracker: Deleting batches: 1637937009000 ms
21/11/26 20:00:35 INFO InputInfoTracker: remove old batch metadata: 1637937009000 ms
21/11/26 20:00:35 INFO JobScheduler: Starting job streaming job 1637937012000 ms.0 from job set of time 1637937012000 ms
21/11/26 20:00:35 INFO BlockManager: Removing RDD 10
21/11/26 20:00:35 INFO BlockManager: Removing RDD 11
21/11/26 20:00:35 INFO JobScheduler: Finished job streaming job 1637937012000 ms.0 from job set of time 1637937012000 ms
21/11/26 20:00:35 INFO JobScheduler: Total delay: 23.825 s for time 1637937012000 ms (execution: 0.029 s)
21/11/26 20:00:35 INFO PythonRDD: Removing RDD 13 from persistence list
21/11/26 20:00:35 INFO JobScheduler: Starting job streaming job 1637937013000 ms.0 from job set of time 1637937013000 ms
21/11/26 20:00:35 INFO BlockRDD: Removing RDD 12 from persistence list
21/11/26 20:00:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[12] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937012000 ms
21/11/26 20:00:35 INFO ReceivedBlockTracker: Deleting batches: 1637937010000 ms
21/11/26 20:00:35 INFO InputInfoTracker: remove old batch metadata: 1637937010000 ms
21/11/26 20:00:35 INFO BlockManager: Removing RDD 13
21/11/26 20:00:35 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:00:35 INFO DAGScheduler: Got job 8 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:00:35 INFO DAGScheduler: Final stage: ResultStage 9 (runJob at PythonRDD.scala:166)
21/11/26 20:00:35 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:35 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:35 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[81] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:00:35 INFO BlockManager: Removing RDD 12
21/11/26 20:00:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 5.9 KiB, free 365.3 MiB)
21/11/26 20:00:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 365.3 MiB)
21/11/26 20:00:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 365.5 MiB)
21/11/26 20:00:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (PythonRDD[81] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:35 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
21/11/26 20:00:35 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 14) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:00:35 INFO Executor: Running task 0.0 in stage 9.0 (TID 14)
21/11/26 20:00:35 INFO BlockManager: Found block input-0-1637937012600 locally
21/11/26 20:00:35 INFO PythonRunner: Times: total = 19, boot = -495, init = 513, finish = 1
21/11/26 20:00:36 INFO PythonRunner: Times: total = 18, boot = 9, init = 6, finish = 3
21/11/26 20:00:36 INFO Executor: Finished task 0.0 in stage 9.0 (TID 14). 143121 bytes result sent to driver
21/11/26 20:00:36 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 14) in 44 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:36 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/11/26 20:00:36 INFO DAGScheduler: ResultStage 9 (runJob at PythonRDD.scala:166) finished in 0.103 s
21/11/26 20:00:36 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/11/26 20:00:36 INFO DAGScheduler: Job 8 finished: runJob at PythonRDD.scala:166, took 0.144902 s
21/11/26 20:00:36 INFO JobScheduler: Added jobs for time 1637937036000 ms
21/11/26 20:00:36 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:36 INFO DAGScheduler: Got job 9 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:00:36 INFO DAGScheduler: Final stage: ResultStage 10 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:36 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:36 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:36 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[17] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:00:36 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 4.6 KiB, free 365.3 MiB)
21/11/26 20:00:36 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 365.3 MiB)
21/11/26 20:00:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 365.5 MiB)
21/11/26 20:00:36 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (PythonRDD[17] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:36 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
21/11/26 20:00:36 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 15) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:00:36 INFO Executor: Running task 0.0 in stage 10.0 (TID 15)
21/11/26 20:00:36 INFO BlockManager: Found block input-0-1637937012600 locally
21/11/26 20:00:36 INFO PythonRunner: Times: total = 18, boot = -86, init = 93, finish = 11
21/11/26 20:00:36 INFO Executor: Finished task 0.0 in stage 10.0 (TID 15). 143078 bytes result sent to driver
21/11/26 20:00:36 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 15) in 41 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:36 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/11/26 20:00:36 INFO DAGScheduler: ResultStage 10 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.066 s
21/11/26 20:00:36 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/11/26 20:00:36 INFO DAGScheduler: Job 9 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.081681 s
21/11/26 20:00:36 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:00:36 INFO DAGScheduler: Registering RDD 91 (collect at StringIndexer.scala:204) as input to shuffle 1
21/11/26 20:00:36 INFO DAGScheduler: Got job 10 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:00:36 INFO DAGScheduler: Final stage: ResultStage 12 (collect at StringIndexer.scala:204)
21/11/26 20:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/11/26 20:00:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/11/26 20:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[91] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:00:36 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 20.3 KiB, free 365.3 MiB)
21/11/26 20:00:36 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 365.3 MiB)
21/11/26 20:00:36 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 365.5 MiB)
21/11/26 20:00:36 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[91] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:36 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks resource profile 0
21/11/26 20:00:36 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 16) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 66228 bytes) taskResourceAssignments Map()
21/11/26 20:00:36 INFO Executor: Running task 0.0 in stage 11.0 (TID 16)
21/11/26 20:00:36 INFO PythonRunner: Times: total = 45, boot = -483, init = 528, finish = 0
21/11/26 20:00:36 INFO Executor: Finished task 0.0 in stage 11.0 (TID 16). 2271 bytes result sent to driver
21/11/26 20:00:36 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 17) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 77588 bytes) taskResourceAssignments Map()
21/11/26 20:00:36 INFO Executor: Running task 1.0 in stage 11.0 (TID 17)
21/11/26 20:00:36 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 16) in 91 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:36 INFO PythonRunner: Times: total = 6, boot = -31, init = 37, finish = 0
21/11/26 20:00:36 INFO Executor: Finished task 1.0 in stage 11.0 (TID 17). 2271 bytes result sent to driver
21/11/26 20:00:36 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 17) in 56 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:36 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/11/26 20:00:36 INFO DAGScheduler: ShuffleMapStage 11 (collect at StringIndexer.scala:204) finished in 0.157 s
21/11/26 20:00:36 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:00:36 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:00:36 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/11/26 20:00:36 INFO DAGScheduler: failed: Set()
21/11/26 20:00:36 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[94] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:00:36 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 20.8 KiB, free 365.3 MiB)
21/11/26 20:00:36 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 365.3 MiB)
21/11/26 20:00:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 365.4 MiB)
21/11/26 20:00:36 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[94] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:36 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
21/11/26 20:00:36 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 18) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:00:36 INFO Executor: Running task 0.0 in stage 12.0 (TID 18)
21/11/26 20:00:36 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/11/26 20:00:36 INFO Executor: Finished task 0.0 in stage 12.0 (TID 18). 3617 bytes result sent to driver
21/11/26 20:00:36 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 18) in 61 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:36 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/11/26 20:00:36 INFO DAGScheduler: ResultStage 12 (collect at StringIndexer.scala:204) finished in 0.081 s
21/11/26 20:00:36 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
21/11/26 20:00:36 INFO DAGScheduler: Job 10 finished: collect at StringIndexer.scala:204, took 0.249559 s
21/11/26 20:00:37 INFO JobScheduler: Added jobs for time 1637937037000 ms
21/11/26 20:00:37 INFO CodeGenerator: Code generated in 65.393003 ms
21/11/26 20:00:37 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:37 INFO DAGScheduler: Got job 11 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:37 INFO DAGScheduler: Final stage: ResultStage 13 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:37 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:37 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:37 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[98] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:37 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 63.0 KiB, free 365.2 MiB)
21/11/26 20:00:37 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 365.2 MiB)
21/11/26 20:00:37 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 365.4 MiB)
21/11/26 20:00:37 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[98] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:37 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks resource profile 0
21/11/26 20:00:37 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 66239 bytes) taskResourceAssignments Map()
21/11/26 20:00:37 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
21/11/26 20:00:37 INFO BlockManagerInfo: Removed broadcast_12_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 365.4 MiB)
21/11/26 20:00:37 INFO PythonRunner: Times: total = 17, boot = -856, init = 872, finish = 1
21/11/26 20:00:37 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 19033 bytes result sent to driver
21/11/26 20:00:37 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 20) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 77599 bytes) taskResourceAssignments Map()
21/11/26 20:00:37 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 258 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:37 INFO Executor: Running task 1.0 in stage 13.0 (TID 20)
21/11/26 20:00:37 INFO BlockManagerInfo: Removed broadcast_10_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 365.4 MiB)
21/11/26 20:00:37 INFO BlockManagerInfo: Removed broadcast_8_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 365.5 MiB)
21/11/26 20:00:38 INFO MemoryStore: Block input-0-1637937037800 stored as values in memory (estimated size 196.4 KiB, free 357.0 MiB)
21/11/26 20:00:38 INFO BlockManagerInfo: Added input-0-1637937037800 in memory on pes2ug19cs012:38829 (size: 196.4 KiB, free: 365.3 MiB)
21/11/26 20:00:38 INFO BlockManagerInfo: Removed broadcast_11_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 365.3 MiB)
21/11/26 20:00:38 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:38 WARN BlockManager: Block input-0-1637937037800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:38 INFO BlockGenerator: Pushed block input-0-1637937037800
21/11/26 20:00:38 INFO JobScheduler: Added jobs for time 1637937038000 ms
21/11/26 20:00:38 INFO BlockManagerInfo: Removed broadcast_9_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 365.3 MiB)
21/11/26 20:00:38 INFO PythonRunner: Times: total = 21, boot = -218, init = 239, finish = 0
21/11/26 20:00:38 INFO Executor: Finished task 1.0 in stage 13.0 (TID 20). 21078 bytes result sent to driver
21/11/26 20:00:38 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 20) in 364 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:38 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/11/26 20:00:38 INFO DAGScheduler: ResultStage 13 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.656 s
21/11/26 20:00:38 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/11/26 20:00:38 INFO DAGScheduler: Job 11 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.666942 s
21/11/26 20:00:39 INFO JobScheduler: Added jobs for time 1637937039000 ms
21/11/26 20:00:40 INFO JobScheduler: Added jobs for time 1637937040000 ms
21/11/26 20:00:41 INFO JobScheduler: Added jobs for time 1637937041000 ms
21/11/26 20:00:42 INFO JobScheduler: Added jobs for time 1637937042000 ms
21/11/26 20:00:42 INFO MemoryStore: Block input-0-1637937042600 stored as values in memory (estimated size 173.1 KiB, free 365.0 MiB)
21/11/26 20:00:42 INFO BlockManagerInfo: Added input-0-1637937042600 in memory on pes2ug19cs012:38829 (size: 173.1 KiB, free: 365.1 MiB)
21/11/26 20:00:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:42 WARN BlockManager: Block input-0-1637937042600 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:42 INFO BlockGenerator: Pushed block input-0-1637937042600
21/11/26 20:00:43 INFO JobScheduler: Added jobs for time 1637937043000 ms
21/11/26 20:00:44 INFO JobScheduler: Added jobs for time 1637937044000 ms
21/11/26 20:00:45 INFO JobScheduler: Added jobs for time 1637937045000 ms
21/11/26 20:00:45 INFO CodeGenerator: Code generated in 69.996321 ms
21/11/26 20:00:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:45 INFO DAGScheduler: Got job 12 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:45 INFO DAGScheduler: Final stage: ResultStage 14 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:45 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:45 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:45 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[116] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:45 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 57.2 KiB, free 364.9 MiB)
21/11/26 20:00:45 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 364.9 MiB)
21/11/26 20:00:45 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 365.1 MiB)
21/11/26 20:00:45 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[116] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:45 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks resource profile 0
21/11/26 20:00:45 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 21) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 66239 bytes) taskResourceAssignments Map()
21/11/26 20:00:45 INFO Executor: Running task 0.0 in stage 14.0 (TID 21)
21/11/26 20:00:45 INFO PythonRunner: Times: total = 55, boot = -7732, init = 7786, finish = 1
21/11/26 20:00:45 INFO Executor: Finished task 0.0 in stage 14.0 (TID 21). 2162 bytes result sent to driver
21/11/26 20:00:45 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 22) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 77599 bytes) taskResourceAssignments Map()
21/11/26 20:00:45 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 21) in 223 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:45 INFO Executor: Running task 1.0 in stage 14.0 (TID 22)
21/11/26 20:00:46 INFO JobScheduler: Added jobs for time 1637937046000 ms
21/11/26 20:00:46 INFO PythonRunner: Times: total = 3, boot = -150, init = 152, finish = 1
21/11/26 20:00:46 INFO Executor: Finished task 1.0 in stage 14.0 (TID 22). 2162 bytes result sent to driver
21/11/26 20:00:46 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 22) in 245 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:46 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/11/26 20:00:46 INFO DAGScheduler: ResultStage 14 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.490 s
21/11/26 20:00:46 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/11/26 20:00:46 INFO DAGScheduler: Job 12 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.498765 s
21/11/26 20:00:46 INFO CodeGenerator: Code generated in 74.901091 ms
21/11/26 20:00:46 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:46 INFO BlockManagerInfo: Removed broadcast_14_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 365.1 MiB)
21/11/26 20:00:46 INFO DAGScheduler: Got job 13 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:46 INFO DAGScheduler: Final stage: ResultStage 15 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:46 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:46 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:46 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[120] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:46 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 63.0 KiB, free 364.9 MiB)
21/11/26 20:00:46 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.9 MiB)
21/11/26 20:00:46 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 365.1 MiB)
21/11/26 20:00:46 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[120] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:46 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks resource profile 0
21/11/26 20:00:46 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 23) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 66239 bytes) taskResourceAssignments Map()
21/11/26 20:00:46 INFO Executor: Running task 0.0 in stage 15.0 (TID 23)
21/11/26 20:00:46 INFO BlockManagerInfo: Removed broadcast_13_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 365.1 MiB)
21/11/26 20:00:46 INFO PythonRunner: Times: total = 14, boot = -528, init = 542, finish = 0
21/11/26 20:00:46 INFO Executor: Finished task 0.0 in stage 15.0 (TID 23). 8223 bytes result sent to driver
21/11/26 20:00:46 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 24) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 77599 bytes) taskResourceAssignments Map()
21/11/26 20:00:46 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 23) in 299 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:46 INFO Executor: Running task 1.0 in stage 15.0 (TID 24)
21/11/26 20:00:46 INFO PythonRunner: Times: total = 7, boot = -246, init = 252, finish = 1
21/11/26 20:00:46 INFO Executor: Finished task 1.0 in stage 15.0 (TID 24). 8605 bytes result sent to driver
21/11/26 20:00:46 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 24) in 221 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:46 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/11/26 20:00:46 INFO DAGScheduler: ResultStage 15 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.556 s
21/11/26 20:00:46 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/11/26 20:00:46 INFO DAGScheduler: Job 13 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.566744 s
21/11/26 20:00:47 INFO JobScheduler: Added jobs for time 1637937047000 ms
21/11/26 20:00:48 INFO MemoryStore: Block input-0-1637937047800 stored as values in memory (estimated size 181.5 KiB, free 364.8 MiB)
21/11/26 20:00:48 INFO BlockManagerInfo: Added input-0-1637937047800 in memory on pes2ug19cs012:38829 (size: 181.5 KiB, free: 364.9 MiB)
21/11/26 20:00:48 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:48 WARN BlockManager: Block input-0-1637937047800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:48 INFO BlockGenerator: Pushed block input-0-1637937047800
21/11/26 20:00:48 INFO JobScheduler: Added jobs for time 1637937048000 ms
21/11/26 20:00:49 INFO JobScheduler: Added jobs for time 1637937049000 ms
21/11/26 20:00:49 INFO CodeGenerator: Code generated in 52.551345 ms
21/11/26 20:00:49 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:49 INFO DAGScheduler: Got job 14 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:49 INFO DAGScheduler: Final stage: ResultStage 16 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:49 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:49 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:49 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[128] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:49 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 57.2 KiB, free 364.7 MiB)
21/11/26 20:00:49 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 364.7 MiB)
21/11/26 20:00:49 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 364.9 MiB)
21/11/26 20:00:49 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[128] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:49 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks resource profile 0
21/11/26 20:00:49 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 66239 bytes) taskResourceAssignments Map()
21/11/26 20:00:49 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
21/11/26 20:00:50 INFO JobScheduler: Added jobs for time 1637937050000 ms
21/11/26 20:00:50 INFO PythonRunner: Times: total = 44, boot = -3189, init = 3232, finish = 1
21/11/26 20:00:50 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 2160 bytes result sent to driver
21/11/26 20:00:50 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 26) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 77599 bytes) taskResourceAssignments Map()
21/11/26 20:00:50 INFO Executor: Running task 1.0 in stage 16.0 (TID 26)
21/11/26 20:00:50 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 254 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:50 INFO PythonRunner: Times: total = 4, boot = -201, init = 205, finish = 0
21/11/26 20:00:50 INFO Executor: Finished task 1.0 in stage 16.0 (TID 26). 2160 bytes result sent to driver
21/11/26 20:00:50 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 26) in 229 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:50 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/11/26 20:00:50 INFO DAGScheduler: ResultStage 16 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.509 s
21/11/26 20:00:50 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
21/11/26 20:00:50 INFO DAGScheduler: Job 14 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.518675 s
21/11/26 20:00:50 INFO JobScheduler: Finished job streaming job 1637937013000 ms.0 from job set of time 1637937013000 ms
21/11/26 20:00:50 INFO JobScheduler: Total delay: 37.389 s for time 1637937013000 ms (execution: 14.563 s)
21/11/26 20:00:50 INFO PythonRDD: Removing RDD 15 from persistence list
21/11/26 20:00:50 INFO JobScheduler: Starting job streaming job 1637937014000 ms.0 from job set of time 1637937014000 ms
21/11/26 20:00:50 INFO BlockRDD: Removing RDD 14 from persistence list
21/11/26 20:00:50 INFO BlockManager: Removing RDD 15
21/11/26 20:00:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[14] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937013000 ms
21/11/26 20:00:50 INFO ReceivedBlockTracker: Deleting batches: 1637937011000 ms
21/11/26 20:00:50 INFO BlockManager: Removing RDD 14
21/11/26 20:00:50 INFO InputInfoTracker: remove old batch metadata: 1637937011000 ms
21/11/26 20:00:50 INFO JobScheduler: Finished job streaming job 1637937014000 ms.0 from job set of time 1637937014000 ms
21/11/26 20:00:50 INFO PythonRDD: Removing RDD 17 from persistence list
21/11/26 20:00:50 INFO JobScheduler: Total delay: 36.431 s for time 1637937014000 ms (execution: 0.041 s)
21/11/26 20:00:50 INFO BlockRDD: Removing RDD 16 from persistence list
21/11/26 20:00:50 INFO JobScheduler: Starting job streaming job 1637937015000 ms.0 from job set of time 1637937015000 ms
21/11/26 20:00:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[16] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937014000 ms
21/11/26 20:00:50 INFO ReceivedBlockTracker: Deleting batches: 1637937012000 ms
21/11/26 20:00:50 INFO InputInfoTracker: remove old batch metadata: 1637937012000 ms
21/11/26 20:00:50 INFO BlockManager: Removing RDD 17
21/11/26 20:00:50 INFO BlockManager: Removing RDD 16
21/11/26 20:00:50 INFO JobScheduler: Finished job streaming job 1637937015000 ms.0 from job set of time 1637937015000 ms
21/11/26 20:00:50 INFO JobScheduler: Total delay: 35.519 s for time 1637937015000 ms (execution: 0.086 s)
21/11/26 20:00:50 INFO JobScheduler: Starting job streaming job 1637937016000 ms.0 from job set of time 1637937016000 ms
21/11/26 20:00:50 INFO PythonRDD: Removing RDD 24 from persistence list
21/11/26 20:00:50 INFO BlockRDD: Removing RDD 23 from persistence list
21/11/26 20:00:50 INFO BlockManagerInfo: Removed input-0-1637937012600 on pes2ug19cs012:38829 in memory (size: 137.8 KiB, free: 365.0 MiB)
21/11/26 20:00:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[23] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937015000 ms
21/11/26 20:00:50 INFO BlockManager: Removing RDD 24
21/11/26 20:00:50 INFO ReceivedBlockTracker: Deleting batches: 1637937013000 ms
21/11/26 20:00:50 INFO InputInfoTracker: remove old batch metadata: 1637937013000 ms
21/11/26 20:00:50 INFO BlockManager: Removing RDD 23
21/11/26 20:00:50 INFO BlockManagerInfo: Removed broadcast_15_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 365.1 MiB)
21/11/26 20:00:50 INFO BlockManagerInfo: Removed broadcast_16_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 365.1 MiB)
21/11/26 20:00:50 INFO JobScheduler: Finished job streaming job 1637937016000 ms.0 from job set of time 1637937016000 ms
21/11/26 20:00:50 INFO JobScheduler: Total delay: 34.576 s for time 1637937016000 ms (execution: 0.056 s)
21/11/26 20:00:50 INFO JobScheduler: Starting job streaming job 1637937017000 ms.0 from job set of time 1637937017000 ms
21/11/26 20:00:50 INFO PythonRDD: Removing RDD 26 from persistence list
21/11/26 20:00:50 INFO BlockRDD: Removing RDD 25 from persistence list
21/11/26 20:00:50 INFO BlockManager: Removing RDD 26
21/11/26 20:00:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[25] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937016000 ms
21/11/26 20:00:50 INFO BlockManager: Removing RDD 25
21/11/26 20:00:50 INFO ReceivedBlockTracker: Deleting batches: 1637937014000 ms
21/11/26 20:00:50 INFO InputInfoTracker: remove old batch metadata: 1637937014000 ms
21/11/26 20:00:50 INFO JobScheduler: Finished job streaming job 1637937017000 ms.0 from job set of time 1637937017000 ms
21/11/26 20:00:50 INFO JobScheduler: Total delay: 33.602 s for time 1637937017000 ms (execution: 0.025 s)
21/11/26 20:00:50 INFO JobScheduler: Starting job streaming job 1637937018000 ms.0 from job set of time 1637937018000 ms
21/11/26 20:00:50 INFO PythonRDD: Removing RDD 28 from persistence list
21/11/26 20:00:50 INFO BlockRDD: Removing RDD 27 from persistence list
21/11/26 20:00:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[27] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937017000 ms
21/11/26 20:00:50 INFO ReceivedBlockTracker: Deleting batches: 1637937015000 ms
21/11/26 20:00:50 INFO InputInfoTracker: remove old batch metadata: 1637937015000 ms
21/11/26 20:00:50 INFO BlockManager: Removing RDD 28
21/11/26 20:00:50 INFO BlockManager: Removing RDD 27
21/11/26 20:00:50 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:00:50 INFO DAGScheduler: Got job 15 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:00:50 INFO DAGScheduler: Final stage: ResultStage 17 (runJob at PythonRDD.scala:166)
21/11/26 20:00:50 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:50 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:50 INFO DAGScheduler: Submitting ResultStage 17 (PythonRDD[131] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:00:50 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.9 KiB, free 365.0 MiB)
21/11/26 20:00:50 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 365.0 MiB)
21/11/26 20:00:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 365.1 MiB)
21/11/26 20:00:50 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (PythonRDD[131] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:50 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
21/11/26 20:00:50 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 27) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:00:50 INFO Executor: Running task 0.0 in stage 17.0 (TID 27)
21/11/26 20:00:50 INFO BlockManager: Found block input-0-1637937017600 locally
21/11/26 20:00:50 INFO PythonRunner: Times: total = 17, boot = -559, init = 573, finish = 3
21/11/26 20:00:50 INFO PythonRunner: Times: total = 78, boot = 25, init = 50, finish = 3
21/11/26 20:00:50 INFO Executor: Finished task 0.0 in stage 17.0 (TID 27). 162743 bytes result sent to driver
21/11/26 20:00:50 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 27) in 111 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:50 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/11/26 20:00:50 INFO DAGScheduler: ResultStage 17 (runJob at PythonRDD.scala:166) finished in 0.132 s
21/11/26 20:00:50 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/11/26 20:00:50 INFO DAGScheduler: Job 15 finished: runJob at PythonRDD.scala:166, took 0.142434 s
21/11/26 20:00:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:50 INFO DAGScheduler: Got job 16 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:00:50 INFO DAGScheduler: Final stage: ResultStage 18 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:50 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:50 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:50 INFO DAGScheduler: Submitting ResultStage 18 (PythonRDD[38] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:00:50 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.6 KiB, free 365.0 MiB)
21/11/26 20:00:50 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 365.0 MiB)
21/11/26 20:00:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 365.1 MiB)
21/11/26 20:00:50 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (PythonRDD[38] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:50 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
21/11/26 20:00:50 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 28) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:00:50 INFO Executor: Running task 0.0 in stage 18.0 (TID 28)
21/11/26 20:00:50 INFO BlockManager: Found block input-0-1637937017600 locally
21/11/26 20:00:51 INFO PythonRunner: Times: total = 32, boot = -221, init = 251, finish = 2
21/11/26 20:00:51 INFO Executor: Finished task 0.0 in stage 18.0 (TID 28). 162743 bytes result sent to driver
21/11/26 20:00:51 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 28) in 74 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:51 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/11/26 20:00:51 INFO DAGScheduler: ResultStage 18 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.127 s
21/11/26 20:00:51 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/11/26 20:00:51 INFO DAGScheduler: Job 16 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.139295 s
21/11/26 20:00:51 INFO JobScheduler: Added jobs for time 1637937051000 ms
21/11/26 20:00:51 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:00:51 INFO DAGScheduler: Registering RDD 141 (collect at StringIndexer.scala:204) as input to shuffle 2
21/11/26 20:00:51 INFO DAGScheduler: Got job 17 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:00:51 INFO DAGScheduler: Final stage: ResultStage 20 (collect at StringIndexer.scala:204)
21/11/26 20:00:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
21/11/26 20:00:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
21/11/26 20:00:51 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[141] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:00:51 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 20.3 KiB, free 365.0 MiB)
21/11/26 20:00:51 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 365.0 MiB)
21/11/26 20:00:51 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 365.1 MiB)
21/11/26 20:00:51 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[141] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:51 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks resource profile 0
21/11/26 20:00:51 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 29) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 71984 bytes) taskResourceAssignments Map()
21/11/26 20:00:51 INFO Executor: Running task 0.0 in stage 19.0 (TID 29)
21/11/26 20:00:51 INFO PythonRunner: Times: total = 47, boot = -543, init = 546, finish = 44
21/11/26 20:00:51 INFO Executor: Finished task 0.0 in stage 19.0 (TID 29). 2271 bytes result sent to driver
21/11/26 20:00:51 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 30) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 91399 bytes) taskResourceAssignments Map()
21/11/26 20:00:51 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 29) in 81 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:51 INFO Executor: Running task 1.0 in stage 19.0 (TID 30)
21/11/26 20:00:51 INFO PythonRunner: Times: total = 5, boot = -21, init = 23, finish = 3
21/11/26 20:00:51 INFO Executor: Finished task 1.0 in stage 19.0 (TID 30). 2271 bytes result sent to driver
21/11/26 20:00:51 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 30) in 54 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:51 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/11/26 20:00:51 INFO DAGScheduler: ShuffleMapStage 19 (collect at StringIndexer.scala:204) finished in 0.146 s
21/11/26 20:00:51 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:00:51 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:00:51 INFO DAGScheduler: waiting: Set(ResultStage 20)
21/11/26 20:00:51 INFO DAGScheduler: failed: Set()
21/11/26 20:00:51 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[144] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:00:51 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 20.8 KiB, free 364.9 MiB)
21/11/26 20:00:51 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 364.9 MiB)
21/11/26 20:00:51 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 365.1 MiB)
21/11/26 20:00:51 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[144] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:00:51 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
21/11/26 20:00:51 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 31) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:00:51 INFO Executor: Running task 0.0 in stage 20.0 (TID 31)
21/11/26 20:00:51 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:00:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:00:51 INFO Executor: Finished task 0.0 in stage 20.0 (TID 31). 3617 bytes result sent to driver
21/11/26 20:00:51 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 31) in 67 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:00:51 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/11/26 20:00:51 INFO DAGScheduler: ResultStage 20 (collect at StringIndexer.scala:204) finished in 0.090 s
21/11/26 20:00:51 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/11/26 20:00:51 INFO DAGScheduler: Job 17 finished: collect at StringIndexer.scala:204, took 0.257307 s
21/11/26 20:00:52 INFO JobScheduler: Added jobs for time 1637937052000 ms
21/11/26 20:00:52 INFO CodeGenerator: Code generated in 50.635911 ms
21/11/26 20:00:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:52 INFO DAGScheduler: Got job 18 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:52 INFO DAGScheduler: Final stage: ResultStage 21 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:52 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:52 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:52 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[148] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:52 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 63.0 KiB, free 364.9 MiB)
21/11/26 20:00:52 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.8 MiB)
21/11/26 20:00:52 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 365.0 MiB)
21/11/26 20:00:52 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[148] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:52 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks resource profile 0
21/11/26 20:00:52 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 32) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 71995 bytes) taskResourceAssignments Map()
21/11/26 20:00:52 INFO Executor: Running task 0.0 in stage 21.0 (TID 32)
21/11/26 20:00:52 INFO PythonRunner: Times: total = 15, boot = -797, init = 801, finish = 11
21/11/26 20:00:52 INFO Executor: Finished task 0.0 in stage 21.0 (TID 32). 17231 bytes result sent to driver
21/11/26 20:00:52 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 33) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 91410 bytes) taskResourceAssignments Map()
21/11/26 20:00:52 INFO Executor: Running task 1.0 in stage 21.0 (TID 33)
21/11/26 20:00:52 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 32) in 167 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:52 INFO PythonRunner: Times: total = 3, boot = -128, init = 130, finish = 1
21/11/26 20:00:52 INFO Executor: Finished task 1.0 in stage 21.0 (TID 33). 26786 bytes result sent to driver
21/11/26 20:00:52 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 33) in 209 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:52 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/11/26 20:00:52 INFO DAGScheduler: ResultStage 21 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.393 s
21/11/26 20:00:52 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
21/11/26 20:00:52 INFO DAGScheduler: Job 18 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.412475 s
21/11/26 20:00:53 INFO MemoryStore: Block input-0-1637937052800 stored as values in memory (estimated size 166.7 KiB, free 364.7 MiB)
21/11/26 20:00:53 INFO BlockManagerInfo: Added input-0-1637937052800 in memory on pes2ug19cs012:38829 (size: 166.7 KiB, free: 364.9 MiB)
21/11/26 20:00:53 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:53 WARN BlockManager: Block input-0-1637937052800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:53 INFO BlockGenerator: Pushed block input-0-1637937052800
21/11/26 20:00:53 INFO JobScheduler: Added jobs for time 1637937053000 ms
21/11/26 20:00:54 INFO JobScheduler: Added jobs for time 1637937054000 ms
21/11/26 20:00:55 INFO BlockManagerInfo: Removed broadcast_17_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 364.9 MiB)
21/11/26 20:00:55 INFO BlockManagerInfo: Removed broadcast_21_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.9 MiB)
21/11/26 20:00:55 INFO BlockManagerInfo: Removed broadcast_20_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 364.9 MiB)
21/11/26 20:00:55 INFO BlockManagerInfo: Removed broadcast_19_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 364.9 MiB)
21/11/26 20:00:55 INFO BlockManagerInfo: Removed broadcast_18_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 364.9 MiB)
21/11/26 20:00:55 INFO JobScheduler: Added jobs for time 1637937055000 ms
21/11/26 20:00:56 INFO JobScheduler: Added jobs for time 1637937056000 ms
21/11/26 20:00:57 INFO JobScheduler: Added jobs for time 1637937057000 ms
21/11/26 20:00:58 INFO MemoryStore: Block input-0-1637937057800 stored as values in memory (estimated size 153.8 KiB, free 364.7 MiB)
21/11/26 20:00:58 INFO BlockManagerInfo: Added input-0-1637937057800 in memory on pes2ug19cs012:38829 (size: 153.8 KiB, free: 364.8 MiB)
21/11/26 20:00:58 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:00:58 WARN BlockManager: Block input-0-1637937057800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:00:58 INFO BlockGenerator: Pushed block input-0-1637937057800
21/11/26 20:00:58 INFO JobScheduler: Added jobs for time 1637937058000 ms
21/11/26 20:00:59 INFO JobScheduler: Added jobs for time 1637937059000 ms
21/11/26 20:00:59 INFO CodeGenerator: Code generated in 49.219049 ms
21/11/26 20:00:59 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:00:59 INFO DAGScheduler: Got job 19 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:00:59 INFO DAGScheduler: Final stage: ResultStage 22 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:00:59 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:00:59 INFO DAGScheduler: Missing parents: List()
21/11/26 20:00:59 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[164] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:00:59 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 57.2 KiB, free 364.6 MiB)
21/11/26 20:00:59 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 364.6 MiB)
21/11/26 20:00:59 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 364.8 MiB)
21/11/26 20:00:59 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1388
21/11/26 20:00:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 22 (MapPartitionsRDD[164] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:00:59 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks resource profile 0
21/11/26 20:00:59 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 34) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 71995 bytes) taskResourceAssignments Map()
21/11/26 20:00:59 INFO Executor: Running task 0.0 in stage 22.0 (TID 34)
21/11/26 20:00:59 INFO PythonRunner: Times: total = 49, boot = -6914, init = 6921, finish = 42
21/11/26 20:00:59 INFO Executor: Finished task 0.0 in stage 22.0 (TID 34). 2162 bytes result sent to driver
21/11/26 20:00:59 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 35) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 91410 bytes) taskResourceAssignments Map()
21/11/26 20:00:59 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 34) in 216 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:00:59 INFO Executor: Running task 1.0 in stage 22.0 (TID 35)
21/11/26 20:00:59 INFO PythonRunner: Times: total = 3, boot = -147, init = 149, finish = 1
21/11/26 20:00:59 INFO Executor: Finished task 1.0 in stage 22.0 (TID 35). 2161 bytes result sent to driver
21/11/26 20:00:59 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 35) in 170 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:00:59 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/11/26 20:00:59 INFO DAGScheduler: ResultStage 22 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.408 s
21/11/26 20:00:59 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:00:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/11/26 20:00:59 INFO DAGScheduler: Job 19 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.416662 s
21/11/26 20:01:00 INFO JobScheduler: Added jobs for time 1637937060000 ms
21/11/26 20:01:00 INFO CodeGenerator: Code generated in 52.259927 ms
21/11/26 20:01:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:00 INFO DAGScheduler: Got job 20 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:00 INFO DAGScheduler: Final stage: ResultStage 23 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:00 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:00 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:00 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[168] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:00 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 63.0 KiB, free 364.6 MiB)
21/11/26 20:01:00 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.5 MiB)
21/11/26 20:01:00 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.7 MiB)
21/11/26 20:01:00 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[168] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:00 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks resource profile 0
21/11/26 20:01:00 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 36) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 71995 bytes) taskResourceAssignments Map()
21/11/26 20:01:00 INFO Executor: Running task 0.0 in stage 23.0 (TID 36)
21/11/26 20:01:00 INFO PythonRunner: Times: total = 30, boot = -341, init = 371, finish = 0
21/11/26 20:01:00 INFO Executor: Finished task 0.0 in stage 23.0 (TID 36). 7946 bytes result sent to driver
21/11/26 20:01:00 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 37) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 91410 bytes) taskResourceAssignments Map()
21/11/26 20:01:00 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 36) in 151 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:00 INFO Executor: Running task 1.0 in stage 23.0 (TID 37)
21/11/26 20:01:00 INFO BlockManagerInfo: Removed broadcast_22_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 364.7 MiB)
21/11/26 20:01:00 INFO PythonRunner: Times: total = 48, boot = -101, init = 102, finish = 47
21/11/26 20:01:00 INFO Executor: Finished task 1.0 in stage 23.0 (TID 37). 8653 bytes result sent to driver
21/11/26 20:01:00 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 37) in 183 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:00 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/11/26 20:01:00 INFO DAGScheduler: ResultStage 23 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.350 s
21/11/26 20:01:00 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/11/26 20:01:00 INFO DAGScheduler: Job 20 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.356927 s
21/11/26 20:01:01 INFO JobScheduler: Added jobs for time 1637937061000 ms
21/11/26 20:01:02 INFO JobScheduler: Added jobs for time 1637937062000 ms
21/11/26 20:01:02 INFO CodeGenerator: Code generated in 33.932873 ms
21/11/26 20:01:02 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:02 INFO DAGScheduler: Got job 21 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:02 INFO DAGScheduler: Final stage: ResultStage 24 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:02 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:02 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:02 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[174] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:02 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 57.2 KiB, free 364.6 MiB)
21/11/26 20:01:02 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 364.5 MiB)
21/11/26 20:01:02 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 364.7 MiB)
21/11/26 20:01:02 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 24 (MapPartitionsRDD[174] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:02 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks resource profile 0
21/11/26 20:01:02 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 38) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 71995 bytes) taskResourceAssignments Map()
21/11/26 20:01:02 INFO Executor: Running task 0.0 in stage 24.0 (TID 38)
21/11/26 20:01:02 INFO PythonRunner: Times: total = 3, boot = -2249, init = 2251, finish = 1
21/11/26 20:01:02 INFO Executor: Finished task 0.0 in stage 24.0 (TID 38). 2160 bytes result sent to driver
21/11/26 20:01:02 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 39) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 91410 bytes) taskResourceAssignments Map()
21/11/26 20:01:02 INFO Executor: Running task 1.0 in stage 24.0 (TID 39)
21/11/26 20:01:02 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 38) in 124 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:02 INFO PythonRunner: Times: total = 3, boot = -99, init = 101, finish = 1
21/11/26 20:01:02 INFO Executor: Finished task 1.0 in stage 24.0 (TID 39). 2160 bytes result sent to driver
21/11/26 20:01:02 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 39) in 187 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:02 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/11/26 20:01:02 INFO DAGScheduler: ResultStage 24 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.323 s
21/11/26 20:01:02 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
21/11/26 20:01:02 INFO DAGScheduler: Job 21 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.326351 s
21/11/26 20:01:02 INFO JobScheduler: Finished job streaming job 1637937018000 ms.0 from job set of time 1637937018000 ms
21/11/26 20:01:02 INFO JobScheduler: Total delay: 44.971 s for time 1637937018000 ms (execution: 12.368 s)
21/11/26 20:01:02 INFO JobScheduler: Starting job streaming job 1637937019000 ms.0 from job set of time 1637937019000 ms
21/11/26 20:01:02 INFO PythonRDD: Removing RDD 30 from persistence list
21/11/26 20:01:02 INFO BlockManager: Removing RDD 30
21/11/26 20:01:02 INFO BlockRDD: Removing RDD 29 from persistence list
21/11/26 20:01:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[29] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937018000 ms
21/11/26 20:01:02 INFO ReceivedBlockTracker: Deleting batches: 1637937016000 ms
21/11/26 20:01:02 INFO InputInfoTracker: remove old batch metadata: 1637937016000 ms
21/11/26 20:01:02 INFO BlockManager: Removing RDD 29
21/11/26 20:01:03 INFO MemoryStore: Block input-0-1637937062800 stored as values in memory (estimated size 176.2 KiB, free 364.4 MiB)
21/11/26 20:01:03 INFO BlockManagerInfo: Added input-0-1637937062800 in memory on pes2ug19cs012:38829 (size: 176.2 KiB, free: 364.6 MiB)
21/11/26 20:01:03 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:03 WARN BlockManager: Block input-0-1637937062800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:03 INFO BlockGenerator: Pushed block input-0-1637937062800
21/11/26 20:01:03 INFO JobScheduler: Finished job streaming job 1637937019000 ms.0 from job set of time 1637937019000 ms
21/11/26 20:01:03 INFO JobScheduler: Total delay: 44.039 s for time 1637937019000 ms (execution: 0.067 s)
21/11/26 20:01:03 INFO JobScheduler: Starting job streaming job 1637937020000 ms.0 from job set of time 1637937020000 ms
21/11/26 20:01:03 INFO JobScheduler: Added jobs for time 1637937063000 ms
21/11/26 20:01:03 INFO PythonRDD: Removing RDD 38 from persistence list
21/11/26 20:01:03 INFO BlockManager: Removing RDD 38
21/11/26 20:01:03 INFO BlockRDD: Removing RDD 37 from persistence list
21/11/26 20:01:03 INFO BlockManager: Removing RDD 37
21/11/26 20:01:03 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[37] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937019000 ms
21/11/26 20:01:03 INFO JobScheduler: Finished job streaming job 1637937020000 ms.0 from job set of time 1637937020000 ms
21/11/26 20:01:03 INFO JobScheduler: Total delay: 43.083 s for time 1637937020000 ms (execution: 0.043 s)
21/11/26 20:01:03 INFO JobScheduler: Starting job streaming job 1637937021000 ms.0 from job set of time 1637937021000 ms
21/11/26 20:01:03 INFO ReceivedBlockTracker: Deleting batches: 1637937017000 ms
21/11/26 20:01:03 INFO InputInfoTracker: remove old batch metadata: 1637937017000 ms
21/11/26 20:01:03 INFO PythonRDD: Removing RDD 40 from persistence list
21/11/26 20:01:03 INFO JobScheduler: Finished job streaming job 1637937021000 ms.0 from job set of time 1637937021000 ms
21/11/26 20:01:03 INFO JobScheduler: Total delay: 42.098 s for time 1637937021000 ms (execution: 0.014 s)
21/11/26 20:01:03 INFO JobScheduler: Starting job streaming job 1637937022000 ms.0 from job set of time 1637937022000 ms
21/11/26 20:01:03 INFO BlockManagerInfo: Removed input-0-1637937017600 on pes2ug19cs012:38829 in memory (size: 156.9 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO BlockManager: Removing RDD 40
21/11/26 20:01:03 INFO BlockRDD: Removing RDD 39 from persistence list
21/11/26 20:01:03 INFO BlockManager: Removing RDD 39
21/11/26 20:01:03 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[39] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937020000 ms
21/11/26 20:01:03 INFO ReceivedBlockTracker: Deleting batches: 1637937018000 ms
21/11/26 20:01:03 INFO InputInfoTracker: remove old batch metadata: 1637937018000 ms
21/11/26 20:01:03 INFO PythonRDD: Removing RDD 42 from persistence list
21/11/26 20:01:03 INFO BlockManager: Removing RDD 42
21/11/26 20:01:03 INFO BlockRDD: Removing RDD 41 from persistence list
21/11/26 20:01:03 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[41] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937021000 ms
21/11/26 20:01:03 INFO ReceivedBlockTracker: Deleting batches: 1637937019000 ms
21/11/26 20:01:03 INFO InputInfoTracker: remove old batch metadata: 1637937019000 ms
21/11/26 20:01:03 INFO BlockManager: Removing RDD 41
21/11/26 20:01:03 INFO JobScheduler: Finished job streaming job 1637937022000 ms.0 from job set of time 1637937022000 ms
21/11/26 20:01:03 INFO JobScheduler: Total delay: 41.121 s for time 1637937022000 ms (execution: 0.022 s)
21/11/26 20:01:03 INFO JobScheduler: Starting job streaming job 1637937023000 ms.0 from job set of time 1637937023000 ms
21/11/26 20:01:03 INFO PythonRDD: Removing RDD 44 from persistence list
21/11/26 20:01:03 INFO BlockManager: Removing RDD 44
21/11/26 20:01:03 INFO BlockRDD: Removing RDD 43 from persistence list
21/11/26 20:01:03 INFO BlockManager: Removing RDD 43
21/11/26 20:01:03 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[43] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937022000 ms
21/11/26 20:01:03 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:01:03 INFO ReceivedBlockTracker: Deleting batches: 1637937020000 ms
21/11/26 20:01:03 INFO InputInfoTracker: remove old batch metadata: 1637937020000 ms
21/11/26 20:01:03 INFO DAGScheduler: Got job 22 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:01:03 INFO DAGScheduler: Final stage: ResultStage 25 (runJob at PythonRDD.scala:166)
21/11/26 20:01:03 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:03 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:03 INFO DAGScheduler: Submitting ResultStage 25 (PythonRDD[177] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 5.9 KiB, free 364.5 MiB)
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 364.5 MiB)
21/11/26 20:01:03 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (PythonRDD[177] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:03 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
21/11/26 20:01:03 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 40) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:03 INFO Executor: Running task 0.0 in stage 25.0 (TID 40)
21/11/26 20:01:03 INFO BlockManager: Found block input-0-1637937022600 locally
21/11/26 20:01:03 INFO PythonRunner: Times: total = 13, boot = -434, init = 445, finish = 2
21/11/26 20:01:03 INFO PythonRunner: Times: total = 26, boot = 12, init = 13, finish = 1
21/11/26 20:01:03 INFO Executor: Finished task 0.0 in stage 25.0 (TID 40). 208800 bytes result sent to driver
21/11/26 20:01:03 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 40) in 48 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:03 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/11/26 20:01:03 INFO DAGScheduler: ResultStage 25 (runJob at PythonRDD.scala:166) finished in 0.062 s
21/11/26 20:01:03 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/11/26 20:01:03 INFO DAGScheduler: Job 22 finished: runJob at PythonRDD.scala:166, took 0.076241 s
21/11/26 20:01:03 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:03 INFO DAGScheduler: Got job 23 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:01:03 INFO DAGScheduler: Final stage: ResultStage 26 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:03 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:03 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:03 INFO DAGScheduler: Submitting ResultStage 26 (PythonRDD[50] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.6 KiB, free 364.5 MiB)
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 364.5 MiB)
21/11/26 20:01:03 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (PythonRDD[50] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:03 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
21/11/26 20:01:03 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 41) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:03 INFO Executor: Running task 0.0 in stage 26.0 (TID 41)
21/11/26 20:01:03 INFO BlockManager: Found block input-0-1637937022600 locally
21/11/26 20:01:03 INFO PythonRunner: Times: total = 9, boot = -50, init = 57, finish = 2
21/11/26 20:01:03 INFO Executor: Finished task 0.0 in stage 26.0 (TID 41). 208800 bytes result sent to driver
21/11/26 20:01:03 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 41) in 21 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:03 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/11/26 20:01:03 INFO DAGScheduler: ResultStage 26 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.033 s
21/11/26 20:01:03 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/11/26 20:01:03 INFO DAGScheduler: Job 23 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.037545 s
21/11/26 20:01:03 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:01:03 INFO DAGScheduler: Registering RDD 185 (collect at StringIndexer.scala:204) as input to shuffle 3
21/11/26 20:01:03 INFO DAGScheduler: Got job 24 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:01:03 INFO DAGScheduler: Final stage: ResultStage 28 (collect at StringIndexer.scala:204)
21/11/26 20:01:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
21/11/26 20:01:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
21/11/26 20:01:03 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[185] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 20.3 KiB, free 364.5 MiB)
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 364.5 MiB)
21/11/26 20:01:03 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[185] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:03 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks resource profile 0
21/11/26 20:01:03 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 42) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 129775 bytes) taskResourceAssignments Map()
21/11/26 20:01:03 INFO Executor: Running task 0.0 in stage 27.0 (TID 42)
21/11/26 20:01:03 INFO BlockManagerInfo: Removed broadcast_25_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO PythonRunner: Times: total = 13, boot = -398, init = 411, finish = 0
21/11/26 20:01:03 INFO BlockManagerInfo: Removed broadcast_24_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO Executor: Finished task 0.0 in stage 27.0 (TID 42). 2314 bytes result sent to driver
21/11/26 20:01:03 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 43) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78696 bytes) taskResourceAssignments Map()
21/11/26 20:01:03 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 42) in 65 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:03 INFO Executor: Running task 1.0 in stage 27.0 (TID 43)
21/11/26 20:01:03 INFO BlockManagerInfo: Removed broadcast_23_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO BlockManagerInfo: Removed broadcast_26_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO PythonRunner: Times: total = 53, boot = -74, init = 126, finish = 1
21/11/26 20:01:03 INFO Executor: Finished task 1.0 in stage 27.0 (TID 43). 2271 bytes result sent to driver
21/11/26 20:01:03 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 43) in 192 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:03 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/11/26 20:01:03 INFO DAGScheduler: ShuffleMapStage 27 (collect at StringIndexer.scala:204) finished in 0.267 s
21/11/26 20:01:03 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:01:03 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:01:03 INFO DAGScheduler: waiting: Set(ResultStage 28)
21/11/26 20:01:03 INFO DAGScheduler: failed: Set()
21/11/26 20:01:03 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[188] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 20.8 KiB, free 364.6 MiB)
21/11/26 20:01:03 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 364.6 MiB)
21/11/26 20:01:03 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 364.7 MiB)
21/11/26 20:01:03 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[188] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:03 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
21/11/26 20:01:03 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 44) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:01:03 INFO Executor: Running task 0.0 in stage 28.0 (TID 44)
21/11/26 20:01:03 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:01:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:01:04 INFO Executor: Finished task 0.0 in stage 28.0 (TID 44). 3617 bytes result sent to driver
21/11/26 20:01:04 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 44) in 43 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:04 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/11/26 20:01:04 INFO DAGScheduler: ResultStage 28 (collect at StringIndexer.scala:204) finished in 0.054 s
21/11/26 20:01:04 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/11/26 20:01:04 INFO DAGScheduler: Job 24 finished: collect at StringIndexer.scala:204, took 0.331534 s
21/11/26 20:01:04 INFO JobScheduler: Added jobs for time 1637937064000 ms
21/11/26 20:01:04 INFO CodeGenerator: Code generated in 36.139594 ms
21/11/26 20:01:04 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:04 INFO DAGScheduler: Got job 25 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:04 INFO DAGScheduler: Final stage: ResultStage 29 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:04 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:04 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:04 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[192] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:04 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 63.0 KiB, free 364.6 MiB)
21/11/26 20:01:04 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.5 MiB)
21/11/26 20:01:04 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.7 MiB)
21/11/26 20:01:04 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 29 (MapPartitionsRDD[192] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:04 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks resource profile 0
21/11/26 20:01:04 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 45) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 129786 bytes) taskResourceAssignments Map()
21/11/26 20:01:04 INFO Executor: Running task 0.0 in stage 29.0 (TID 45)
21/11/26 20:01:04 INFO PythonRunner: Times: total = 4, boot = -697, init = 699, finish = 2
21/11/26 20:01:04 INFO Executor: Finished task 0.0 in stage 29.0 (TID 45). 42430 bytes result sent to driver
21/11/26 20:01:04 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 46) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78707 bytes) taskResourceAssignments Map()
21/11/26 20:01:04 INFO Executor: Running task 1.0 in stage 29.0 (TID 46)
21/11/26 20:01:04 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 45) in 195 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:04 INFO PythonRunner: Times: total = 3, boot = -176, init = 179, finish = 0
21/11/26 20:01:04 INFO Executor: Finished task 1.0 in stage 29.0 (TID 46). 23479 bytes result sent to driver
21/11/26 20:01:04 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 46) in 121 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:04 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/11/26 20:01:04 INFO DAGScheduler: ResultStage 29 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.330 s
21/11/26 20:01:04 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
21/11/26 20:01:04 INFO DAGScheduler: Job 25 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.338255 s
21/11/26 20:01:05 INFO JobScheduler: Added jobs for time 1637937065000 ms
21/11/26 20:01:06 INFO JobScheduler: Added jobs for time 1637937066000 ms
21/11/26 20:01:07 INFO JobScheduler: Added jobs for time 1637937067000 ms
21/11/26 20:01:08 INFO MemoryStore: Block input-0-1637937067800 stored as values in memory (estimated size 187.2 KiB, free 364.3 MiB)
21/11/26 20:01:08 INFO BlockManagerInfo: Added input-0-1637937067800 in memory on pes2ug19cs012:38829 (size: 187.2 KiB, free: 364.5 MiB)
21/11/26 20:01:08 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:08 WARN BlockManager: Block input-0-1637937067800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:08 INFO BlockGenerator: Pushed block input-0-1637937067800
21/11/26 20:01:08 INFO JobScheduler: Added jobs for time 1637937068000 ms
21/11/26 20:01:09 INFO JobScheduler: Added jobs for time 1637937069000 ms
21/11/26 20:01:09 INFO CodeGenerator: Code generated in 30.145981 ms
21/11/26 20:01:09 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:09 INFO DAGScheduler: Got job 26 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:09 INFO DAGScheduler: Final stage: ResultStage 30 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:09 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:09 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:09 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[204] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:09 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 57.2 KiB, free 364.3 MiB)
21/11/26 20:01:09 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 364.3 MiB)
21/11/26 20:01:09 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 364.5 MiB)
21/11/26 20:01:09 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 30 (MapPartitionsRDD[204] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:09 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks resource profile 0
21/11/26 20:01:09 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 47) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 129786 bytes) taskResourceAssignments Map()
21/11/26 20:01:09 INFO Executor: Running task 0.0 in stage 30.0 (TID 47)
21/11/26 20:01:09 INFO BlockManagerInfo: Removed broadcast_29_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.5 MiB)
21/11/26 20:01:09 INFO BlockManagerInfo: Removed broadcast_27_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 364.5 MiB)
21/11/26 20:01:09 INFO BlockManagerInfo: Removed broadcast_28_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 364.5 MiB)
21/11/26 20:01:09 INFO PythonRunner: Times: total = 5, boot = -4974, init = 4979, finish = 0
21/11/26 20:01:09 INFO Executor: Finished task 0.0 in stage 30.0 (TID 47). 2205 bytes result sent to driver
21/11/26 20:01:09 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 48) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78707 bytes) taskResourceAssignments Map()
21/11/26 20:01:09 INFO Executor: Running task 1.0 in stage 30.0 (TID 48)
21/11/26 20:01:09 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 47) in 185 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:10 INFO JobScheduler: Added jobs for time 1637937070000 ms
21/11/26 20:01:10 INFO PythonRunner: Times: total = 2, boot = -174, init = 176, finish = 0
21/11/26 20:01:10 INFO Executor: Finished task 1.0 in stage 30.0 (TID 48). 2162 bytes result sent to driver
21/11/26 20:01:10 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 48) in 128 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:10 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/11/26 20:01:10 INFO DAGScheduler: ResultStage 30 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.326 s
21/11/26 20:01:10 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/11/26 20:01:10 INFO DAGScheduler: Job 26 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.329732 s
21/11/26 20:01:10 INFO CodeGenerator: Code generated in 32.679323 ms
21/11/26 20:01:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:10 INFO DAGScheduler: Got job 27 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:10 INFO DAGScheduler: Final stage: ResultStage 31 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:10 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:10 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:10 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[208] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:10 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 63.0 KiB, free 364.4 MiB)
21/11/26 20:01:10 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.3 MiB)
21/11/26 20:01:10 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.5 MiB)
21/11/26 20:01:10 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[208] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:10 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks resource profile 0
21/11/26 20:01:10 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 49) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 129786 bytes) taskResourceAssignments Map()
21/11/26 20:01:10 INFO Executor: Running task 0.0 in stage 31.0 (TID 49)
21/11/26 20:01:10 INFO PythonRunner: Times: total = 9, boot = -245, init = 252, finish = 2
21/11/26 20:01:10 INFO Executor: Finished task 0.0 in stage 31.0 (TID 49). 7484 bytes result sent to driver
21/11/26 20:01:10 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 50) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78707 bytes) taskResourceAssignments Map()
21/11/26 20:01:10 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 49) in 169 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:10 INFO Executor: Running task 1.0 in stage 31.0 (TID 50)
21/11/26 20:01:10 INFO BlockManagerInfo: Removed broadcast_30_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 364.5 MiB)
21/11/26 20:01:10 INFO PythonRunner: Times: total = 44, boot = -147, init = 148, finish = 43
21/11/26 20:01:10 INFO Executor: Finished task 1.0 in stage 31.0 (TID 50). 10886 bytes result sent to driver
21/11/26 20:01:10 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 50) in 143 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:10 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/11/26 20:01:10 INFO DAGScheduler: ResultStage 31 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.327 s
21/11/26 20:01:10 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
21/11/26 20:01:10 INFO DAGScheduler: Job 27 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.334176 s
21/11/26 20:01:11 INFO JobScheduler: Added jobs for time 1637937071000 ms
21/11/26 20:01:12 INFO JobScheduler: Added jobs for time 1637937072000 ms
21/11/26 20:01:13 INFO MemoryStore: Block input-0-1637937072800 stored as values in memory (estimated size 128.9 KiB, free 364.3 MiB)
21/11/26 20:01:13 INFO BlockManagerInfo: Added input-0-1637937072800 in memory on pes2ug19cs012:38829 (size: 128.9 KiB, free: 364.4 MiB)
21/11/26 20:01:13 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:13 WARN BlockManager: Block input-0-1637937072800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:13 INFO BlockGenerator: Pushed block input-0-1637937072800
21/11/26 20:01:13 INFO JobScheduler: Added jobs for time 1637937073000 ms
21/11/26 20:01:13 INFO CodeGenerator: Code generated in 54.437701 ms
21/11/26 20:01:13 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:13 INFO DAGScheduler: Got job 28 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:13 INFO DAGScheduler: Final stage: ResultStage 32 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:13 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:13 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:13 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[216] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:13 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 57.2 KiB, free 364.2 MiB)
21/11/26 20:01:13 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 364.2 MiB)
21/11/26 20:01:13 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 364.4 MiB)
21/11/26 20:01:13 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[216] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:13 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks resource profile 0
21/11/26 20:01:13 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 51) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 129786 bytes) taskResourceAssignments Map()
21/11/26 20:01:13 INFO Executor: Running task 0.0 in stage 32.0 (TID 51)
21/11/26 20:01:13 INFO PythonRunner: Times: total = 3, boot = -3070, init = 3072, finish = 1
21/11/26 20:01:13 INFO Executor: Finished task 0.0 in stage 32.0 (TID 51). 2160 bytes result sent to driver
21/11/26 20:01:13 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 52) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78707 bytes) taskResourceAssignments Map()
21/11/26 20:01:13 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 51) in 202 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:13 INFO Executor: Running task 1.0 in stage 32.0 (TID 52)
21/11/26 20:01:13 INFO PythonRunner: Times: total = 3, boot = -181, init = 184, finish = 0
21/11/26 20:01:13 INFO Executor: Finished task 1.0 in stage 32.0 (TID 52). 2160 bytes result sent to driver
21/11/26 20:01:13 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 52) in 167 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:13 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/11/26 20:01:13 INFO DAGScheduler: ResultStage 32 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.382 s
21/11/26 20:01:13 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/11/26 20:01:13 INFO DAGScheduler: Job 28 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.395429 s
21/11/26 20:01:13 INFO JobScheduler: Finished job streaming job 1637937023000 ms.0 from job set of time 1637937023000 ms
21/11/26 20:01:13 INFO JobScheduler: Total delay: 50.921 s for time 1637937023000 ms (execution: 10.800 s)
21/11/26 20:01:13 INFO JobScheduler: Starting job streaming job 1637937024000 ms.0 from job set of time 1637937024000 ms
21/11/26 20:01:13 INFO PythonRDD: Removing RDD 48 from persistence list
21/11/26 20:01:13 INFO BlockManager: Removing RDD 48
21/11/26 20:01:13 INFO BlockRDD: Removing RDD 47 from persistence list
21/11/26 20:01:13 INFO BlockManager: Removing RDD 47
21/11/26 20:01:14 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[47] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937023000 ms
21/11/26 20:01:14 INFO ReceivedBlockTracker: Deleting batches: 1637937021000 ms
21/11/26 20:01:14 INFO InputInfoTracker: remove old batch metadata: 1637937021000 ms
21/11/26 20:01:14 INFO JobScheduler: Finished job streaming job 1637937024000 ms.0 from job set of time 1637937024000 ms
21/11/26 20:01:14 INFO JobScheduler: Total delay: 50.024 s for time 1637937024000 ms (execution: 0.085 s)
21/11/26 20:01:14 INFO JobScheduler: Starting job streaming job 1637937025000 ms.0 from job set of time 1637937025000 ms
21/11/26 20:01:14 INFO JobScheduler: Finished job streaming job 1637937025000 ms.0 from job set of time 1637937025000 ms
21/11/26 20:01:14 INFO JobScheduler: Total delay: 49.042 s for time 1637937025000 ms (execution: 0.018 s)
21/11/26 20:01:14 INFO JobScheduler: Starting job streaming job 1637937026000 ms.0 from job set of time 1637937026000 ms
21/11/26 20:01:14 INFO JobScheduler: Finished job streaming job 1637937026000 ms.0 from job set of time 1637937026000 ms
21/11/26 20:01:14 INFO JobScheduler: Total delay: 48.089 s for time 1637937026000 ms (execution: 0.046 s)
21/11/26 20:01:14 INFO JobScheduler: Starting job streaming job 1637937027000 ms.0 from job set of time 1637937027000 ms
21/11/26 20:01:14 INFO JobScheduler: Added jobs for time 1637937074000 ms
21/11/26 20:01:14 INFO PythonRDD: Removing RDD 50 from persistence list
21/11/26 20:01:14 INFO BlockRDD: Removing RDD 49 from persistence list
21/11/26 20:01:14 INFO BlockManager: Removing RDD 50
21/11/26 20:01:14 INFO BlockManager: Removing RDD 49
21/11/26 20:01:14 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[49] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937024000 ms
21/11/26 20:01:14 INFO ReceivedBlockTracker: Deleting batches: 1637937022000 ms
21/11/26 20:01:14 INFO JobScheduler: Finished job streaming job 1637937027000 ms.0 from job set of time 1637937027000 ms
21/11/26 20:01:14 INFO InputInfoTracker: remove old batch metadata: 1637937022000 ms
21/11/26 20:01:14 INFO PythonRDD: Removing RDD 52 from persistence list
21/11/26 20:01:14 INFO JobScheduler: Total delay: 47.130 s for time 1637937027000 ms (execution: 0.040 s)
21/11/26 20:01:14 INFO JobScheduler: Starting job streaming job 1637937028000 ms.0 from job set of time 1637937028000 ms
21/11/26 20:01:14 INFO BlockManagerInfo: Removed input-0-1637937022600 on pes2ug19cs012:38829 in memory (size: 201.7 KiB, free: 364.6 MiB)
21/11/26 20:01:14 INFO BlockRDD: Removing RDD 51 from persistence list
21/11/26 20:01:14 INFO BlockManager: Removing RDD 52
21/11/26 20:01:14 INFO BlockManager: Removing RDD 51
21/11/26 20:01:14 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[51] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937025000 ms
21/11/26 20:01:14 INFO ReceivedBlockTracker: Deleting batches: 1637937023000 ms
21/11/26 20:01:14 INFO InputInfoTracker: remove old batch metadata: 1637937023000 ms
21/11/26 20:01:14 INFO PythonRDD: Removing RDD 54 from persistence list
21/11/26 20:01:14 INFO BlockManager: Removing RDD 54
21/11/26 20:01:14 INFO BlockRDD: Removing RDD 53 from persistence list
21/11/26 20:01:14 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[53] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937026000 ms
21/11/26 20:01:14 INFO ReceivedBlockTracker: Deleting batches: 1637937024000 ms
21/11/26 20:01:14 INFO InputInfoTracker: remove old batch metadata: 1637937024000 ms
21/11/26 20:01:14 INFO PythonRDD: Removing RDD 56 from persistence list
21/11/26 20:01:14 INFO BlockManager: Removing RDD 53
21/11/26 20:01:14 INFO BlockManager: Removing RDD 56
21/11/26 20:01:14 INFO BlockRDD: Removing RDD 55 from persistence list
21/11/26 20:01:14 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[55] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937027000 ms
21/11/26 20:01:14 INFO ReceivedBlockTracker: Deleting batches: 1637937025000 ms
21/11/26 20:01:14 INFO InputInfoTracker: remove old batch metadata: 1637937025000 ms
21/11/26 20:01:14 INFO BlockManager: Removing RDD 55
21/11/26 20:01:14 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:01:14 INFO DAGScheduler: Got job 29 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:01:14 INFO DAGScheduler: Final stage: ResultStage 33 (runJob at PythonRDD.scala:166)
21/11/26 20:01:14 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:14 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:14 INFO DAGScheduler: Submitting ResultStage 33 (PythonRDD[219] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:14 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 5.9 KiB, free 364.4 MiB)
21/11/26 20:01:14 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 364.4 MiB)
21/11/26 20:01:14 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 364.6 MiB)
21/11/26 20:01:14 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (PythonRDD[219] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:14 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
21/11/26 20:01:14 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 53) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:14 INFO Executor: Running task 0.0 in stage 33.0 (TID 53)
21/11/26 20:01:14 INFO BlockManager: Found block input-0-1637937027600 locally
21/11/26 20:01:14 INFO PythonRunner: Times: total = 21, boot = -531, init = 550, finish = 2
21/11/26 20:01:14 INFO PythonRunner: Times: total = 36, boot = 27, init = 8, finish = 1
21/11/26 20:01:14 INFO Executor: Finished task 0.0 in stage 33.0 (TID 53). 167580 bytes result sent to driver
21/11/26 20:01:14 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 53) in 59 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:14 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/11/26 20:01:14 INFO DAGScheduler: ResultStage 33 (runJob at PythonRDD.scala:166) finished in 0.078 s
21/11/26 20:01:14 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
21/11/26 20:01:14 INFO DAGScheduler: Job 29 finished: runJob at PythonRDD.scala:166, took 0.093523 s
21/11/26 20:01:14 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:14 INFO DAGScheduler: Got job 30 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:01:14 INFO DAGScheduler: Final stage: ResultStage 34 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:14 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:14 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:14 INFO DAGScheduler: Submitting ResultStage 34 (PythonRDD[60] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:14 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 4.6 KiB, free 364.4 MiB)
21/11/26 20:01:14 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 364.4 MiB)
21/11/26 20:01:14 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 364.6 MiB)
21/11/26 20:01:14 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (PythonRDD[60] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:14 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
21/11/26 20:01:14 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 54) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:14 INFO Executor: Running task 0.0 in stage 34.0 (TID 54)
21/11/26 20:01:14 INFO BlockManager: Found block input-0-1637937027600 locally
21/11/26 20:01:14 INFO PythonRunner: Times: total = 42, boot = -148, init = 189, finish = 1
21/11/26 20:01:14 INFO Executor: Finished task 0.0 in stage 34.0 (TID 54). 167580 bytes result sent to driver
21/11/26 20:01:14 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 54) in 52 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:14 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/11/26 20:01:14 INFO DAGScheduler: ResultStage 34 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.076 s
21/11/26 20:01:14 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/11/26 20:01:14 INFO DAGScheduler: Job 30 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.083702 s
21/11/26 20:01:15 INFO BlockManagerInfo: Removed broadcast_32_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 364.6 MiB)
21/11/26 20:01:15 INFO BlockManagerInfo: Removed broadcast_34_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 364.6 MiB)
21/11/26 20:01:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.6 MiB)
21/11/26 20:01:15 INFO BlockManagerInfo: Removed broadcast_33_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 364.6 MiB)
21/11/26 20:01:15 INFO JobScheduler: Added jobs for time 1637937075000 ms
21/11/26 20:01:15 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:01:15 INFO DAGScheduler: Registering RDD 229 (collect at StringIndexer.scala:204) as input to shuffle 4
21/11/26 20:01:15 INFO DAGScheduler: Got job 31 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:01:15 INFO DAGScheduler: Final stage: ResultStage 36 (collect at StringIndexer.scala:204)
21/11/26 20:01:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
21/11/26 20:01:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
21/11/26 20:01:15 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[229] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:15 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 20.3 KiB, free 364.5 MiB)
21/11/26 20:01:15 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 364.5 MiB)
21/11/26 20:01:15 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 364.6 MiB)
21/11/26 20:01:15 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[229] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:15 INFO TaskSchedulerImpl: Adding task set 35.0 with 2 tasks resource profile 0
21/11/26 20:01:15 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 55) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 83482 bytes) taskResourceAssignments Map()
21/11/26 20:01:15 INFO Executor: Running task 0.0 in stage 35.0 (TID 55)
21/11/26 20:01:15 INFO PythonRunner: Times: total = 4, boot = -695, init = 698, finish = 1
21/11/26 20:01:15 INFO Executor: Finished task 0.0 in stage 35.0 (TID 55). 2271 bytes result sent to driver
21/11/26 20:01:15 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 56) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84073 bytes) taskResourceAssignments Map()
21/11/26 20:01:15 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 55) in 61 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:15 INFO Executor: Running task 1.0 in stage 35.0 (TID 56)
21/11/26 20:01:15 INFO PythonRunner: Times: total = 51, boot = -27, init = 30, finish = 48
21/11/26 20:01:15 INFO Executor: Finished task 1.0 in stage 35.0 (TID 56). 2271 bytes result sent to driver
21/11/26 20:01:15 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 56) in 90 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:15 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/11/26 20:01:15 INFO DAGScheduler: ShuffleMapStage 35 (collect at StringIndexer.scala:204) finished in 0.162 s
21/11/26 20:01:15 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:01:15 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:01:15 INFO DAGScheduler: waiting: Set(ResultStage 36)
21/11/26 20:01:15 INFO DAGScheduler: failed: Set()
21/11/26 20:01:15 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[232] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:15 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 20.8 KiB, free 364.5 MiB)
21/11/26 20:01:15 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 364.5 MiB)
21/11/26 20:01:15 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 364.6 MiB)
21/11/26 20:01:15 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[232] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:15 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
21/11/26 20:01:15 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 57) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:01:15 INFO Executor: Running task 0.0 in stage 36.0 (TID 57)
21/11/26 20:01:15 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:01:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/11/26 20:01:15 INFO Executor: Finished task 0.0 in stage 36.0 (TID 57). 3617 bytes result sent to driver
21/11/26 20:01:15 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 57) in 54 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:15 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/11/26 20:01:15 INFO DAGScheduler: ResultStage 36 (collect at StringIndexer.scala:204) finished in 0.082 s
21/11/26 20:01:15 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
21/11/26 20:01:15 INFO DAGScheduler: Job 31 finished: collect at StringIndexer.scala:204, took 0.254170 s
21/11/26 20:01:16 INFO CodeGenerator: Code generated in 79.255371 ms
21/11/26 20:01:16 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:16 INFO DAGScheduler: Got job 32 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:16 INFO DAGScheduler: Final stage: ResultStage 37 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:16 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:16 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:16 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[235] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:16 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 63.0 KiB, free 364.4 MiB)
21/11/26 20:01:16 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.4 MiB)
21/11/26 20:01:16 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.6 MiB)
21/11/26 20:01:16 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[235] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:16 INFO TaskSchedulerImpl: Adding task set 37.0 with 2 tasks resource profile 0
21/11/26 20:01:16 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 58) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 83493 bytes) taskResourceAssignments Map()
21/11/26 20:01:16 INFO Executor: Running task 0.0 in stage 37.0 (TID 58)
21/11/26 20:01:16 INFO JobScheduler: Added jobs for time 1637937076000 ms
21/11/26 20:01:16 INFO PythonRunner: Times: total = 15, boot = -788, init = 802, finish = 1
21/11/26 20:01:16 INFO Executor: Finished task 0.0 in stage 37.0 (TID 58). 20337 bytes result sent to driver
21/11/26 20:01:16 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 59) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84084 bytes) taskResourceAssignments Map()
21/11/26 20:01:16 INFO Executor: Running task 1.0 in stage 37.0 (TID 59)
21/11/26 20:01:16 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 58) in 170 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:16 INFO PythonRunner: Times: total = 10, boot = -139, init = 148, finish = 1
21/11/26 20:01:16 INFO Executor: Finished task 1.0 in stage 37.0 (TID 59). 20008 bytes result sent to driver
21/11/26 20:01:16 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 59) in 177 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:16 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/11/26 20:01:16 INFO DAGScheduler: ResultStage 37 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.362 s
21/11/26 20:01:16 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/11/26 20:01:16 INFO DAGScheduler: Job 32 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.372823 s
21/11/26 20:01:17 INFO JobScheduler: Added jobs for time 1637937077000 ms
21/11/26 20:01:18 INFO MemoryStore: Block input-0-1637937077800 stored as values in memory (estimated size 144.4 KiB, free 364.3 MiB)
21/11/26 20:01:18 INFO BlockManagerInfo: Added input-0-1637937077800 in memory on pes2ug19cs012:38829 (size: 144.4 KiB, free: 364.5 MiB)
21/11/26 20:01:18 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:18 WARN BlockManager: Block input-0-1637937077800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:18 INFO BlockGenerator: Pushed block input-0-1637937077800
21/11/26 20:01:18 INFO JobScheduler: Added jobs for time 1637937078000 ms
21/11/26 20:01:19 INFO JobScheduler: Added jobs for time 1637937079000 ms
21/11/26 20:01:20 INFO JobScheduler: Added jobs for time 1637937080000 ms
21/11/26 20:01:21 INFO JobScheduler: Added jobs for time 1637937081000 ms
21/11/26 20:01:22 INFO JobScheduler: Added jobs for time 1637937082000 ms
21/11/26 20:01:23 INFO MemoryStore: Block input-0-1637937082800 stored as values in memory (estimated size 224.8 KiB, free 364.1 MiB)
21/11/26 20:01:23 INFO BlockManagerInfo: Added input-0-1637937082800 in memory on pes2ug19cs012:38829 (size: 224.8 KiB, free: 364.2 MiB)
21/11/26 20:01:23 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:23 WARN BlockManager: Block input-0-1637937082800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:23 INFO BlockGenerator: Pushed block input-0-1637937082800
21/11/26 20:01:23 INFO JobScheduler: Added jobs for time 1637937083000 ms
21/11/26 20:01:23 INFO CodeGenerator: Code generated in 27.87607 ms
21/11/26 20:01:23 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:23 INFO DAGScheduler: Got job 33 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:23 INFO DAGScheduler: Final stage: ResultStage 38 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:23 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:23 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:23 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[252] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:23 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 57.2 KiB, free 364.0 MiB)
21/11/26 20:01:23 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 364.0 MiB)
21/11/26 20:01:23 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 364.2 MiB)
21/11/26 20:01:23 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[252] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:23 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks resource profile 0
21/11/26 20:01:23 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 60) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 83493 bytes) taskResourceAssignments Map()
21/11/26 20:01:23 INFO Executor: Running task 0.0 in stage 38.0 (TID 60)
21/11/26 20:01:23 INFO BlockManagerInfo: Removed broadcast_36_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 364.2 MiB)
21/11/26 20:01:23 INFO BlockManagerInfo: Removed broadcast_37_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.2 MiB)
21/11/26 20:01:23 INFO BlockManagerInfo: Removed broadcast_35_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 364.3 MiB)
21/11/26 20:01:23 INFO PythonRunner: Times: total = 47, boot = -7345, init = 7346, finish = 46
21/11/26 20:01:23 INFO Executor: Finished task 0.0 in stage 38.0 (TID 60). 2205 bytes result sent to driver
21/11/26 20:01:23 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 61) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84084 bytes) taskResourceAssignments Map()
21/11/26 20:01:23 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 60) in 151 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:23 INFO Executor: Running task 1.0 in stage 38.0 (TID 61)
21/11/26 20:01:23 INFO PythonRunner: Times: total = 2, boot = -92, init = 94, finish = 0
21/11/26 20:01:23 INFO Executor: Finished task 1.0 in stage 38.0 (TID 61). 2161 bytes result sent to driver
21/11/26 20:01:23 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 61) in 122 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:23 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/11/26 20:01:23 INFO DAGScheduler: ResultStage 38 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.285 s
21/11/26 20:01:23 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
21/11/26 20:01:23 INFO DAGScheduler: Job 33 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.290283 s
21/11/26 20:01:24 INFO JobScheduler: Added jobs for time 1637937084000 ms
21/11/26 20:01:24 INFO CodeGenerator: Code generated in 52.596715 ms
21/11/26 20:01:24 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:24 INFO DAGScheduler: Got job 34 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:24 INFO DAGScheduler: Final stage: ResultStage 39 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:24 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:24 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:24 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[256] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:24 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 63.0 KiB, free 364.1 MiB)
21/11/26 20:01:24 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.0 MiB)
21/11/26 20:01:24 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.2 MiB)
21/11/26 20:01:24 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[256] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:24 INFO TaskSchedulerImpl: Adding task set 39.0 with 2 tasks resource profile 0
21/11/26 20:01:24 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 62) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 83493 bytes) taskResourceAssignments Map()
21/11/26 20:01:24 INFO Executor: Running task 0.0 in stage 39.0 (TID 62)
21/11/26 20:01:24 INFO PythonRunner: Times: total = 1, boot = -258, init = 259, finish = 0
21/11/26 20:01:24 INFO Executor: Finished task 0.0 in stage 39.0 (TID 62). 11414 bytes result sent to driver
21/11/26 20:01:24 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 63) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84084 bytes) taskResourceAssignments Map()
21/11/26 20:01:24 INFO Executor: Running task 1.0 in stage 39.0 (TID 63)
21/11/26 20:01:24 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 62) in 114 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:24 INFO PythonRunner: Times: total = 2, boot = -103, init = 104, finish = 1
21/11/26 20:01:24 INFO Executor: Finished task 1.0 in stage 39.0 (TID 63). 14429 bytes result sent to driver
21/11/26 20:01:24 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 63) in 105 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:24 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/11/26 20:01:24 INFO DAGScheduler: ResultStage 39 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.229 s
21/11/26 20:01:24 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/11/26 20:01:24 INFO DAGScheduler: Job 34 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.232103 s
21/11/26 20:01:25 INFO JobScheduler: Added jobs for time 1637937085000 ms
21/11/26 20:01:26 INFO JobScheduler: Added jobs for time 1637937086000 ms
21/11/26 20:01:26 INFO CodeGenerator: Code generated in 37.00723 ms
21/11/26 20:01:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:26 INFO DAGScheduler: Got job 35 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:26 INFO DAGScheduler: Final stage: ResultStage 40 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:26 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:26 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:26 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[262] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:26 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 57.2 KiB, free 364.0 MiB)
21/11/26 20:01:26 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 364.0 MiB)
21/11/26 20:01:26 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 364.2 MiB)
21/11/26 20:01:26 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[262] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:26 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks resource profile 0
21/11/26 20:01:26 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 64) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 83493 bytes) taskResourceAssignments Map()
21/11/26 20:01:26 INFO Executor: Running task 0.0 in stage 40.0 (TID 64)
21/11/26 20:01:26 INFO BlockManagerInfo: Removed broadcast_38_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 364.2 MiB)
21/11/26 20:01:26 INFO BlockManagerInfo: Removed broadcast_39_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.3 MiB)
21/11/26 20:01:26 INFO PythonRunner: Times: total = 4, boot = -2324, init = 2327, finish = 1
21/11/26 20:01:26 INFO Executor: Finished task 0.0 in stage 40.0 (TID 64). 2203 bytes result sent to driver
21/11/26 20:01:26 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 65) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84084 bytes) taskResourceAssignments Map()
21/11/26 20:01:26 INFO Executor: Running task 1.0 in stage 40.0 (TID 65)
21/11/26 20:01:26 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 64) in 210 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:26 INFO PythonRunner: Times: total = 2, boot = -186, init = 188, finish = 0
21/11/26 20:01:26 INFO Executor: Finished task 1.0 in stage 40.0 (TID 65). 2160 bytes result sent to driver
21/11/26 20:01:26 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 65) in 170 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:26 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/11/26 20:01:26 INFO DAGScheduler: ResultStage 40 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.393 s
21/11/26 20:01:26 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/11/26 20:01:26 INFO DAGScheduler: Job 35 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.400656 s
21/11/26 20:01:26 INFO JobScheduler: Finished job streaming job 1637937028000 ms.0 from job set of time 1637937028000 ms
21/11/26 20:01:26 INFO JobScheduler: Total delay: 58.938 s for time 1637937028000 ms (execution: 12.807 s)
21/11/26 20:01:26 INFO JobScheduler: Starting job streaming job 1637937029000 ms.0 from job set of time 1637937029000 ms
21/11/26 20:01:26 INFO PythonRDD: Removing RDD 58 from persistence list
21/11/26 20:01:26 INFO BlockManager: Removing RDD 58
21/11/26 20:01:26 INFO BlockRDD: Removing RDD 57 from persistence list
21/11/26 20:01:26 INFO BlockManager: Removing RDD 57
21/11/26 20:01:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[57] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937028000 ms
21/11/26 20:01:26 INFO ReceivedBlockTracker: Deleting batches: 1637937026000 ms
21/11/26 20:01:26 INFO InputInfoTracker: remove old batch metadata: 1637937026000 ms
21/11/26 20:01:27 INFO JobScheduler: Finished job streaming job 1637937029000 ms.0 from job set of time 1637937029000 ms
21/11/26 20:01:27 INFO JobScheduler: Total delay: 58.002 s for time 1637937029000 ms (execution: 0.062 s)
21/11/26 20:01:27 INFO JobScheduler: Starting job streaming job 1637937030000 ms.0 from job set of time 1637937030000 ms
21/11/26 20:01:27 INFO PythonRDD: Removing RDD 60 from persistence list
21/11/26 20:01:27 INFO BlockRDD: Removing RDD 59 from persistence list
21/11/26 20:01:27 INFO BlockManager: Removing RDD 60
21/11/26 20:01:27 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[59] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937029000 ms
21/11/26 20:01:27 INFO BlockManager: Removing RDD 59
21/11/26 20:01:27 INFO ReceivedBlockTracker: Deleting batches: 1637937027000 ms
21/11/26 20:01:27 INFO InputInfoTracker: remove old batch metadata: 1637937027000 ms
21/11/26 20:01:27 INFO BlockManagerInfo: Removed input-0-1637937027600 on pes2ug19cs012:38829 in memory (size: 161.6 KiB, free: 364.4 MiB)
21/11/26 20:01:27 INFO JobScheduler: Finished job streaming job 1637937030000 ms.0 from job set of time 1637937030000 ms
21/11/26 20:01:27 INFO JobScheduler: Total delay: 57.058 s for time 1637937030000 ms (execution: 0.055 s)
21/11/26 20:01:27 INFO JobScheduler: Starting job streaming job 1637937031000 ms.0 from job set of time 1637937031000 ms
21/11/26 20:01:27 INFO JobScheduler: Added jobs for time 1637937087000 ms
21/11/26 20:01:27 INFO PythonRDD: Removing RDD 62 from persistence list
21/11/26 20:01:27 INFO JobScheduler: Finished job streaming job 1637937031000 ms.0 from job set of time 1637937031000 ms
21/11/26 20:01:27 INFO JobScheduler: Total delay: 56.086 s for time 1637937031000 ms (execution: 0.027 s)
21/11/26 20:01:27 INFO JobScheduler: Starting job streaming job 1637937032000 ms.0 from job set of time 1637937032000 ms
21/11/26 20:01:27 INFO BlockManager: Removing RDD 62
21/11/26 20:01:27 INFO BlockRDD: Removing RDD 61 from persistence list
21/11/26 20:01:27 INFO BlockManager: Removing RDD 61
21/11/26 20:01:27 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[61] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937030000 ms
21/11/26 20:01:27 INFO ReceivedBlockTracker: Deleting batches: 1637937028000 ms
21/11/26 20:01:27 INFO InputInfoTracker: remove old batch metadata: 1637937028000 ms
21/11/26 20:01:27 INFO PythonRDD: Removing RDD 64 from persistence list
21/11/26 20:01:27 INFO BlockManager: Removing RDD 64
21/11/26 20:01:27 INFO BlockRDD: Removing RDD 63 from persistence list
21/11/26 20:01:27 INFO BlockManager: Removing RDD 63
21/11/26 20:01:27 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[63] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937031000 ms
21/11/26 20:01:27 INFO ReceivedBlockTracker: Deleting batches: 1637937029000 ms
21/11/26 20:01:27 INFO InputInfoTracker: remove old batch metadata: 1637937029000 ms
21/11/26 20:01:27 INFO JobScheduler: Finished job streaming job 1637937032000 ms.0 from job set of time 1637937032000 ms
21/11/26 20:01:27 INFO JobScheduler: Total delay: 55.128 s for time 1637937032000 ms (execution: 0.041 s)
21/11/26 20:01:27 INFO JobScheduler: Starting job streaming job 1637937033000 ms.0 from job set of time 1637937033000 ms
21/11/26 20:01:27 INFO PythonRDD: Removing RDD 68 from persistence list
21/11/26 20:01:27 INFO BlockManager: Removing RDD 68
21/11/26 20:01:27 INFO BlockRDD: Removing RDD 67 from persistence list
21/11/26 20:01:27 INFO BlockManager: Removing RDD 67
21/11/26 20:01:27 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[67] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937032000 ms
21/11/26 20:01:27 INFO ReceivedBlockTracker: Deleting batches: 1637937030000 ms
21/11/26 20:01:27 INFO InputInfoTracker: remove old batch metadata: 1637937030000 ms
21/11/26 20:01:27 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:01:27 INFO DAGScheduler: Got job 36 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:01:27 INFO DAGScheduler: Final stage: ResultStage 41 (runJob at PythonRDD.scala:166)
21/11/26 20:01:27 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:27 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:27 INFO DAGScheduler: Submitting ResultStage 41 (PythonRDD[265] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 5.9 KiB, free 364.3 MiB)
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 364.3 MiB)
21/11/26 20:01:27 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 364.4 MiB)
21/11/26 20:01:27 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (PythonRDD[265] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:27 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
21/11/26 20:01:27 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 66) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:27 INFO Executor: Running task 0.0 in stage 41.0 (TID 66)
21/11/26 20:01:27 INFO BlockManager: Found block input-0-1637937032600 locally
21/11/26 20:01:27 INFO PythonRunner: Times: total = 12, boot = -454, init = 464, finish = 2
21/11/26 20:01:27 INFO PythonRunner: Times: total = 28, boot = 11, init = 16, finish = 1
21/11/26 20:01:27 INFO Executor: Finished task 0.0 in stage 41.0 (TID 66). 148978 bytes result sent to driver
21/11/26 20:01:27 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 66) in 44 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:27 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/11/26 20:01:27 INFO DAGScheduler: ResultStage 41 (runJob at PythonRDD.scala:166) finished in 0.062 s
21/11/26 20:01:27 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
21/11/26 20:01:27 INFO DAGScheduler: Job 36 finished: runJob at PythonRDD.scala:166, took 0.071339 s
21/11/26 20:01:27 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:27 INFO DAGScheduler: Got job 37 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:01:27 INFO DAGScheduler: Final stage: ResultStage 42 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:27 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:27 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:27 INFO DAGScheduler: Submitting ResultStage 42 (PythonRDD[74] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 4.6 KiB, free 364.3 MiB)
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 364.3 MiB)
21/11/26 20:01:27 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 364.4 MiB)
21/11/26 20:01:27 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (PythonRDD[74] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:27 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
21/11/26 20:01:27 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 67) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:27 INFO Executor: Running task 0.0 in stage 42.0 (TID 67)
21/11/26 20:01:27 INFO BlockManager: Found block input-0-1637937032600 locally
21/11/26 20:01:27 INFO PythonRunner: Times: total = 12, boot = -74, init = 85, finish = 1
21/11/26 20:01:27 INFO Executor: Finished task 0.0 in stage 42.0 (TID 67). 148978 bytes result sent to driver
21/11/26 20:01:27 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 67) in 28 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:27 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/11/26 20:01:27 INFO DAGScheduler: ResultStage 42 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.041 s
21/11/26 20:01:27 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/11/26 20:01:27 INFO DAGScheduler: Job 37 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.049190 s
21/11/26 20:01:27 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:01:27 INFO DAGScheduler: Registering RDD 273 (collect at StringIndexer.scala:204) as input to shuffle 5
21/11/26 20:01:27 INFO DAGScheduler: Got job 38 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:01:27 INFO DAGScheduler: Final stage: ResultStage 44 (collect at StringIndexer.scala:204)
21/11/26 20:01:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
21/11/26 20:01:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
21/11/26 20:01:27 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[273] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 20.3 KiB, free 364.2 MiB)
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 364.2 MiB)
21/11/26 20:01:27 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on pes2ug19cs012:38829 (size: 9.9 KiB, free: 364.4 MiB)
21/11/26 20:01:27 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[273] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:27 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
21/11/26 20:01:27 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 68) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 70409 bytes) taskResourceAssignments Map()
21/11/26 20:01:27 INFO Executor: Running task 0.0 in stage 43.0 (TID 68)
21/11/26 20:01:27 INFO PythonRunner: Times: total = 46, boot = -447, init = 450, finish = 43
21/11/26 20:01:27 INFO Executor: Finished task 0.0 in stage 43.0 (TID 68). 2271 bytes result sent to driver
21/11/26 20:01:27 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 69) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79374 bytes) taskResourceAssignments Map()
21/11/26 20:01:27 INFO Executor: Running task 1.0 in stage 43.0 (TID 69)
21/11/26 20:01:27 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 68) in 110 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:27 INFO PythonRunner: Times: total = 7, boot = -48, init = 54, finish = 1
21/11/26 20:01:27 INFO Executor: Finished task 1.0 in stage 43.0 (TID 69). 2271 bytes result sent to driver
21/11/26 20:01:27 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 69) in 98 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:27 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/11/26 20:01:27 INFO DAGScheduler: ShuffleMapStage 43 (collect at StringIndexer.scala:204) finished in 0.222 s
21/11/26 20:01:27 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:01:27 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:01:27 INFO DAGScheduler: waiting: Set(ResultStage 44)
21/11/26 20:01:27 INFO DAGScheduler: failed: Set()
21/11/26 20:01:27 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[276] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 20.8 KiB, free 364.2 MiB)
21/11/26 20:01:27 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 364.2 MiB)
21/11/26 20:01:27 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 364.4 MiB)
21/11/26 20:01:27 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[276] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:27 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
21/11/26 20:01:27 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 70) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:01:27 INFO Executor: Running task 0.0 in stage 44.0 (TID 70)
21/11/26 20:01:28 INFO MemoryStore: Block input-0-1637937087800 stored as values in memory (estimated size 158.6 KiB, free 364.1 MiB)
21/11/26 20:01:28 INFO BlockManagerInfo: Added input-0-1637937087800 in memory on pes2ug19cs012:38829 (size: 158.6 KiB, free: 364.2 MiB)
21/11/26 20:01:28 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:28 WARN BlockManager: Block input-0-1637937087800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:28 INFO BlockGenerator: Pushed block input-0-1637937087800
21/11/26 20:01:28 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:01:28 INFO JobScheduler: Added jobs for time 1637937088000 ms
21/11/26 20:01:28 INFO Executor: Finished task 0.0 in stage 44.0 (TID 70). 3617 bytes result sent to driver
21/11/26 20:01:28 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 70) in 109 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:28 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/11/26 20:01:28 INFO DAGScheduler: ResultStage 44 (collect at StringIndexer.scala:204) finished in 0.138 s
21/11/26 20:01:28 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/11/26 20:01:28 INFO DAGScheduler: Job 38 finished: collect at StringIndexer.scala:204, took 0.369799 s
21/11/26 20:01:28 INFO CodeGenerator: Code generated in 41.315692 ms
21/11/26 20:01:28 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:28 INFO DAGScheduler: Got job 39 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:28 INFO DAGScheduler: Final stage: ResultStage 45 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:28 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:28 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:28 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[280] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:28 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 63.0 KiB, free 364.0 MiB)
21/11/26 20:01:28 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 364.0 MiB)
21/11/26 20:01:28 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.2 MiB)
21/11/26 20:01:28 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[280] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:28 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
21/11/26 20:01:28 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 71) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 70420 bytes) taskResourceAssignments Map()
21/11/26 20:01:28 INFO Executor: Running task 0.0 in stage 45.0 (TID 71)
21/11/26 20:01:28 INFO PythonRunner: Times: total = 3, boot = -970, init = 972, finish = 1
21/11/26 20:01:29 INFO Executor: Finished task 0.0 in stage 45.0 (TID 71). 18563 bytes result sent to driver
21/11/26 20:01:29 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 72) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79385 bytes) taskResourceAssignments Map()
21/11/26 20:01:29 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 71) in 144 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:29 INFO Executor: Running task 1.0 in stage 45.0 (TID 72)
21/11/26 20:01:29 INFO BlockManagerInfo: Removed broadcast_43_piece0 on pes2ug19cs012:38829 in memory (size: 9.9 KiB, free: 364.2 MiB)
21/11/26 20:01:29 INFO BlockManagerInfo: Removed broadcast_40_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 364.2 MiB)
21/11/26 20:01:29 INFO JobScheduler: Added jobs for time 1637937089000 ms
21/11/26 20:01:29 INFO BlockManagerInfo: Removed broadcast_42_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 364.2 MiB)
21/11/26 20:01:29 INFO BlockManagerInfo: Removed broadcast_44_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 364.3 MiB)
21/11/26 20:01:29 INFO BlockManagerInfo: Removed broadcast_41_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 364.3 MiB)
21/11/26 20:01:29 INFO PythonRunner: Times: total = 55, boot = -125, init = 136, finish = 44
21/11/26 20:01:29 INFO Executor: Finished task 1.0 in stage 45.0 (TID 72). 23041 bytes result sent to driver
21/11/26 20:01:29 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 72) in 237 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:29 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/11/26 20:01:29 INFO DAGScheduler: ResultStage 45 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.398 s
21/11/26 20:01:29 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/11/26 20:01:29 INFO DAGScheduler: Job 39 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.408111 s
21/11/26 20:01:30 INFO JobScheduler: Added jobs for time 1637937090000 ms
21/11/26 20:01:31 INFO JobScheduler: Added jobs for time 1637937091000 ms
21/11/26 20:01:32 INFO JobScheduler: Added jobs for time 1637937092000 ms
21/11/26 20:01:33 INFO MemoryStore: Block input-0-1637937092800 stored as values in memory (estimated size 160.6 KiB, free 364.0 MiB)
21/11/26 20:01:33 INFO BlockManagerInfo: Added input-0-1637937092800 in memory on pes2ug19cs012:38829 (size: 160.6 KiB, free: 364.1 MiB)
21/11/26 20:01:33 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:33 WARN BlockManager: Block input-0-1637937092800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:33 INFO BlockGenerator: Pushed block input-0-1637937092800
21/11/26 20:01:33 INFO JobScheduler: Added jobs for time 1637937093000 ms
21/11/26 20:01:34 INFO JobScheduler: Added jobs for time 1637937094000 ms
21/11/26 20:01:35 INFO JobScheduler: Added jobs for time 1637937095000 ms
21/11/26 20:01:35 INFO CodeGenerator: Code generated in 33.358303 ms
21/11/26 20:01:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:35 INFO DAGScheduler: Got job 40 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:35 INFO DAGScheduler: Final stage: ResultStage 46 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:35 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:35 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:35 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[296] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:35 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 57.2 KiB, free 363.9 MiB)
21/11/26 20:01:35 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.9 MiB)
21/11/26 20:01:35 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 364.1 MiB)
21/11/26 20:01:35 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[296] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:35 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks resource profile 0
21/11/26 20:01:35 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 73) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 70420 bytes) taskResourceAssignments Map()
21/11/26 20:01:35 INFO Executor: Running task 0.0 in stage 46.0 (TID 73)
21/11/26 20:01:35 INFO PythonRunner: Times: total = 12, boot = -6655, init = 6667, finish = 0
21/11/26 20:01:35 INFO Executor: Finished task 0.0 in stage 46.0 (TID 73). 2162 bytes result sent to driver
21/11/26 20:01:35 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 74) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79385 bytes) taskResourceAssignments Map()
21/11/26 20:01:35 INFO Executor: Running task 1.0 in stage 46.0 (TID 74)
21/11/26 20:01:35 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 73) in 119 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:35 INFO PythonRunner: Times: total = 2, boot = -81, init = 83, finish = 0
21/11/26 20:01:35 INFO Executor: Finished task 1.0 in stage 46.0 (TID 74). 2162 bytes result sent to driver
21/11/26 20:01:35 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 74) in 109 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:35 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/11/26 20:01:35 INFO DAGScheduler: ResultStage 46 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.244 s
21/11/26 20:01:35 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/11/26 20:01:35 INFO DAGScheduler: Job 40 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.247418 s
21/11/26 20:01:36 INFO JobScheduler: Added jobs for time 1637937096000 ms
21/11/26 20:01:36 INFO CodeGenerator: Code generated in 29.817933 ms
21/11/26 20:01:36 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:36 INFO DAGScheduler: Got job 41 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:36 INFO DAGScheduler: Final stage: ResultStage 47 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:36 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:36 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:36 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[300] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:36 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 63.0 KiB, free 363.8 MiB)
21/11/26 20:01:36 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.8 MiB)
21/11/26 20:01:36 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.1 MiB)
21/11/26 20:01:36 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[300] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:36 INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks resource profile 0
21/11/26 20:01:36 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 75) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 70420 bytes) taskResourceAssignments Map()
21/11/26 20:01:36 INFO Executor: Running task 0.0 in stage 47.0 (TID 75)
21/11/26 20:01:36 INFO PythonRunner: Times: total = 11, boot = -315, init = 326, finish = 0
21/11/26 20:01:36 INFO Executor: Finished task 0.0 in stage 47.0 (TID 75). 11281 bytes result sent to driver
21/11/26 20:01:36 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 76) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79385 bytes) taskResourceAssignments Map()
21/11/26 20:01:36 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 75) in 140 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:36 INFO BlockManagerInfo: Removed broadcast_45_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.1 MiB)
21/11/26 20:01:36 INFO Executor: Running task 1.0 in stage 47.0 (TID 76)
21/11/26 20:01:36 INFO BlockManagerInfo: Removed broadcast_46_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 364.1 MiB)
21/11/26 20:01:36 INFO PythonRunner: Times: total = 9, boot = -99, init = 107, finish = 1
21/11/26 20:01:36 INFO Executor: Finished task 1.0 in stage 47.0 (TID 76). 10511 bytes result sent to driver
21/11/26 20:01:36 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 76) in 219 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:36 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/11/26 20:01:36 INFO DAGScheduler: ResultStage 47 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.358 s
21/11/26 20:01:36 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/11/26 20:01:36 INFO DAGScheduler: Job 41 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.372126 s
21/11/26 20:01:37 INFO JobScheduler: Added jobs for time 1637937097000 ms
21/11/26 20:01:38 INFO MemoryStore: Block input-0-1637937097800 stored as values in memory (estimated size 143.6 KiB, free 363.8 MiB)
21/11/26 20:01:38 INFO BlockManagerInfo: Added input-0-1637937097800 in memory on pes2ug19cs012:38829 (size: 143.6 KiB, free: 364.0 MiB)
21/11/26 20:01:38 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:38 WARN BlockManager: Block input-0-1637937097800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:38 INFO BlockGenerator: Pushed block input-0-1637937097800
21/11/26 20:01:38 INFO JobScheduler: Added jobs for time 1637937098000 ms
21/11/26 20:01:38 INFO CodeGenerator: Code generated in 28.885845 ms
21/11/26 20:01:38 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:38 INFO DAGScheduler: Got job 42 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:38 INFO DAGScheduler: Final stage: ResultStage 48 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:38 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:38 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:38 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[306] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:38 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 57.2 KiB, free 363.8 MiB)
21/11/26 20:01:38 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.7 MiB)
21/11/26 20:01:38 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 363.9 MiB)
21/11/26 20:01:38 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 48 (MapPartitionsRDD[306] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:38 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks resource profile 0
21/11/26 20:01:38 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 77) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 70420 bytes) taskResourceAssignments Map()
21/11/26 20:01:38 INFO Executor: Running task 0.0 in stage 48.0 (TID 77)
21/11/26 20:01:38 INFO PythonRunner: Times: total = 44, boot = -1931, init = 1933, finish = 42
21/11/26 20:01:38 INFO Executor: Finished task 0.0 in stage 48.0 (TID 77). 2160 bytes result sent to driver
21/11/26 20:01:38 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 78) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79385 bytes) taskResourceAssignments Map()
21/11/26 20:01:38 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 77) in 118 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:38 INFO Executor: Running task 1.0 in stage 48.0 (TID 78)
21/11/26 20:01:38 INFO PythonRunner: Times: total = 4, boot = -65, init = 68, finish = 1
21/11/26 20:01:38 INFO Executor: Finished task 1.0 in stage 48.0 (TID 78). 2160 bytes result sent to driver
21/11/26 20:01:38 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 78) in 104 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:38 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/11/26 20:01:38 INFO DAGScheduler: ResultStage 48 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.231 s
21/11/26 20:01:38 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/11/26 20:01:38 INFO DAGScheduler: Job 42 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.233810 s
21/11/26 20:01:38 INFO JobScheduler: Finished job streaming job 1637937033000 ms.0 from job set of time 1637937033000 ms
21/11/26 20:01:38 INFO JobScheduler: Total delay: 65.504 s for time 1637937033000 ms (execution: 11.376 s)
21/11/26 20:01:38 INFO JobScheduler: Starting job streaming job 1637937034000 ms.0 from job set of time 1637937034000 ms
21/11/26 20:01:38 INFO PythonRDD: Removing RDD 72 from persistence list
21/11/26 20:01:38 INFO BlockRDD: Removing RDD 71 from persistence list
21/11/26 20:01:38 INFO BlockManager: Removing RDD 72
21/11/26 20:01:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[71] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937033000 ms
21/11/26 20:01:38 INFO ReceivedBlockTracker: Deleting batches: 1637937031000 ms
21/11/26 20:01:38 INFO InputInfoTracker: remove old batch metadata: 1637937031000 ms
21/11/26 20:01:38 INFO BlockManager: Removing RDD 71
21/11/26 20:01:38 INFO JobScheduler: Finished job streaming job 1637937034000 ms.0 from job set of time 1637937034000 ms
21/11/26 20:01:38 INFO JobScheduler: Total delay: 64.528 s for time 1637937034000 ms (execution: 0.023 s)
21/11/26 20:01:38 INFO JobScheduler: Starting job streaming job 1637937035000 ms.0 from job set of time 1637937035000 ms
21/11/26 20:01:38 INFO PythonRDD: Removing RDD 74 from persistence list
21/11/26 20:01:38 INFO BlockRDD: Removing RDD 73 from persistence list
21/11/26 20:01:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[73] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937034000 ms
21/11/26 20:01:38 INFO ReceivedBlockTracker: Deleting batches: 1637937032000 ms
21/11/26 20:01:38 INFO InputInfoTracker: remove old batch metadata: 1637937032000 ms
21/11/26 20:01:38 INFO JobScheduler: Finished job streaming job 1637937035000 ms.0 from job set of time 1637937035000 ms
21/11/26 20:01:38 INFO JobScheduler: Total delay: 63.548 s for time 1637937035000 ms (execution: 0.019 s)
21/11/26 20:01:38 INFO JobScheduler: Starting job streaming job 1637937036000 ms.0 from job set of time 1637937036000 ms
21/11/26 20:01:38 INFO PythonRDD: Removing RDD 76 from persistence list
21/11/26 20:01:38 INFO BlockRDD: Removing RDD 75 from persistence list
21/11/26 20:01:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[75] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937035000 ms
21/11/26 20:01:38 INFO ReceivedBlockTracker: Deleting batches: 1637937033000 ms
21/11/26 20:01:38 INFO InputInfoTracker: remove old batch metadata: 1637937033000 ms
21/11/26 20:01:38 INFO BlockManager: Removing RDD 74
21/11/26 20:01:38 INFO BlockManager: Removing RDD 73
21/11/26 20:01:38 INFO BlockManagerInfo: Removed input-0-1637937032600 on pes2ug19cs012:38829 in memory (size: 143.5 KiB, free: 364.1 MiB)
21/11/26 20:01:38 INFO BlockManager: Removing RDD 76
21/11/26 20:01:38 INFO BlockManager: Removing RDD 75
21/11/26 20:01:38 INFO JobScheduler: Finished job streaming job 1637937036000 ms.0 from job set of time 1637937036000 ms
21/11/26 20:01:38 INFO JobScheduler: Total delay: 62.574 s for time 1637937036000 ms (execution: 0.026 s)
21/11/26 20:01:38 INFO JobScheduler: Starting job streaming job 1637937037000 ms.0 from job set of time 1637937037000 ms
21/11/26 20:01:38 INFO PythonRDD: Removing RDD 80 from persistence list
21/11/26 20:01:38 INFO BlockManager: Removing RDD 80
21/11/26 20:01:38 INFO BlockRDD: Removing RDD 79 from persistence list
21/11/26 20:01:38 INFO BlockManager: Removing RDD 79
21/11/26 20:01:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[79] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937036000 ms
21/11/26 20:01:38 INFO ReceivedBlockTracker: Deleting batches: 1637937034000 ms
21/11/26 20:01:38 INFO InputInfoTracker: remove old batch metadata: 1637937034000 ms
21/11/26 20:01:38 INFO JobScheduler: Finished job streaming job 1637937037000 ms.0 from job set of time 1637937037000 ms
21/11/26 20:01:38 INFO JobScheduler: Total delay: 61.596 s for time 1637937037000 ms (execution: 0.022 s)
21/11/26 20:01:38 INFO PythonRDD: Removing RDD 83 from persistence list
21/11/26 20:01:38 INFO JobScheduler: Starting job streaming job 1637937038000 ms.0 from job set of time 1637937038000 ms
21/11/26 20:01:38 INFO BlockRDD: Removing RDD 82 from persistence list
21/11/26 20:01:38 INFO BlockManager: Removing RDD 83
21/11/26 20:01:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[82] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937037000 ms
21/11/26 20:01:38 INFO ReceivedBlockTracker: Deleting batches: 1637937035000 ms
21/11/26 20:01:38 INFO InputInfoTracker: remove old batch metadata: 1637937035000 ms
21/11/26 20:01:38 INFO BlockManager: Removing RDD 82
21/11/26 20:01:38 INFO JobScheduler: Finished job streaming job 1637937038000 ms.0 from job set of time 1637937038000 ms
21/11/26 20:01:38 INFO JobScheduler: Total delay: 60.622 s for time 1637937038000 ms (execution: 0.026 s)
21/11/26 20:01:38 INFO JobScheduler: Starting job streaming job 1637937039000 ms.0 from job set of time 1637937039000 ms
21/11/26 20:01:38 INFO PythonRDD: Removing RDD 96 from persistence list
21/11/26 20:01:38 INFO BlockManager: Removing RDD 96
21/11/26 20:01:38 INFO BlockRDD: Removing RDD 95 from persistence list
21/11/26 20:01:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[95] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937038000 ms
21/11/26 20:01:38 INFO ReceivedBlockTracker: Deleting batches: 1637937036000 ms
21/11/26 20:01:38 INFO InputInfoTracker: remove old batch metadata: 1637937036000 ms
21/11/26 20:01:38 INFO BlockManager: Removing RDD 95
21/11/26 20:01:38 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:01:38 INFO DAGScheduler: Got job 43 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:01:38 INFO DAGScheduler: Final stage: ResultStage 49 (runJob at PythonRDD.scala:166)
21/11/26 20:01:38 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:38 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:38 INFO DAGScheduler: Submitting ResultStage 49 (PythonRDD[307] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:38 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 5.9 KiB, free 363.9 MiB)
21/11/26 20:01:38 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 363.9 MiB)
21/11/26 20:01:38 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 364.1 MiB)
21/11/26 20:01:38 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (PythonRDD[307] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:38 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
21/11/26 20:01:38 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 79) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:38 INFO Executor: Running task 0.0 in stage 49.0 (TID 79)
21/11/26 20:01:38 INFO BlockManager: Found block input-0-1637937037800 locally
21/11/26 20:01:38 INFO PythonRunner: Times: total = 16, boot = -298, init = 313, finish = 1
21/11/26 20:01:38 INFO PythonRunner: Times: total = 38, boot = 18, init = 19, finish = 1
21/11/26 20:01:38 INFO Executor: Finished task 0.0 in stage 49.0 (TID 79). 203368 bytes result sent to driver
21/11/26 20:01:38 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 79) in 58 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:38 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/11/26 20:01:38 INFO DAGScheduler: ResultStage 49 (runJob at PythonRDD.scala:166) finished in 0.079 s
21/11/26 20:01:38 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/11/26 20:01:38 INFO DAGScheduler: Job 43 finished: runJob at PythonRDD.scala:166, took 0.088234 s
21/11/26 20:01:38 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:38 INFO DAGScheduler: Got job 44 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:01:38 INFO DAGScheduler: Final stage: ResultStage 50 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:38 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:38 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:38 INFO DAGScheduler: Submitting ResultStage 50 (PythonRDD[102] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:38 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 4.6 KiB, free 363.9 MiB)
21/11/26 20:01:38 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 363.9 MiB)
21/11/26 20:01:38 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 364.1 MiB)
21/11/26 20:01:38 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (PythonRDD[102] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:38 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
21/11/26 20:01:38 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 80) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:38 INFO Executor: Running task 0.0 in stage 50.0 (TID 80)
21/11/26 20:01:38 INFO BlockManager: Found block input-0-1637937037800 locally
21/11/26 20:01:38 INFO PythonRunner: Times: total = 9, boot = -85, init = 92, finish = 2
21/11/26 20:01:38 INFO Executor: Finished task 0.0 in stage 50.0 (TID 80). 203368 bytes result sent to driver
21/11/26 20:01:38 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 80) in 21 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:38 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/11/26 20:01:38 INFO DAGScheduler: ResultStage 50 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.050 s
21/11/26 20:01:38 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/11/26 20:01:38 INFO DAGScheduler: Job 44 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.057725 s
21/11/26 20:01:39 INFO JobScheduler: Added jobs for time 1637937099000 ms
21/11/26 20:01:39 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:01:39 INFO DAGScheduler: Registering RDD 317 (collect at StringIndexer.scala:204) as input to shuffle 6
21/11/26 20:01:39 INFO DAGScheduler: Got job 45 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:01:39 INFO DAGScheduler: Final stage: ResultStage 52 (collect at StringIndexer.scala:204)
21/11/26 20:01:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
21/11/26 20:01:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
21/11/26 20:01:39 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[317] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:39 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 20.3 KiB, free 363.8 MiB)
21/11/26 20:01:39 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 363.8 MiB)
21/11/26 20:01:39 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[317] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:39 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks resource profile 0
21/11/26 20:01:39 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 81) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75090 bytes) taskResourceAssignments Map()
21/11/26 20:01:39 INFO Executor: Running task 0.0 in stage 51.0 (TID 81)
21/11/26 20:01:39 INFO PythonRunner: Times: total = 4, boot = -413, init = 417, finish = 0
21/11/26 20:01:39 INFO Executor: Finished task 0.0 in stage 51.0 (TID 81). 2271 bytes result sent to driver
21/11/26 20:01:39 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 82) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 127965 bytes) taskResourceAssignments Map()
21/11/26 20:01:39 INFO Executor: Running task 1.0 in stage 51.0 (TID 82)
21/11/26 20:01:39 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 81) in 26 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:39 INFO PythonRunner: Times: total = 2, boot = -9, init = 11, finish = 0
21/11/26 20:01:39 INFO Executor: Finished task 1.0 in stage 51.0 (TID 82). 2271 bytes result sent to driver
21/11/26 20:01:39 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 82) in 39 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:39 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/11/26 20:01:39 INFO DAGScheduler: ShuffleMapStage 51 (collect at StringIndexer.scala:204) finished in 0.078 s
21/11/26 20:01:39 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:01:39 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:01:39 INFO DAGScheduler: waiting: Set(ResultStage 52)
21/11/26 20:01:39 INFO DAGScheduler: failed: Set()
21/11/26 20:01:39 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[320] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:39 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 20.8 KiB, free 363.8 MiB)
21/11/26 20:01:39 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 363.8 MiB)
21/11/26 20:01:39 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[320] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:39 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
21/11/26 20:01:39 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 83) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:01:39 INFO Executor: Running task 0.0 in stage 52.0 (TID 83)
21/11/26 20:01:39 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:01:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/11/26 20:01:39 INFO BlockManagerInfo: Removed broadcast_51_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO BlockManagerInfo: Removed broadcast_50_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO BlockManagerInfo: Removed broadcast_48_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO BlockManagerInfo: Removed broadcast_47_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO BlockManagerInfo: Removed broadcast_49_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO Executor: Finished task 0.0 in stage 52.0 (TID 83). 3658 bytes result sent to driver
21/11/26 20:01:39 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 83) in 93 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:39 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/11/26 20:01:39 INFO DAGScheduler: ResultStage 52 (collect at StringIndexer.scala:204) finished in 0.104 s
21/11/26 20:01:39 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/11/26 20:01:39 INFO DAGScheduler: Job 45 finished: collect at StringIndexer.scala:204, took 0.187077 s
21/11/26 20:01:39 INFO CodeGenerator: Code generated in 32.794121 ms
21/11/26 20:01:39 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:39 INFO DAGScheduler: Got job 46 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:39 INFO DAGScheduler: Final stage: ResultStage 53 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:39 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:39 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:39 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[322] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:39 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 63.0 KiB, free 364.0 MiB)
21/11/26 20:01:39 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.9 MiB)
21/11/26 20:01:39 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 364.1 MiB)
21/11/26 20:01:39 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[322] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:39 INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks resource profile 0
21/11/26 20:01:39 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 84) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75101 bytes) taskResourceAssignments Map()
21/11/26 20:01:39 INFO Executor: Running task 0.0 in stage 53.0 (TID 84)
21/11/26 20:01:40 INFO PythonRunner: Times: total = 45, boot = -595, init = 597, finish = 43
21/11/26 20:01:40 INFO Executor: Finished task 0.0 in stage 53.0 (TID 84). 18045 bytes result sent to driver
21/11/26 20:01:40 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 84) in 147 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:40 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 85) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 127976 bytes) taskResourceAssignments Map()
21/11/26 20:01:40 INFO Executor: Running task 1.0 in stage 53.0 (TID 85)
21/11/26 20:01:40 INFO JobScheduler: Added jobs for time 1637937100000 ms
21/11/26 20:01:40 INFO PythonRunner: Times: total = 2, boot = -94, init = 95, finish = 1
21/11/26 20:01:40 INFO Executor: Finished task 1.0 in stage 53.0 (TID 85). 41303 bytes result sent to driver
21/11/26 20:01:40 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 85) in 122 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:40 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/11/26 20:01:40 INFO DAGScheduler: ResultStage 53 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.287 s
21/11/26 20:01:40 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/11/26 20:01:40 INFO DAGScheduler: Job 46 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.291704 s
21/11/26 20:01:41 INFO JobScheduler: Added jobs for time 1637937101000 ms
21/11/26 20:01:42 INFO JobScheduler: Added jobs for time 1637937102000 ms
21/11/26 20:01:43 INFO MemoryStore: Block input-0-1637937102800 stored as values in memory (estimated size 189.6 KiB, free 363.7 MiB)
21/11/26 20:01:43 INFO BlockManagerInfo: Added input-0-1637937102800 in memory on pes2ug19cs012:38829 (size: 189.6 KiB, free: 363.9 MiB)
21/11/26 20:01:43 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:43 WARN BlockManager: Block input-0-1637937102800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:43 INFO BlockGenerator: Pushed block input-0-1637937102800
21/11/26 20:01:43 INFO JobScheduler: Added jobs for time 1637937103000 ms
21/11/26 20:01:44 INFO JobScheduler: Added jobs for time 1637937104000 ms
21/11/26 20:01:45 INFO JobScheduler: Added jobs for time 1637937105000 ms
21/11/26 20:01:46 INFO JobScheduler: Added jobs for time 1637937106000 ms
21/11/26 20:01:47 INFO JobScheduler: Added jobs for time 1637937107000 ms
21/11/26 20:01:48 INFO MemoryStore: Block input-0-1637937107800 stored as values in memory (estimated size 152.4 KiB, free 363.6 MiB)
21/11/26 20:01:48 INFO CodeGenerator: Code generated in 56.212215 ms
21/11/26 20:01:48 INFO BlockManagerInfo: Added input-0-1637937107800 in memory on pes2ug19cs012:38829 (size: 152.4 KiB, free: 363.8 MiB)
21/11/26 20:01:48 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:48 WARN BlockManager: Block input-0-1637937107800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:48 INFO BlockGenerator: Pushed block input-0-1637937107800
21/11/26 20:01:48 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:48 INFO DAGScheduler: Got job 47 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:48 INFO DAGScheduler: Final stage: ResultStage 54 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:48 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:48 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:48 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[341] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:48 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 57.2 KiB, free 363.5 MiB)
21/11/26 20:01:48 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.5 MiB)
21/11/26 20:01:48 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 363.7 MiB)
21/11/26 20:01:48 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 54 (MapPartitionsRDD[341] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:48 INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0
21/11/26 20:01:48 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 86) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75101 bytes) taskResourceAssignments Map()
21/11/26 20:01:48 INFO Executor: Running task 0.0 in stage 54.0 (TID 86)
21/11/26 20:01:48 INFO JobScheduler: Added jobs for time 1637937108000 ms
21/11/26 20:01:48 INFO PythonRunner: Times: total = 4, boot = -8037, init = 8040, finish = 1
21/11/26 20:01:48 INFO Executor: Finished task 0.0 in stage 54.0 (TID 86). 2162 bytes result sent to driver
21/11/26 20:01:48 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 87) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 127976 bytes) taskResourceAssignments Map()
21/11/26 20:01:48 INFO Executor: Running task 1.0 in stage 54.0 (TID 87)
21/11/26 20:01:48 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 86) in 166 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:48 INFO BlockManagerInfo: Removed broadcast_52_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 363.7 MiB)
21/11/26 20:01:48 INFO BlockManagerInfo: Removed broadcast_53_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.8 MiB)
21/11/26 20:01:48 INFO PythonRunner: Times: total = 3, boot = -144, init = 146, finish = 1
21/11/26 20:01:48 INFO Executor: Finished task 1.0 in stage 54.0 (TID 87). 2204 bytes result sent to driver
21/11/26 20:01:48 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 87) in 236 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:48 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/11/26 20:01:48 INFO DAGScheduler: ResultStage 54 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.414 s
21/11/26 20:01:48 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/11/26 20:01:48 INFO DAGScheduler: Job 47 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.417955 s
21/11/26 20:01:48 INFO CodeGenerator: Code generated in 59.470345 ms
21/11/26 20:01:48 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:48 INFO DAGScheduler: Got job 48 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:48 INFO DAGScheduler: Final stage: ResultStage 55 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:48 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:48 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:48 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[344] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:48 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 63.0 KiB, free 363.6 MiB)
21/11/26 20:01:48 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.6 MiB)
21/11/26 20:01:48 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.7 MiB)
21/11/26 20:01:48 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[344] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:48 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks resource profile 0
21/11/26 20:01:48 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 88) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75101 bytes) taskResourceAssignments Map()
21/11/26 20:01:48 INFO Executor: Running task 0.0 in stage 55.0 (TID 88)
21/11/26 20:01:48 INFO PythonRunner: Times: total = 48, boot = -414, init = 418, finish = 44
21/11/26 20:01:48 INFO Executor: Finished task 0.0 in stage 55.0 (TID 88). 8933 bytes result sent to driver
21/11/26 20:01:48 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 89) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 127976 bytes) taskResourceAssignments Map()
21/11/26 20:01:48 INFO Executor: Running task 1.0 in stage 55.0 (TID 89)
21/11/26 20:01:48 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 88) in 194 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:49 INFO JobScheduler: Added jobs for time 1637937109000 ms
21/11/26 20:01:49 INFO PythonRunner: Times: total = 3, boot = -119, init = 122, finish = 0
21/11/26 20:01:49 INFO Executor: Finished task 1.0 in stage 55.0 (TID 89). 9960 bytes result sent to driver
21/11/26 20:01:49 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 89) in 213 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:49 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/11/26 20:01:49 INFO DAGScheduler: ResultStage 55 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.420 s
21/11/26 20:01:49 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/11/26 20:01:49 INFO DAGScheduler: Job 48 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.425726 s
21/11/26 20:01:50 INFO JobScheduler: Added jobs for time 1637937110000 ms
21/11/26 20:01:51 INFO JobScheduler: Added jobs for time 1637937111000 ms
21/11/26 20:01:51 INFO CodeGenerator: Code generated in 40.39288 ms
21/11/26 20:01:51 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:51 INFO DAGScheduler: Got job 49 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:51 INFO DAGScheduler: Final stage: ResultStage 56 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:51 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:51 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:51 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[352] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:51 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 57.2 KiB, free 363.5 MiB)
21/11/26 20:01:51 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.5 MiB)
21/11/26 20:01:51 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 363.7 MiB)
21/11/26 20:01:51 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 56 (MapPartitionsRDD[352] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:51 INFO TaskSchedulerImpl: Adding task set 56.0 with 2 tasks resource profile 0
21/11/26 20:01:51 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 90) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75101 bytes) taskResourceAssignments Map()
21/11/26 20:01:51 INFO Executor: Running task 0.0 in stage 56.0 (TID 90)
21/11/26 20:01:51 INFO BlockManagerInfo: Removed broadcast_55_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.7 MiB)
21/11/26 20:01:51 INFO BlockManagerInfo: Removed broadcast_54_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 363.8 MiB)
21/11/26 20:01:52 INFO JobScheduler: Added jobs for time 1637937112000 ms
21/11/26 20:01:52 INFO PythonRunner: Times: total = 5, boot = -2989, init = 2993, finish = 1
21/11/26 20:01:52 INFO Executor: Finished task 0.0 in stage 56.0 (TID 90). 2203 bytes result sent to driver
21/11/26 20:01:52 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 91) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 127976 bytes) taskResourceAssignments Map()
21/11/26 20:01:52 INFO Executor: Running task 1.0 in stage 56.0 (TID 91)
21/11/26 20:01:52 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 90) in 197 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:52 INFO PythonRunner: Times: total = 8, boot = -179, init = 186, finish = 1
21/11/26 20:01:52 INFO Executor: Finished task 1.0 in stage 56.0 (TID 91). 2160 bytes result sent to driver
21/11/26 20:01:52 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 91) in 181 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:52 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/11/26 20:01:52 INFO DAGScheduler: ResultStage 56 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.404 s
21/11/26 20:01:52 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
21/11/26 20:01:52 INFO DAGScheduler: Job 49 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.418097 s
21/11/26 20:01:52 INFO JobScheduler: Finished job streaming job 1637937039000 ms.0 from job set of time 1637937039000 ms
21/11/26 20:01:52 INFO JobScheduler: Total delay: 73.273 s for time 1637937039000 ms (execution: 13.650 s)
21/11/26 20:01:52 INFO PythonRDD: Removing RDD 100 from persistence list
21/11/26 20:01:52 INFO JobScheduler: Starting job streaming job 1637937040000 ms.0 from job set of time 1637937040000 ms
21/11/26 20:01:52 INFO BlockRDD: Removing RDD 99 from persistence list
21/11/26 20:01:52 INFO BlockManager: Removing RDD 100
21/11/26 20:01:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[99] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937039000 ms
21/11/26 20:01:52 INFO ReceivedBlockTracker: Deleting batches: 1637937037000 ms
21/11/26 20:01:52 INFO InputInfoTracker: remove old batch metadata: 1637937037000 ms
21/11/26 20:01:52 INFO BlockManager: Removing RDD 99
21/11/26 20:01:52 INFO JobScheduler: Finished job streaming job 1637937040000 ms.0 from job set of time 1637937040000 ms
21/11/26 20:01:52 INFO JobScheduler: Total delay: 72.304 s for time 1637937040000 ms (execution: 0.020 s)
21/11/26 20:01:52 INFO PythonRDD: Removing RDD 102 from persistence list
21/11/26 20:01:52 INFO JobScheduler: Starting job streaming job 1637937041000 ms.0 from job set of time 1637937041000 ms
21/11/26 20:01:52 INFO BlockManager: Removing RDD 102
21/11/26 20:01:52 INFO BlockRDD: Removing RDD 101 from persistence list
21/11/26 20:01:52 INFO BlockManager: Removing RDD 101
21/11/26 20:01:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[101] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937040000 ms
21/11/26 20:01:52 INFO BlockManagerInfo: Removed input-0-1637937037800 on pes2ug19cs012:38829 in memory (size: 196.4 KiB, free: 364.0 MiB)
21/11/26 20:01:52 INFO ReceivedBlockTracker: Deleting batches: 1637937038000 ms
21/11/26 20:01:52 INFO InputInfoTracker: remove old batch metadata: 1637937038000 ms
21/11/26 20:01:52 INFO JobScheduler: Finished job streaming job 1637937041000 ms.0 from job set of time 1637937041000 ms
21/11/26 20:01:52 INFO JobScheduler: Total delay: 71.339 s for time 1637937041000 ms (execution: 0.030 s)
21/11/26 20:01:52 INFO JobScheduler: Starting job streaming job 1637937042000 ms.0 from job set of time 1637937042000 ms
21/11/26 20:01:52 INFO PythonRDD: Removing RDD 104 from persistence list
21/11/26 20:01:52 INFO BlockRDD: Removing RDD 103 from persistence list
21/11/26 20:01:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[103] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937041000 ms
21/11/26 20:01:52 INFO ReceivedBlockTracker: Deleting batches: 1637937039000 ms
21/11/26 20:01:52 INFO InputInfoTracker: remove old batch metadata: 1637937039000 ms
21/11/26 20:01:52 INFO BlockManager: Removing RDD 104
21/11/26 20:01:52 INFO BlockManager: Removing RDD 103
21/11/26 20:01:52 INFO JobScheduler: Finished job streaming job 1637937042000 ms.0 from job set of time 1637937042000 ms
21/11/26 20:01:52 INFO JobScheduler: Total delay: 70.364 s for time 1637937042000 ms (execution: 0.020 s)
21/11/26 20:01:52 INFO PythonRDD: Removing RDD 106 from persistence list
21/11/26 20:01:52 INFO JobScheduler: Starting job streaming job 1637937043000 ms.0 from job set of time 1637937043000 ms
21/11/26 20:01:52 INFO BlockRDD: Removing RDD 105 from persistence list
21/11/26 20:01:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[105] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937042000 ms
21/11/26 20:01:52 INFO ReceivedBlockTracker: Deleting batches: 1637937040000 ms
21/11/26 20:01:52 INFO InputInfoTracker: remove old batch metadata: 1637937040000 ms
21/11/26 20:01:52 INFO BlockManager: Removing RDD 106
21/11/26 20:01:52 INFO BlockManager: Removing RDD 105
21/11/26 20:01:52 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:01:52 INFO DAGScheduler: Got job 50 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:01:52 INFO DAGScheduler: Final stage: ResultStage 57 (runJob at PythonRDD.scala:166)
21/11/26 20:01:52 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:52 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:52 INFO DAGScheduler: Submitting ResultStage 57 (PythonRDD[355] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:52 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 5.9 KiB, free 363.8 MiB)
21/11/26 20:01:52 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 363.8 MiB)
21/11/26 20:01:52 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 364.0 MiB)
21/11/26 20:01:52 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (PythonRDD[355] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:52 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
21/11/26 20:01:52 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 92) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:52 INFO Executor: Running task 0.0 in stage 57.0 (TID 92)
21/11/26 20:01:52 INFO BlockManager: Found block input-0-1637937042600 locally
21/11/26 20:01:52 INFO PythonRunner: Times: total = 35, boot = -358, init = 391, finish = 2
21/11/26 20:01:52 INFO PythonRunner: Times: total = 35, boot = 13, init = 21, finish = 1
21/11/26 20:01:52 INFO Executor: Finished task 0.0 in stage 57.0 (TID 92). 179374 bytes result sent to driver
21/11/26 20:01:52 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 92) in 78 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:52 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/11/26 20:01:52 INFO DAGScheduler: ResultStage 57 (runJob at PythonRDD.scala:166) finished in 0.090 s
21/11/26 20:01:52 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/11/26 20:01:52 INFO DAGScheduler: Job 50 finished: runJob at PythonRDD.scala:166, took 0.106972 s
21/11/26 20:01:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:52 INFO DAGScheduler: Got job 51 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:01:52 INFO DAGScheduler: Final stage: ResultStage 58 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:52 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:52 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:52 INFO DAGScheduler: Submitting ResultStage 58 (PythonRDD[110] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:01:52 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 4.6 KiB, free 363.8 MiB)
21/11/26 20:01:52 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 363.8 MiB)
21/11/26 20:01:52 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 364.0 MiB)
21/11/26 20:01:52 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (PythonRDD[110] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:52 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
21/11/26 20:01:52 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 93) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:01:52 INFO Executor: Running task 0.0 in stage 58.0 (TID 93)
21/11/26 20:01:52 INFO BlockManager: Found block input-0-1637937042600 locally
21/11/26 20:01:52 INFO PythonRunner: Times: total = 13, boot = -74, init = 85, finish = 2
21/11/26 20:01:52 INFO Executor: Finished task 0.0 in stage 58.0 (TID 93). 179374 bytes result sent to driver
21/11/26 20:01:52 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 93) in 22 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:52 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/11/26 20:01:52 INFO DAGScheduler: ResultStage 58 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.035 s
21/11/26 20:01:52 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/11/26 20:01:52 INFO DAGScheduler: Job 51 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.046198 s
21/11/26 20:01:53 INFO MemoryStore: Block input-0-1637937112800 stored as values in memory (estimated size 146.4 KiB, free 363.7 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Added input-0-1637937112800 in memory on pes2ug19cs012:38829 (size: 146.4 KiB, free: 363.8 MiB)
21/11/26 20:01:53 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:53 WARN BlockManager: Block input-0-1637937112800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:53 INFO BlockGenerator: Pushed block input-0-1637937112800
21/11/26 20:01:53 INFO JobScheduler: Added jobs for time 1637937113000 ms
21/11/26 20:01:53 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:01:53 INFO DAGScheduler: Registering RDD 365 (collect at StringIndexer.scala:204) as input to shuffle 7
21/11/26 20:01:53 INFO DAGScheduler: Got job 52 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:01:53 INFO DAGScheduler: Final stage: ResultStage 60 (collect at StringIndexer.scala:204)
21/11/26 20:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
21/11/26 20:01:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
21/11/26 20:01:53 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[365] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:53 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 20.3 KiB, free 363.6 MiB)
21/11/26 20:01:53 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 363.6 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[365] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:53 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks resource profile 0
21/11/26 20:01:53 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 94) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 91267 bytes) taskResourceAssignments Map()
21/11/26 20:01:53 INFO Executor: Running task 0.0 in stage 59.0 (TID 94)
21/11/26 20:01:53 INFO PythonRunner: Times: total = 2, boot = -658, init = 660, finish = 0
21/11/26 20:01:53 INFO Executor: Finished task 0.0 in stage 59.0 (TID 94). 2271 bytes result sent to driver
21/11/26 20:01:53 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 95) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 87786 bytes) taskResourceAssignments Map()
21/11/26 20:01:53 INFO Executor: Running task 1.0 in stage 59.0 (TID 95)
21/11/26 20:01:53 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 94) in 24 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:53 INFO PythonRunner: Times: total = 46, boot = -16, init = 17, finish = 45
21/11/26 20:01:53 INFO Executor: Finished task 1.0 in stage 59.0 (TID 95). 2271 bytes result sent to driver
21/11/26 20:01:53 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 95) in 76 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:53 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/11/26 20:01:53 INFO DAGScheduler: ShuffleMapStage 59 (collect at StringIndexer.scala:204) finished in 0.109 s
21/11/26 20:01:53 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:01:53 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:01:53 INFO DAGScheduler: waiting: Set(ResultStage 60)
21/11/26 20:01:53 INFO DAGScheduler: failed: Set()
21/11/26 20:01:53 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[368] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:01:53 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 20.8 KiB, free 363.6 MiB)
21/11/26 20:01:53 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 363.6 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[368] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:01:53 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
21/11/26 20:01:53 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 96) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:01:53 INFO Executor: Running task 0.0 in stage 60.0 (TID 96)
21/11/26 20:01:53 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:01:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:01:53 INFO Executor: Finished task 0.0 in stage 60.0 (TID 96). 3617 bytes result sent to driver
21/11/26 20:01:53 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 96) in 28 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:01:53 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/11/26 20:01:53 INFO DAGScheduler: ResultStage 60 (collect at StringIndexer.scala:204) finished in 0.036 s
21/11/26 20:01:53 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/11/26 20:01:53 INFO DAGScheduler: Job 52 finished: collect at StringIndexer.scala:204, took 0.152675 s
21/11/26 20:01:53 INFO CodeGenerator: Code generated in 26.505571 ms
21/11/26 20:01:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:53 INFO DAGScheduler: Got job 53 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:53 INFO DAGScheduler: Final stage: ResultStage 61 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:53 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:53 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:53 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[370] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:53 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 63.0 KiB, free 363.5 MiB)
21/11/26 20:01:53 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.5 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[370] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:53 INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks resource profile 0
21/11/26 20:01:53 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 97) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 91278 bytes) taskResourceAssignments Map()
21/11/26 20:01:53 INFO Executor: Running task 0.0 in stage 61.0 (TID 97)
21/11/26 20:01:53 INFO BlockManagerInfo: Removed broadcast_60_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Removed broadcast_58_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Removed broadcast_57_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Removed broadcast_56_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO BlockManagerInfo: Removed broadcast_59_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 363.8 MiB)
21/11/26 20:01:53 INFO PythonRunner: Times: total = 1, boot = -470, init = 471, finish = 0
21/11/26 20:01:53 INFO Executor: Finished task 0.0 in stage 61.0 (TID 97). 18658 bytes result sent to driver
21/11/26 20:01:53 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 98) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 87797 bytes) taskResourceAssignments Map()
21/11/26 20:01:53 INFO Executor: Running task 1.0 in stage 61.0 (TID 98)
21/11/26 20:01:53 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 97) in 142 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:54 INFO JobScheduler: Added jobs for time 1637937114000 ms
21/11/26 20:01:54 INFO PythonRunner: Times: total = 2, boot = -130, init = 131, finish = 1
21/11/26 20:01:54 INFO Executor: Finished task 1.0 in stage 61.0 (TID 98). 22133 bytes result sent to driver
21/11/26 20:01:54 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 98) in 103 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:54 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/11/26 20:01:54 INFO DAGScheduler: ResultStage 61 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.252 s
21/11/26 20:01:54 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/11/26 20:01:54 INFO DAGScheduler: Job 53 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.254649 s
21/11/26 20:01:55 INFO JobScheduler: Added jobs for time 1637937115000 ms
21/11/26 20:01:56 INFO JobScheduler: Added jobs for time 1637937116000 ms
21/11/26 20:01:57 INFO JobScheduler: Added jobs for time 1637937117000 ms
21/11/26 20:01:58 INFO MemoryStore: Block input-0-1637937117800 stored as values in memory (estimated size 327.7 KiB, free 363.4 MiB)
21/11/26 20:01:58 INFO BlockManagerInfo: Added input-0-1637937117800 in memory on pes2ug19cs012:38829 (size: 327.7 KiB, free: 363.5 MiB)
21/11/26 20:01:58 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:01:58 WARN BlockManager: Block input-0-1637937117800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:01:58 INFO BlockGenerator: Pushed block input-0-1637937117800
21/11/26 20:01:58 INFO JobScheduler: Added jobs for time 1637937118000 ms
21/11/26 20:01:59 INFO JobScheduler: Added jobs for time 1637937119000 ms
21/11/26 20:01:59 INFO CodeGenerator: Code generated in 36.683677 ms
21/11/26 20:01:59 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:59 INFO DAGScheduler: Got job 54 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:59 INFO DAGScheduler: Final stage: ResultStage 62 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:59 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:59 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:59 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[384] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:59 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 57.2 KiB, free 363.3 MiB)
21/11/26 20:01:59 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 363.3 MiB)
21/11/26 20:01:59 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 363.5 MiB)
21/11/26 20:01:59 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 62 (MapPartitionsRDD[384] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:59 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks resource profile 0
21/11/26 20:01:59 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 99) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 91278 bytes) taskResourceAssignments Map()
21/11/26 20:01:59 INFO Executor: Running task 0.0 in stage 62.0 (TID 99)
21/11/26 20:01:59 INFO PythonRunner: Times: total = 44, boot = -5472, init = 5473, finish = 43
21/11/26 20:01:59 INFO Executor: Finished task 0.0 in stage 62.0 (TID 99). 2161 bytes result sent to driver
21/11/26 20:01:59 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 100) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 87797 bytes) taskResourceAssignments Map()
21/11/26 20:01:59 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 99) in 138 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:01:59 INFO Executor: Running task 1.0 in stage 62.0 (TID 100)
21/11/26 20:01:59 INFO PythonRunner: Times: total = 2, boot = -81, init = 83, finish = 0
21/11/26 20:01:59 INFO Executor: Finished task 1.0 in stage 62.0 (TID 100). 2162 bytes result sent to driver
21/11/26 20:01:59 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 100) in 92 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:01:59 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/11/26 20:01:59 INFO DAGScheduler: ResultStage 62 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.239 s
21/11/26 20:01:59 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:01:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
21/11/26 20:01:59 INFO DAGScheduler: Job 54 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.243096 s
21/11/26 20:01:59 INFO CodeGenerator: Code generated in 27.736631 ms
21/11/26 20:01:59 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:01:59 INFO DAGScheduler: Got job 55 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:01:59 INFO DAGScheduler: Final stage: ResultStage 63 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:01:59 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:01:59 INFO DAGScheduler: Missing parents: List()
21/11/26 20:01:59 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[386] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:01:59 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 63.0 KiB, free 363.2 MiB)
21/11/26 20:01:59 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.2 MiB)
21/11/26 20:01:59 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.5 MiB)
21/11/26 20:01:59 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1388
21/11/26 20:01:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 63 (MapPartitionsRDD[386] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:01:59 INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks resource profile 0
21/11/26 20:01:59 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 101) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 91278 bytes) taskResourceAssignments Map()
21/11/26 20:01:59 INFO Executor: Running task 0.0 in stage 63.0 (TID 101)
21/11/26 20:01:59 INFO BlockManagerInfo: Removed broadcast_62_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 363.5 MiB)
21/11/26 20:01:59 INFO BlockManagerInfo: Removed broadcast_61_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.5 MiB)
21/11/26 20:01:59 INFO PythonRunner: Times: total = 2, boot = -186, init = 188, finish = 0
21/11/26 20:01:59 INFO Executor: Finished task 0.0 in stage 63.0 (TID 101). 20745 bytes result sent to driver
21/11/26 20:01:59 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 102) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 87797 bytes) taskResourceAssignments Map()
21/11/26 20:01:59 INFO Executor: Running task 1.0 in stage 63.0 (TID 102)
21/11/26 20:01:59 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 101) in 123 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:00 INFO PythonRunner: Times: total = 45, boot = -110, init = 111, finish = 44
21/11/26 20:02:00 INFO Executor: Finished task 1.0 in stage 63.0 (TID 102). 14584 bytes result sent to driver
21/11/26 20:02:00 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 102) in 132 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:00 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/11/26 20:02:00 INFO DAGScheduler: ResultStage 63 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.262 s
21/11/26 20:02:00 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/11/26 20:02:00 INFO DAGScheduler: Job 55 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.266891 s
21/11/26 20:02:00 INFO JobScheduler: Added jobs for time 1637937120000 ms
21/11/26 20:02:01 INFO JobScheduler: Added jobs for time 1637937121000 ms
21/11/26 20:02:02 INFO JobScheduler: Added jobs for time 1637937122000 ms
21/11/26 20:02:02 INFO CodeGenerator: Code generated in 18.884746 ms
21/11/26 20:02:02 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:02 INFO DAGScheduler: Got job 56 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:02 INFO DAGScheduler: Final stage: ResultStage 64 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:02 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:02 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:02 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[394] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 57.2 KiB, free 363.3 MiB)
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 363.3 MiB)
21/11/26 20:02:02 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 363.5 MiB)
21/11/26 20:02:02 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 64 (MapPartitionsRDD[394] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:02 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks resource profile 0
21/11/26 20:02:02 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 103) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 91278 bytes) taskResourceAssignments Map()
21/11/26 20:02:02 INFO Executor: Running task 0.0 in stage 64.0 (TID 103)
21/11/26 20:02:02 INFO PythonRunner: Times: total = 2, boot = -2113, init = 2115, finish = 0
21/11/26 20:02:02 INFO Executor: Finished task 0.0 in stage 64.0 (TID 103). 2160 bytes result sent to driver
21/11/26 20:02:02 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 104) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 87797 bytes) taskResourceAssignments Map()
21/11/26 20:02:02 INFO Executor: Running task 1.0 in stage 64.0 (TID 104)
21/11/26 20:02:02 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 103) in 113 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:02 INFO PythonRunner: Times: total = 2, boot = -99, init = 101, finish = 0
21/11/26 20:02:02 INFO Executor: Finished task 1.0 in stage 64.0 (TID 104). 2160 bytes result sent to driver
21/11/26 20:02:02 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 104) in 103 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:02 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/11/26 20:02:02 INFO DAGScheduler: ResultStage 64 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.225 s
21/11/26 20:02:02 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/11/26 20:02:02 INFO DAGScheduler: Job 56 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.229695 s
21/11/26 20:02:02 INFO JobScheduler: Finished job streaming job 1637937043000 ms.0 from job set of time 1637937043000 ms
21/11/26 20:02:02 INFO JobScheduler: Total delay: 79.305 s for time 1637937043000 ms (execution: 9.940 s)
21/11/26 20:02:02 INFO JobScheduler: Starting job streaming job 1637937044000 ms.0 from job set of time 1637937044000 ms
21/11/26 20:02:02 INFO PythonRDD: Removing RDD 108 from persistence list
21/11/26 20:02:02 INFO BlockManager: Removing RDD 108
21/11/26 20:02:02 INFO BlockRDD: Removing RDD 107 from persistence list
21/11/26 20:02:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[107] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937043000 ms
21/11/26 20:02:02 INFO ReceivedBlockTracker: Deleting batches: 1637937041000 ms
21/11/26 20:02:02 INFO InputInfoTracker: remove old batch metadata: 1637937041000 ms
21/11/26 20:02:02 INFO JobScheduler: Finished job streaming job 1637937044000 ms.0 from job set of time 1637937044000 ms
21/11/26 20:02:02 INFO JobScheduler: Total delay: 78.317 s for time 1637937044000 ms (execution: 0.011 s)
21/11/26 20:02:02 INFO JobScheduler: Starting job streaming job 1637937045000 ms.0 from job set of time 1637937045000 ms
21/11/26 20:02:02 INFO PythonRDD: Removing RDD 110 from persistence list
21/11/26 20:02:02 INFO BlockRDD: Removing RDD 109 from persistence list
21/11/26 20:02:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[109] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937044000 ms
21/11/26 20:02:02 INFO ReceivedBlockTracker: Deleting batches: 1637937042000 ms
21/11/26 20:02:02 INFO InputInfoTracker: remove old batch metadata: 1637937042000 ms
21/11/26 20:02:02 INFO BlockManager: Removing RDD 107
21/11/26 20:02:02 INFO BlockManager: Removing RDD 110
21/11/26 20:02:02 INFO BlockManager: Removing RDD 109
21/11/26 20:02:02 INFO BlockManagerInfo: Removed input-0-1637937042600 on pes2ug19cs012:38829 in memory (size: 173.1 KiB, free: 363.6 MiB)
21/11/26 20:02:02 INFO JobScheduler: Finished job streaming job 1637937045000 ms.0 from job set of time 1637937045000 ms
21/11/26 20:02:02 INFO JobScheduler: Total delay: 77.334 s for time 1637937045000 ms (execution: 0.016 s)
21/11/26 20:02:02 INFO JobScheduler: Starting job streaming job 1637937046000 ms.0 from job set of time 1637937046000 ms
21/11/26 20:02:02 INFO PythonRDD: Removing RDD 112 from persistence list
21/11/26 20:02:02 INFO BlockRDD: Removing RDD 111 from persistence list
21/11/26 20:02:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[111] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937045000 ms
21/11/26 20:02:02 INFO ReceivedBlockTracker: Deleting batches: 1637937043000 ms
21/11/26 20:02:02 INFO InputInfoTracker: remove old batch metadata: 1637937043000 ms
21/11/26 20:02:02 INFO BlockManager: Removing RDD 112
21/11/26 20:02:02 INFO BlockManager: Removing RDD 111
21/11/26 20:02:02 INFO JobScheduler: Finished job streaming job 1637937046000 ms.0 from job set of time 1637937046000 ms
21/11/26 20:02:02 INFO JobScheduler: Total delay: 76.373 s for time 1637937046000 ms (execution: 0.038 s)
21/11/26 20:02:02 INFO JobScheduler: Starting job streaming job 1637937047000 ms.0 from job set of time 1637937047000 ms
21/11/26 20:02:02 INFO PythonRDD: Removing RDD 114 from persistence list
21/11/26 20:02:02 INFO BlockRDD: Removing RDD 113 from persistence list
21/11/26 20:02:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[113] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937046000 ms
21/11/26 20:02:02 INFO ReceivedBlockTracker: Deleting batches: 1637937044000 ms
21/11/26 20:02:02 INFO InputInfoTracker: remove old batch metadata: 1637937044000 ms
21/11/26 20:02:02 INFO BlockManager: Removing RDD 114
21/11/26 20:02:02 INFO BlockManager: Removing RDD 113
21/11/26 20:02:02 INFO JobScheduler: Finished job streaming job 1637937047000 ms.0 from job set of time 1637937047000 ms
21/11/26 20:02:02 INFO JobScheduler: Total delay: 75.426 s for time 1637937047000 ms (execution: 0.052 s)
21/11/26 20:02:02 INFO JobScheduler: Starting job streaming job 1637937048000 ms.0 from job set of time 1637937048000 ms
21/11/26 20:02:02 INFO PythonRDD: Removing RDD 118 from persistence list
21/11/26 20:02:02 INFO BlockManager: Removing RDD 118
21/11/26 20:02:02 INFO BlockRDD: Removing RDD 117 from persistence list
21/11/26 20:02:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[117] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937047000 ms
21/11/26 20:02:02 INFO ReceivedBlockTracker: Deleting batches: 1637937045000 ms
21/11/26 20:02:02 INFO InputInfoTracker: remove old batch metadata: 1637937045000 ms
21/11/26 20:02:02 INFO BlockManager: Removing RDD 117
21/11/26 20:02:02 INFO JobScheduler: Finished job streaming job 1637937048000 ms.0 from job set of time 1637937048000 ms
21/11/26 20:02:02 INFO JobScheduler: Total delay: 74.442 s for time 1637937048000 ms (execution: 0.015 s)
21/11/26 20:02:02 INFO JobScheduler: Starting job streaming job 1637937049000 ms.0 from job set of time 1637937049000 ms
21/11/26 20:02:02 INFO PythonRDD: Removing RDD 122 from persistence list
21/11/26 20:02:02 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:02:02 INFO BlockManager: Removing RDD 122
21/11/26 20:02:02 INFO DAGScheduler: Got job 57 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:02:02 INFO DAGScheduler: Final stage: ResultStage 65 (runJob at PythonRDD.scala:166)
21/11/26 20:02:02 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:02 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:02 INFO DAGScheduler: Submitting ResultStage 65 (PythonRDD[395] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:02 INFO BlockRDD: Removing RDD 121 from persistence list
21/11/26 20:02:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[121] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937048000 ms
21/11/26 20:02:02 INFO ReceivedBlockTracker: Deleting batches: 1637937046000 ms
21/11/26 20:02:02 INFO InputInfoTracker: remove old batch metadata: 1637937046000 ms
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 5.9 KiB, free 363.4 MiB)
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 363.4 MiB)
21/11/26 20:02:02 INFO BlockManager: Removing RDD 121
21/11/26 20:02:02 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 363.6 MiB)
21/11/26 20:02:02 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (PythonRDD[395] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:02 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
21/11/26 20:02:02 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 105) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:02 INFO Executor: Running task 0.0 in stage 65.0 (TID 105)
21/11/26 20:02:02 INFO BlockManager: Found block input-0-1637937047800 locally
21/11/26 20:02:02 INFO BlockManagerInfo: Removed broadcast_63_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.7 MiB)
21/11/26 20:02:02 INFO BlockManagerInfo: Removed broadcast_64_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 363.7 MiB)
21/11/26 20:02:02 INFO PythonRunner: Times: total = 33, boot = -311, init = 342, finish = 2
21/11/26 20:02:02 INFO PythonRunner: Times: total = 52, boot = 7, init = 42, finish = 3
21/11/26 20:02:02 INFO Executor: Finished task 0.0 in stage 65.0 (TID 105). 188084 bytes result sent to driver
21/11/26 20:02:02 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 105) in 64 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:02 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/11/26 20:02:02 INFO DAGScheduler: ResultStage 65 (runJob at PythonRDD.scala:166) finished in 0.081 s
21/11/26 20:02:02 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
21/11/26 20:02:02 INFO DAGScheduler: Job 57 finished: runJob at PythonRDD.scala:166, took 0.091339 s
21/11/26 20:02:02 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:02 INFO DAGScheduler: Got job 58 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:02:02 INFO DAGScheduler: Final stage: ResultStage 66 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:02 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:02 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:02 INFO DAGScheduler: Submitting ResultStage 66 (PythonRDD[126] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 4.6 KiB, free 363.6 MiB)
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 363.6 MiB)
21/11/26 20:02:02 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 363.7 MiB)
21/11/26 20:02:02 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (PythonRDD[126] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:02 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
21/11/26 20:02:02 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 106) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:02 INFO Executor: Running task 0.0 in stage 66.0 (TID 106)
21/11/26 20:02:02 INFO BlockManager: Found block input-0-1637937047800 locally
21/11/26 20:02:02 INFO PythonRunner: Times: total = 7, boot = -45, init = 51, finish = 1
21/11/26 20:02:02 INFO Executor: Finished task 0.0 in stage 66.0 (TID 106). 188041 bytes result sent to driver
21/11/26 20:02:02 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 106) in 13 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:02 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/11/26 20:02:02 INFO DAGScheduler: ResultStage 66 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.028 s
21/11/26 20:02:02 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/11/26 20:02:02 INFO DAGScheduler: Job 58 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.031512 s
21/11/26 20:02:02 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:02:02 INFO DAGScheduler: Registering RDD 403 (collect at StringIndexer.scala:204) as input to shuffle 8
21/11/26 20:02:02 INFO DAGScheduler: Got job 59 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:02:02 INFO DAGScheduler: Final stage: ResultStage 68 (collect at StringIndexer.scala:204)
21/11/26 20:02:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
21/11/26 20:02:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67)
21/11/26 20:02:02 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[403] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 20.3 KiB, free 363.6 MiB)
21/11/26 20:02:02 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 363.6 MiB)
21/11/26 20:02:02 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on pes2ug19cs012:38829 (size: 9.9 KiB, free: 363.7 MiB)
21/11/26 20:02:02 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[403] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:02 INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks resource profile 0
21/11/26 20:02:02 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 107) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 92538 bytes) taskResourceAssignments Map()
21/11/26 20:02:02 INFO Executor: Running task 0.0 in stage 67.0 (TID 107)
21/11/26 20:02:02 INFO PythonRunner: Times: total = 5, boot = -323, init = 328, finish = 0
21/11/26 20:02:02 INFO Executor: Finished task 0.0 in stage 67.0 (TID 107). 2271 bytes result sent to driver
21/11/26 20:02:02 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 108) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 95240 bytes) taskResourceAssignments Map()
21/11/26 20:02:02 INFO Executor: Running task 1.0 in stage 67.0 (TID 108)
21/11/26 20:02:02 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 107) in 38 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:02 INFO PythonRunner: Times: total = 3, boot = -17, init = 20, finish = 0
21/11/26 20:02:02 INFO Executor: Finished task 1.0 in stage 67.0 (TID 108). 2271 bytes result sent to driver
21/11/26 20:02:03 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 108) in 31 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:03 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
21/11/26 20:02:03 INFO MemoryStore: Block input-0-1637937122800 stored as values in memory (estimated size 209.3 KiB, free 363.4 MiB)
21/11/26 20:02:03 INFO BlockManagerInfo: Added input-0-1637937122800 in memory on pes2ug19cs012:38829 (size: 209.3 KiB, free: 363.5 MiB)
21/11/26 20:02:03 INFO DAGScheduler: ShuffleMapStage 67 (collect at StringIndexer.scala:204) finished in 0.078 s
21/11/26 20:02:03 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:02:03 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:02:03 INFO DAGScheduler: waiting: Set(ResultStage 68)
21/11/26 20:02:03 INFO DAGScheduler: failed: Set()
21/11/26 20:02:03 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:03 WARN BlockManager: Block input-0-1637937122800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:03 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[406] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:03 INFO BlockGenerator: Pushed block input-0-1637937122800
21/11/26 20:02:03 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 20.8 KiB, free 363.3 MiB)
21/11/26 20:02:03 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 363.3 MiB)
21/11/26 20:02:03 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 363.5 MiB)
21/11/26 20:02:03 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[406] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:03 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
21/11/26 20:02:03 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 109) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:02:03 INFO Executor: Running task 0.0 in stage 68.0 (TID 109)
21/11/26 20:02:03 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:02:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:02:03 INFO JobScheduler: Added jobs for time 1637937123000 ms
21/11/26 20:02:03 INFO Executor: Finished task 0.0 in stage 68.0 (TID 109). 3617 bytes result sent to driver
21/11/26 20:02:03 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 109) in 55 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:03 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
21/11/26 20:02:03 INFO DAGScheduler: ResultStage 68 (collect at StringIndexer.scala:204) finished in 0.065 s
21/11/26 20:02:03 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
21/11/26 20:02:03 INFO DAGScheduler: Job 59 finished: collect at StringIndexer.scala:204, took 0.150465 s
21/11/26 20:02:03 INFO CodeGenerator: Code generated in 26.651199 ms
21/11/26 20:02:03 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:03 INFO DAGScheduler: Got job 60 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:03 INFO DAGScheduler: Final stage: ResultStage 69 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:03 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:03 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:03 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[410] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:03 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 63.0 KiB, free 363.3 MiB)
21/11/26 20:02:03 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.2 MiB)
21/11/26 20:02:03 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.4 MiB)
21/11/26 20:02:03 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 69 (MapPartitionsRDD[410] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:03 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks resource profile 0
21/11/26 20:02:03 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 110) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 92549 bytes) taskResourceAssignments Map()
21/11/26 20:02:03 INFO Executor: Running task 0.0 in stage 69.0 (TID 110)
21/11/26 20:02:03 INFO PythonRunner: Times: total = 47, boot = -542, init = 544, finish = 45
21/11/26 20:02:03 INFO Executor: Finished task 0.0 in stage 69.0 (TID 110). 25990 bytes result sent to driver
21/11/26 20:02:03 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 111) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 95251 bytes) taskResourceAssignments Map()
21/11/26 20:02:03 INFO Executor: Running task 1.0 in stage 69.0 (TID 111)
21/11/26 20:02:03 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 110) in 131 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:03 INFO PythonRunner: Times: total = 2, boot = -73, init = 75, finish = 0
21/11/26 20:02:03 INFO Executor: Finished task 1.0 in stage 69.0 (TID 111). 19807 bytes result sent to driver
21/11/26 20:02:03 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 111) in 98 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:03 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
21/11/26 20:02:03 INFO DAGScheduler: ResultStage 69 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.237 s
21/11/26 20:02:03 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
21/11/26 20:02:03 INFO DAGScheduler: Job 60 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.242649 s
21/11/26 20:02:04 INFO JobScheduler: Added jobs for time 1637937124000 ms
21/11/26 20:02:05 INFO JobScheduler: Added jobs for time 1637937125000 ms
21/11/26 20:02:06 INFO JobScheduler: Added jobs for time 1637937126000 ms
21/11/26 20:02:07 INFO JobScheduler: Added jobs for time 1637937127000 ms
21/11/26 20:02:08 INFO MemoryStore: Block input-0-1637937127800 stored as values in memory (estimated size 138.6 KiB, free 363.1 MiB)
21/11/26 20:02:08 INFO BlockManagerInfo: Added input-0-1637937127800 in memory on pes2ug19cs012:38829 (size: 138.6 KiB, free: 363.3 MiB)
21/11/26 20:02:08 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:08 WARN BlockManager: Block input-0-1637937127800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:08 INFO BlockGenerator: Pushed block input-0-1637937127800
21/11/26 20:02:08 INFO JobScheduler: Added jobs for time 1637937128000 ms
21/11/26 20:02:08 INFO CodeGenerator: Code generated in 24.611383 ms
21/11/26 20:02:08 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:08 INFO DAGScheduler: Got job 61 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:08 INFO DAGScheduler: Final stage: ResultStage 70 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:08 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:08 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:08 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[422] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:08 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 57.2 KiB, free 363.1 MiB)
21/11/26 20:02:08 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.0 MiB)
21/11/26 20:02:08 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 363.3 MiB)
21/11/26 20:02:08 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 70 (MapPartitionsRDD[422] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:08 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks resource profile 0
21/11/26 20:02:08 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 112) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 92549 bytes) taskResourceAssignments Map()
21/11/26 20:02:08 INFO Executor: Running task 0.0 in stage 70.0 (TID 112)
21/11/26 20:02:08 INFO BlockManagerInfo: Removed broadcast_69_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.3 MiB)
21/11/26 20:02:08 INFO BlockManagerInfo: Removed broadcast_65_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 363.3 MiB)
21/11/26 20:02:08 INFO BlockManagerInfo: Removed broadcast_66_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 363.3 MiB)
21/11/26 20:02:08 INFO BlockManagerInfo: Removed broadcast_67_piece0 on pes2ug19cs012:38829 in memory (size: 9.9 KiB, free: 363.3 MiB)
21/11/26 20:02:08 INFO BlockManagerInfo: Removed broadcast_68_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 363.3 MiB)
21/11/26 20:02:08 INFO PythonRunner: Times: total = 2, boot = -4714, init = 4716, finish = 0
21/11/26 20:02:08 INFO Executor: Finished task 0.0 in stage 70.0 (TID 112). 2204 bytes result sent to driver
21/11/26 20:02:08 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 113) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 95251 bytes) taskResourceAssignments Map()
21/11/26 20:02:08 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 112) in 149 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:08 INFO Executor: Running task 1.0 in stage 70.0 (TID 113)
21/11/26 20:02:08 INFO PythonRunner: Times: total = 46, boot = -146, init = 147, finish = 45
21/11/26 20:02:08 INFO Executor: Finished task 1.0 in stage 70.0 (TID 113). 2162 bytes result sent to driver
21/11/26 20:02:08 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 113) in 149 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:08 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
21/11/26 20:02:08 INFO DAGScheduler: ResultStage 70 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.308 s
21/11/26 20:02:08 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
21/11/26 20:02:08 INFO DAGScheduler: Job 61 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.310747 s
21/11/26 20:02:08 INFO CodeGenerator: Code generated in 32.619354 ms
21/11/26 20:02:08 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:08 INFO DAGScheduler: Got job 62 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:08 INFO DAGScheduler: Final stage: ResultStage 71 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:08 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:08 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:08 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[424] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:08 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 63.0 KiB, free 363.1 MiB)
21/11/26 20:02:08 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.1 MiB)
21/11/26 20:02:08 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.3 MiB)
21/11/26 20:02:08 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 71 (MapPartitionsRDD[424] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:08 INFO TaskSchedulerImpl: Adding task set 71.0 with 2 tasks resource profile 0
21/11/26 20:02:08 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 114) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 92549 bytes) taskResourceAssignments Map()
21/11/26 20:02:08 INFO Executor: Running task 0.0 in stage 71.0 (TID 114)
21/11/26 20:02:08 INFO PythonRunner: Times: total = 2, boot = -188, init = 189, finish = 1
21/11/26 20:02:08 INFO Executor: Finished task 0.0 in stage 71.0 (TID 114). 8592 bytes result sent to driver
21/11/26 20:02:08 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 115) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 95251 bytes) taskResourceAssignments Map()
21/11/26 20:02:08 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 114) in 115 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:08 INFO Executor: Running task 1.0 in stage 71.0 (TID 115)
21/11/26 20:02:08 INFO PythonRunner: Times: total = 2, boot = -107, init = 109, finish = 0
21/11/26 20:02:08 INFO Executor: Finished task 1.0 in stage 71.0 (TID 115). 10750 bytes result sent to driver
21/11/26 20:02:08 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 115) in 99 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:08 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
21/11/26 20:02:08 INFO DAGScheduler: ResultStage 71 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.222 s
21/11/26 20:02:08 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
21/11/26 20:02:08 INFO DAGScheduler: Job 62 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.224605 s
21/11/26 20:02:09 INFO JobScheduler: Added jobs for time 1637937129000 ms
21/11/26 20:02:10 INFO JobScheduler: Added jobs for time 1637937130000 ms
21/11/26 20:02:11 INFO JobScheduler: Added jobs for time 1637937131000 ms
21/11/26 20:02:11 INFO CodeGenerator: Code generated in 44.58847 ms
21/11/26 20:02:11 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:11 INFO DAGScheduler: Got job 63 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:11 INFO DAGScheduler: Final stage: ResultStage 72 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:11 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:11 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:11 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[432] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:11 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 57.2 KiB, free 363.1 MiB)
21/11/26 20:02:11 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.0 MiB)
21/11/26 20:02:11 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 363.3 MiB)
21/11/26 20:02:11 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (MapPartitionsRDD[432] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:11 INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks resource profile 0
21/11/26 20:02:11 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 116) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 92549 bytes) taskResourceAssignments Map()
21/11/26 20:02:11 INFO Executor: Running task 0.0 in stage 72.0 (TID 116)
21/11/26 20:02:11 INFO BlockManagerInfo: Removed broadcast_70_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 363.3 MiB)
21/11/26 20:02:11 INFO BlockManagerInfo: Removed broadcast_71_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.3 MiB)
21/11/26 20:02:11 INFO PythonRunner: Times: total = 8, boot = -2495, init = 2502, finish = 1
21/11/26 20:02:11 INFO Executor: Finished task 0.0 in stage 72.0 (TID 116). 2203 bytes result sent to driver
21/11/26 20:02:11 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 117) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 95251 bytes) taskResourceAssignments Map()
21/11/26 20:02:11 INFO Executor: Running task 1.0 in stage 72.0 (TID 117)
21/11/26 20:02:11 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 116) in 329 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:11 INFO PythonRunner: Times: total = 5, boot = -301, init = 306, finish = 0
21/11/26 20:02:11 INFO Executor: Finished task 1.0 in stage 72.0 (TID 117). 2160 bytes result sent to driver
21/11/26 20:02:11 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 117) in 158 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:11 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
21/11/26 20:02:11 INFO DAGScheduler: ResultStage 72 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.500 s
21/11/26 20:02:11 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
21/11/26 20:02:11 INFO DAGScheduler: Job 63 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.505174 s
21/11/26 20:02:11 INFO JobScheduler: Finished job streaming job 1637937049000 ms.0 from job set of time 1637937049000 ms
21/11/26 20:02:11 INFO JobScheduler: Total delay: 82.929 s for time 1637937049000 ms (execution: 9.467 s)
21/11/26 20:02:11 INFO JobScheduler: Starting job streaming job 1637937050000 ms.0 from job set of time 1637937050000 ms
21/11/26 20:02:11 INFO PythonRDD: Removing RDD 124 from persistence list
21/11/26 20:02:11 INFO BlockRDD: Removing RDD 123 from persistence list
21/11/26 20:02:11 INFO BlockManager: Removing RDD 124
21/11/26 20:02:11 INFO BlockManager: Removing RDD 123
21/11/26 20:02:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[123] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937049000 ms
21/11/26 20:02:11 INFO ReceivedBlockTracker: Deleting batches: 1637937047000 ms
21/11/26 20:02:11 INFO InputInfoTracker: remove old batch metadata: 1637937047000 ms
21/11/26 20:02:11 INFO JobScheduler: Finished job streaming job 1637937050000 ms.0 from job set of time 1637937050000 ms
21/11/26 20:02:11 INFO JobScheduler: Total delay: 81.956 s for time 1637937050000 ms (execution: 0.026 s)
21/11/26 20:02:11 INFO JobScheduler: Starting job streaming job 1637937051000 ms.0 from job set of time 1637937051000 ms
21/11/26 20:02:11 INFO PythonRDD: Removing RDD 126 from persistence list
21/11/26 20:02:11 INFO BlockManager: Removing RDD 126
21/11/26 20:02:11 INFO BlockRDD: Removing RDD 125 from persistence list
21/11/26 20:02:11 INFO BlockManager: Removing RDD 125
21/11/26 20:02:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[125] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937050000 ms
21/11/26 20:02:11 INFO ReceivedBlockTracker: Deleting batches: 1637937048000 ms
21/11/26 20:02:11 INFO InputInfoTracker: remove old batch metadata: 1637937048000 ms
21/11/26 20:02:11 INFO BlockManagerInfo: Removed input-0-1637937047800 on pes2ug19cs012:38829 in memory (size: 181.5 KiB, free: 363.5 MiB)
21/11/26 20:02:11 INFO JobScheduler: Finished job streaming job 1637937051000 ms.0 from job set of time 1637937051000 ms
21/11/26 20:02:11 INFO JobScheduler: Total delay: 80.984 s for time 1637937051000 ms (execution: 0.028 s)
21/11/26 20:02:11 INFO JobScheduler: Starting job streaming job 1637937052000 ms.0 from job set of time 1637937052000 ms
21/11/26 20:02:11 INFO PythonRDD: Removing RDD 130 from persistence list
21/11/26 20:02:11 INFO BlockManager: Removing RDD 130
21/11/26 20:02:11 INFO BlockRDD: Removing RDD 129 from persistence list
21/11/26 20:02:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[129] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937051000 ms
21/11/26 20:02:11 INFO BlockManager: Removing RDD 129
21/11/26 20:02:11 INFO ReceivedBlockTracker: Deleting batches: 1637937049000 ms
21/11/26 20:02:11 INFO InputInfoTracker: remove old batch metadata: 1637937049000 ms
21/11/26 20:02:12 INFO JobScheduler: Finished job streaming job 1637937052000 ms.0 from job set of time 1637937052000 ms
21/11/26 20:02:12 INFO JobScheduler: Total delay: 80.026 s for time 1637937052000 ms (execution: 0.042 s)
21/11/26 20:02:12 INFO JobScheduler: Starting job streaming job 1637937053000 ms.0 from job set of time 1637937053000 ms
21/11/26 20:02:12 INFO JobScheduler: Finished job streaming job 1637937053000 ms.0 from job set of time 1637937053000 ms
21/11/26 20:02:12 INFO JobScheduler: Total delay: 79.062 s for time 1637937053000 ms (execution: 0.035 s)
21/11/26 20:02:12 INFO JobScheduler: Starting job streaming job 1637937054000 ms.0 from job set of time 1637937054000 ms
21/11/26 20:02:12 INFO JobScheduler: Added jobs for time 1637937132000 ms
21/11/26 20:02:12 INFO PythonRDD: Removing RDD 133 from persistence list
21/11/26 20:02:12 INFO BlockRDD: Removing RDD 132 from persistence list
21/11/26 20:02:12 INFO BlockManager: Removing RDD 133
21/11/26 20:02:12 INFO BlockManager: Removing RDD 132
21/11/26 20:02:12 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[132] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937052000 ms
21/11/26 20:02:12 INFO ReceivedBlockTracker: Deleting batches: 1637937050000 ms
21/11/26 20:02:12 INFO InputInfoTracker: remove old batch metadata: 1637937050000 ms
21/11/26 20:02:12 INFO PythonRDD: Removing RDD 146 from persistence list
21/11/26 20:02:12 INFO BlockRDD: Removing RDD 145 from persistence list
21/11/26 20:02:12 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[145] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937053000 ms
21/11/26 20:02:12 INFO ReceivedBlockTracker: Deleting batches: 1637937051000 ms
21/11/26 20:02:12 INFO BlockManager: Removing RDD 146
21/11/26 20:02:12 INFO BlockManager: Removing RDD 145
21/11/26 20:02:12 INFO InputInfoTracker: remove old batch metadata: 1637937051000 ms
21/11/26 20:02:12 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:02:12 INFO DAGScheduler: Got job 64 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:02:12 INFO DAGScheduler: Final stage: ResultStage 73 (runJob at PythonRDD.scala:166)
21/11/26 20:02:12 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:12 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:12 INFO DAGScheduler: Submitting ResultStage 73 (PythonRDD[435] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:12 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 5.9 KiB, free 363.4 MiB)
21/11/26 20:02:12 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 363.4 MiB)
21/11/26 20:02:12 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 363.5 MiB)
21/11/26 20:02:12 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (PythonRDD[435] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:12 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
21/11/26 20:02:12 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 118) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:12 INFO Executor: Running task 0.0 in stage 73.0 (TID 118)
21/11/26 20:02:12 INFO BlockManager: Found block input-0-1637937052800 locally
21/11/26 20:02:12 INFO PythonRunner: Times: total = 14, boot = -400, init = 413, finish = 1
21/11/26 20:02:12 INFO PythonRunner: Times: total = 27, boot = 17, init = 7, finish = 3
21/11/26 20:02:12 INFO Executor: Finished task 0.0 in stage 73.0 (TID 118). 172782 bytes result sent to driver
21/11/26 20:02:12 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 118) in 44 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:12 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
21/11/26 20:02:12 INFO DAGScheduler: ResultStage 73 (runJob at PythonRDD.scala:166) finished in 0.059 s
21/11/26 20:02:12 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
21/11/26 20:02:12 INFO DAGScheduler: Job 64 finished: runJob at PythonRDD.scala:166, took 0.068920 s
21/11/26 20:02:12 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:12 INFO DAGScheduler: Got job 65 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:02:12 INFO DAGScheduler: Final stage: ResultStage 74 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:12 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:12 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:12 INFO DAGScheduler: Submitting ResultStage 74 (PythonRDD[152] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:12 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 4.6 KiB, free 363.4 MiB)
21/11/26 20:02:12 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 363.4 MiB)
21/11/26 20:02:12 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 363.5 MiB)
21/11/26 20:02:12 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (PythonRDD[152] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:12 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
21/11/26 20:02:12 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 119) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:12 INFO Executor: Running task 0.0 in stage 74.0 (TID 119)
21/11/26 20:02:12 INFO BlockManager: Found block input-0-1637937052800 locally
21/11/26 20:02:12 INFO PythonRunner: Times: total = 12, boot = -62, init = 72, finish = 2
21/11/26 20:02:12 INFO Executor: Finished task 0.0 in stage 74.0 (TID 119). 172825 bytes result sent to driver
21/11/26 20:02:12 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 119) in 25 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:12 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
21/11/26 20:02:12 INFO DAGScheduler: ResultStage 74 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.039 s
21/11/26 20:02:12 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
21/11/26 20:02:12 INFO DAGScheduler: Job 65 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.044552 s
21/11/26 20:02:12 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:02:12 INFO DAGScheduler: Registering RDD 443 (collect at StringIndexer.scala:204) as input to shuffle 9
21/11/26 20:02:12 INFO DAGScheduler: Got job 66 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:02:12 INFO DAGScheduler: Final stage: ResultStage 76 (collect at StringIndexer.scala:204)
21/11/26 20:02:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
21/11/26 20:02:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 75)
21/11/26 20:02:12 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[443] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:12 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 20.3 KiB, free 363.3 MiB)
21/11/26 20:02:12 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 363.3 MiB)
21/11/26 20:02:12 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on pes2ug19cs012:38829 (size: 9.9 KiB, free: 363.5 MiB)
21/11/26 20:02:12 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[443] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:12 INFO TaskSchedulerImpl: Adding task set 75.0 with 2 tasks resource profile 0
21/11/26 20:02:12 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 120) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 94628 bytes) taskResourceAssignments Map()
21/11/26 20:02:12 INFO Executor: Running task 0.0 in stage 75.0 (TID 120)
21/11/26 20:02:12 INFO PythonRunner: Times: total = 5, boot = -578, init = 582, finish = 1
21/11/26 20:02:12 INFO Executor: Finished task 0.0 in stage 75.0 (TID 120). 2271 bytes result sent to driver
21/11/26 20:02:12 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 121) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78554 bytes) taskResourceAssignments Map()
21/11/26 20:02:12 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 120) in 67 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:12 INFO Executor: Running task 1.0 in stage 75.0 (TID 121)
21/11/26 20:02:12 INFO PythonRunner: Times: total = 9, boot = -27, init = 35, finish = 1
21/11/26 20:02:13 INFO MemoryStore: Block input-0-1637937132800 stored as values in memory (estimated size 193.3 KiB, free 363.1 MiB)
21/11/26 20:02:13 INFO BlockManagerInfo: Added input-0-1637937132800 in memory on pes2ug19cs012:38829 (size: 193.3 KiB, free: 363.3 MiB)
21/11/26 20:02:13 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:13 WARN BlockManager: Block input-0-1637937132800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:13 INFO BlockGenerator: Pushed block input-0-1637937132800
21/11/26 20:02:13 INFO Executor: Finished task 1.0 in stage 75.0 (TID 121). 2271 bytes result sent to driver
21/11/26 20:02:13 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 121) in 102 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:13 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
21/11/26 20:02:13 INFO DAGScheduler: ShuffleMapStage 75 (collect at StringIndexer.scala:204) finished in 0.183 s
21/11/26 20:02:13 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:02:13 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:02:13 INFO DAGScheduler: waiting: Set(ResultStage 76)
21/11/26 20:02:13 INFO DAGScheduler: failed: Set()
21/11/26 20:02:13 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[446] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:13 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 20.8 KiB, free 363.1 MiB)
21/11/26 20:02:13 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 363.1 MiB)
21/11/26 20:02:13 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 363.3 MiB)
21/11/26 20:02:13 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[446] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:13 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
21/11/26 20:02:13 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 122) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:02:13 INFO Executor: Running task 0.0 in stage 76.0 (TID 122)
21/11/26 20:02:13 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:02:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:02:13 INFO JobScheduler: Added jobs for time 1637937133000 ms
21/11/26 20:02:13 INFO Executor: Finished task 0.0 in stage 76.0 (TID 122). 3617 bytes result sent to driver
21/11/26 20:02:13 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 122) in 57 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:13 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
21/11/26 20:02:13 INFO DAGScheduler: ResultStage 76 (collect at StringIndexer.scala:204) finished in 0.121 s
21/11/26 20:02:13 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
21/11/26 20:02:13 INFO DAGScheduler: Job 66 finished: collect at StringIndexer.scala:204, took 0.328072 s
21/11/26 20:02:13 INFO CodeGenerator: Code generated in 42.251349 ms
21/11/26 20:02:13 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:13 INFO DAGScheduler: Got job 67 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:13 INFO DAGScheduler: Final stage: ResultStage 77 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:13 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:13 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:13 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[450] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:13 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 63.0 KiB, free 363.0 MiB)
21/11/26 20:02:13 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.0 MiB)
21/11/26 20:02:13 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.3 MiB)
21/11/26 20:02:13 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (MapPartitionsRDD[450] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:13 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks resource profile 0
21/11/26 20:02:13 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 123) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 94639 bytes) taskResourceAssignments Map()
21/11/26 20:02:13 INFO Executor: Running task 0.0 in stage 77.0 (TID 123)
21/11/26 20:02:13 INFO BlockManagerInfo: Removed broadcast_74_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 363.3 MiB)
21/11/26 20:02:13 INFO BlockManagerInfo: Removed broadcast_72_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 363.3 MiB)
21/11/26 20:02:13 INFO BlockManagerInfo: Removed broadcast_75_piece0 on pes2ug19cs012:38829 in memory (size: 9.9 KiB, free: 363.3 MiB)
21/11/26 20:02:13 INFO BlockManagerInfo: Removed broadcast_73_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 363.3 MiB)
21/11/26 20:02:13 INFO PythonRunner: Times: total = 3, boot = -700, init = 702, finish = 1
21/11/26 20:02:13 INFO BlockManagerInfo: Removed broadcast_76_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 363.3 MiB)
21/11/26 20:02:13 INFO Executor: Finished task 0.0 in stage 77.0 (TID 123). 24236 bytes result sent to driver
21/11/26 20:02:13 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 124) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78565 bytes) taskResourceAssignments Map()
21/11/26 20:02:13 INFO Executor: Running task 1.0 in stage 77.0 (TID 124)
21/11/26 20:02:13 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 123) in 192 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:14 INFO PythonRunner: Times: total = 2, boot = -174, init = 176, finish = 0
21/11/26 20:02:14 INFO JobScheduler: Added jobs for time 1637937134000 ms
21/11/26 20:02:14 INFO Executor: Finished task 1.0 in stage 77.0 (TID 124). 19227 bytes result sent to driver
21/11/26 20:02:14 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 124) in 260 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:14 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
21/11/26 20:02:14 INFO DAGScheduler: ResultStage 77 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.464 s
21/11/26 20:02:14 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
21/11/26 20:02:14 INFO DAGScheduler: Job 67 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.469713 s
21/11/26 20:02:15 INFO JobScheduler: Added jobs for time 1637937135000 ms
21/11/26 20:02:16 INFO JobScheduler: Added jobs for time 1637937136000 ms
21/11/26 20:02:17 INFO JobScheduler: Added jobs for time 1637937137000 ms
21/11/26 20:02:18 INFO MemoryStore: Block input-0-1637937137800 stored as values in memory (estimated size 130.6 KiB, free 363.0 MiB)
21/11/26 20:02:18 INFO BlockManagerInfo: Added input-0-1637937137800 in memory on pes2ug19cs012:38829 (size: 130.6 KiB, free: 363.2 MiB)
21/11/26 20:02:18 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:18 WARN BlockManager: Block input-0-1637937137800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:18 INFO BlockGenerator: Pushed block input-0-1637937137800
21/11/26 20:02:18 INFO JobScheduler: Added jobs for time 1637937138000 ms
21/11/26 20:02:18 INFO CodeGenerator: Code generated in 29.994423 ms
21/11/26 20:02:18 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:18 INFO DAGScheduler: Got job 68 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:18 INFO DAGScheduler: Final stage: ResultStage 78 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:18 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:18 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:18 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[462] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:18 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 57.2 KiB, free 363.0 MiB)
21/11/26 20:02:18 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 363.0 MiB)
21/11/26 20:02:18 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 363.2 MiB)
21/11/26 20:02:18 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 78 (MapPartitionsRDD[462] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:18 INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks resource profile 0
21/11/26 20:02:18 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 125) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 94639 bytes) taskResourceAssignments Map()
21/11/26 20:02:18 INFO Executor: Running task 0.0 in stage 78.0 (TID 125)
21/11/26 20:02:18 INFO PythonRunner: Times: total = 64, boot = -4742, init = 4761, finish = 45
21/11/26 20:02:18 INFO Executor: Finished task 0.0 in stage 78.0 (TID 125). 2161 bytes result sent to driver
21/11/26 20:02:18 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 126) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78565 bytes) taskResourceAssignments Map()
21/11/26 20:02:18 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 125) in 174 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:18 INFO Executor: Running task 1.0 in stage 78.0 (TID 126)
21/11/26 20:02:18 INFO PythonRunner: Times: total = 2, boot = -101, init = 103, finish = 0
21/11/26 20:02:18 INFO Executor: Finished task 1.0 in stage 78.0 (TID 126). 2161 bytes result sent to driver
21/11/26 20:02:18 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 126) in 90 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:18 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
21/11/26 20:02:18 INFO DAGScheduler: ResultStage 78 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.275 s
21/11/26 20:02:18 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
21/11/26 20:02:18 INFO DAGScheduler: Job 68 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.278241 s
21/11/26 20:02:18 INFO CodeGenerator: Code generated in 33.433708 ms
21/11/26 20:02:18 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:18 INFO DAGScheduler: Got job 69 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:18 INFO DAGScheduler: Final stage: ResultStage 79 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:18 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:18 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:18 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[464] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:18 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 63.0 KiB, free 362.9 MiB)
21/11/26 20:02:18 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 362.9 MiB)
21/11/26 20:02:18 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.1 MiB)
21/11/26 20:02:18 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (MapPartitionsRDD[464] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:18 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0
21/11/26 20:02:18 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 127) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 94639 bytes) taskResourceAssignments Map()
21/11/26 20:02:18 INFO Executor: Running task 0.0 in stage 79.0 (TID 127)
21/11/26 20:02:19 INFO JobScheduler: Added jobs for time 1637937139000 ms
21/11/26 20:02:19 INFO PythonRunner: Times: total = 2, boot = -179, init = 181, finish = 0
21/11/26 20:02:19 INFO Executor: Finished task 0.0 in stage 79.0 (TID 127). 17855 bytes result sent to driver
21/11/26 20:02:19 INFO BlockManagerInfo: Removed broadcast_77_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.2 MiB)
21/11/26 20:02:19 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 128) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78565 bytes) taskResourceAssignments Map()
21/11/26 20:02:19 INFO Executor: Running task 1.0 in stage 79.0 (TID 128)
21/11/26 20:02:19 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 127) in 156 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:19 INFO BlockManagerInfo: Removed broadcast_78_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 363.2 MiB)
21/11/26 20:02:19 INFO PythonRunner: Times: total = 55, boot = -148, init = 161, finish = 42
21/11/26 20:02:19 INFO Executor: Finished task 1.0 in stage 79.0 (TID 128). 10399 bytes result sent to driver
21/11/26 20:02:19 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 128) in 173 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:19 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
21/11/26 20:02:19 INFO DAGScheduler: ResultStage 79 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.330 s
21/11/26 20:02:19 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
21/11/26 20:02:19 INFO DAGScheduler: Job 69 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.333069 s
21/11/26 20:02:20 INFO JobScheduler: Added jobs for time 1637937140000 ms
21/11/26 20:02:21 INFO JobScheduler: Added jobs for time 1637937141000 ms
21/11/26 20:02:21 INFO CodeGenerator: Code generated in 29.341883 ms
21/11/26 20:02:21 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:21 INFO DAGScheduler: Got job 70 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:21 INFO DAGScheduler: Final stage: ResultStage 80 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:21 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:21 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:21 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[472] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:21 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 57.2 KiB, free 363.0 MiB)
21/11/26 20:02:21 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.0 MiB)
21/11/26 20:02:21 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on pes2ug19cs012:38829 (size: 23.0 KiB, free: 363.2 MiB)
21/11/26 20:02:21 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 80 (MapPartitionsRDD[472] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:21 INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks resource profile 0
21/11/26 20:02:21 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 129) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 94639 bytes) taskResourceAssignments Map()
21/11/26 20:02:21 INFO Executor: Running task 0.0 in stage 80.0 (TID 129)
21/11/26 20:02:21 INFO PythonRunner: Times: total = 15, boot = -2317, init = 2330, finish = 2
21/11/26 20:02:21 INFO Executor: Finished task 0.0 in stage 80.0 (TID 129). 2160 bytes result sent to driver
21/11/26 20:02:21 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 130) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 78565 bytes) taskResourceAssignments Map()
21/11/26 20:02:21 INFO Executor: Running task 1.0 in stage 80.0 (TID 130)
21/11/26 20:02:21 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 129) in 157 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:21 INFO PythonRunner: Times: total = 2, boot = -109, init = 111, finish = 0
21/11/26 20:02:21 INFO Executor: Finished task 1.0 in stage 80.0 (TID 130). 2160 bytes result sent to driver
21/11/26 20:02:21 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 130) in 110 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:21 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
21/11/26 20:02:21 INFO DAGScheduler: ResultStage 80 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.279 s
21/11/26 20:02:21 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished
21/11/26 20:02:21 INFO DAGScheduler: Job 70 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.286824 s
21/11/26 20:02:21 INFO JobScheduler: Finished job streaming job 1637937054000 ms.0 from job set of time 1637937054000 ms
21/11/26 20:02:21 INFO JobScheduler: Total delay: 87.829 s for time 1637937054000 ms (execution: 9.766 s)
21/11/26 20:02:21 INFO JobScheduler: Starting job streaming job 1637937055000 ms.0 from job set of time 1637937055000 ms
21/11/26 20:02:21 INFO PythonRDD: Removing RDD 150 from persistence list
21/11/26 20:02:21 INFO BlockRDD: Removing RDD 149 from persistence list
21/11/26 20:02:21 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[149] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937054000 ms
21/11/26 20:02:21 INFO BlockManager: Removing RDD 150
21/11/26 20:02:21 INFO ReceivedBlockTracker: Deleting batches: 1637937052000 ms
21/11/26 20:02:21 INFO InputInfoTracker: remove old batch metadata: 1637937052000 ms
21/11/26 20:02:21 INFO BlockManager: Removing RDD 149
21/11/26 20:02:21 INFO JobScheduler: Finished job streaming job 1637937055000 ms.0 from job set of time 1637937055000 ms
21/11/26 20:02:21 INFO JobScheduler: Total delay: 86.856 s for time 1637937055000 ms (execution: 0.027 s)
21/11/26 20:02:21 INFO JobScheduler: Starting job streaming job 1637937056000 ms.0 from job set of time 1637937056000 ms
21/11/26 20:02:21 INFO PythonRDD: Removing RDD 152 from persistence list
21/11/26 20:02:21 INFO BlockManager: Removing RDD 152
21/11/26 20:02:21 INFO BlockRDD: Removing RDD 151 from persistence list
21/11/26 20:02:21 INFO BlockManager: Removing RDD 151
21/11/26 20:02:21 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[151] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937055000 ms
21/11/26 20:02:21 INFO ReceivedBlockTracker: Deleting batches: 1637937053000 ms
21/11/26 20:02:21 INFO InputInfoTracker: remove old batch metadata: 1637937053000 ms
21/11/26 20:02:21 INFO BlockManagerInfo: Removed input-0-1637937052800 on pes2ug19cs012:38829 in memory (size: 166.7 KiB, free: 363.3 MiB)
21/11/26 20:02:21 INFO JobScheduler: Finished job streaming job 1637937056000 ms.0 from job set of time 1637937056000 ms
21/11/26 20:02:21 INFO JobScheduler: Total delay: 85.872 s for time 1637937056000 ms (execution: 0.016 s)
21/11/26 20:02:21 INFO JobScheduler: Starting job streaming job 1637937057000 ms.0 from job set of time 1637937057000 ms
21/11/26 20:02:21 INFO PythonRDD: Removing RDD 154 from persistence list
21/11/26 20:02:21 INFO BlockManager: Removing RDD 154
21/11/26 20:02:21 INFO BlockRDD: Removing RDD 153 from persistence list
21/11/26 20:02:21 INFO BlockManager: Removing RDD 153
21/11/26 20:02:21 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[153] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937056000 ms
21/11/26 20:02:21 INFO ReceivedBlockTracker: Deleting batches: 1637937054000 ms
21/11/26 20:02:21 INFO InputInfoTracker: remove old batch metadata: 1637937054000 ms
21/11/26 20:02:21 INFO JobScheduler: Finished job streaming job 1637937057000 ms.0 from job set of time 1637937057000 ms
21/11/26 20:02:21 INFO JobScheduler: Total delay: 84.889 s for time 1637937057000 ms (execution: 0.017 s)
21/11/26 20:02:21 INFO JobScheduler: Starting job streaming job 1637937058000 ms.0 from job set of time 1637937058000 ms
21/11/26 20:02:21 INFO PythonRDD: Removing RDD 156 from persistence list
21/11/26 20:02:21 INFO BlockRDD: Removing RDD 155 from persistence list
21/11/26 20:02:21 INFO BlockManager: Removing RDD 156
21/11/26 20:02:21 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[155] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937057000 ms
21/11/26 20:02:21 INFO BlockManager: Removing RDD 155
21/11/26 20:02:21 INFO ReceivedBlockTracker: Deleting batches: 1637937055000 ms
21/11/26 20:02:21 INFO InputInfoTracker: remove old batch metadata: 1637937055000 ms
21/11/26 20:02:21 INFO JobScheduler: Finished job streaming job 1637937058000 ms.0 from job set of time 1637937058000 ms
21/11/26 20:02:21 INFO JobScheduler: Total delay: 83.922 s for time 1637937058000 ms (execution: 0.032 s)
21/11/26 20:02:21 INFO PythonRDD: Removing RDD 158 from persistence list
21/11/26 20:02:21 INFO JobScheduler: Starting job streaming job 1637937059000 ms.0 from job set of time 1637937059000 ms
21/11/26 20:02:21 INFO BlockManager: Removing RDD 158
21/11/26 20:02:21 INFO BlockRDD: Removing RDD 157 from persistence list
21/11/26 20:02:21 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[157] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937058000 ms
21/11/26 20:02:21 INFO ReceivedBlockTracker: Deleting batches: 1637937056000 ms
21/11/26 20:02:21 INFO InputInfoTracker: remove old batch metadata: 1637937056000 ms
21/11/26 20:02:21 INFO BlockManager: Removing RDD 157
21/11/26 20:02:21 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:02:21 INFO DAGScheduler: Got job 71 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:02:21 INFO DAGScheduler: Final stage: ResultStage 81 (runJob at PythonRDD.scala:166)
21/11/26 20:02:21 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:21 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:21 INFO DAGScheduler: Submitting ResultStage 81 (PythonRDD[473] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:21 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 5.9 KiB, free 363.1 MiB)
21/11/26 20:02:21 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 363.1 MiB)
21/11/26 20:02:21 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 363.3 MiB)
21/11/26 20:02:21 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (PythonRDD[473] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:21 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
21/11/26 20:02:21 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 131) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:21 INFO Executor: Running task 0.0 in stage 81.0 (TID 131)
21/11/26 20:02:21 INFO BlockManager: Found block input-0-1637937057800 locally
21/11/26 20:02:22 INFO PythonRunner: Times: total = 21, boot = -270, init = 291, finish = 0
21/11/26 20:02:22 INFO PythonRunner: Times: total = 70, boot = 63, init = 6, finish = 1
21/11/26 20:02:22 INFO Executor: Finished task 0.0 in stage 81.0 (TID 131). 159599 bytes result sent to driver
21/11/26 20:02:22 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 131) in 79 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:22 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
21/11/26 20:02:22 INFO DAGScheduler: ResultStage 81 (runJob at PythonRDD.scala:166) finished in 0.095 s
21/11/26 20:02:22 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
21/11/26 20:02:22 INFO DAGScheduler: Job 71 finished: runJob at PythonRDD.scala:166, took 0.105445 s
21/11/26 20:02:22 INFO JobScheduler: Added jobs for time 1637937142000 ms
21/11/26 20:02:22 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:22 INFO DAGScheduler: Got job 72 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:02:22 INFO DAGScheduler: Final stage: ResultStage 82 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:22 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:22 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:22 INFO DAGScheduler: Submitting ResultStage 82 (PythonRDD[162] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 4.6 KiB, free 363.1 MiB)
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 363.1 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 363.3 MiB)
21/11/26 20:02:22 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (PythonRDD[162] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:22 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
21/11/26 20:02:22 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 132) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:22 INFO Executor: Running task 0.0 in stage 82.0 (TID 132)
21/11/26 20:02:22 INFO BlockManager: Found block input-0-1637937057800 locally
21/11/26 20:02:22 INFO PythonRunner: Times: total = 5, boot = -86, init = 90, finish = 1
21/11/26 20:02:22 INFO Executor: Finished task 0.0 in stage 82.0 (TID 132). 159599 bytes result sent to driver
21/11/26 20:02:22 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 132) in 14 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:22 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
21/11/26 20:02:22 INFO DAGScheduler: ResultStage 82 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.030 s
21/11/26 20:02:22 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
21/11/26 20:02:22 INFO DAGScheduler: Job 72 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.036367 s
21/11/26 20:02:22 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:02:22 INFO DAGScheduler: Registering RDD 483 (collect at StringIndexer.scala:204) as input to shuffle 10
21/11/26 20:02:22 INFO DAGScheduler: Got job 73 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:02:22 INFO DAGScheduler: Final stage: ResultStage 84 (collect at StringIndexer.scala:204)
21/11/26 20:02:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
21/11/26 20:02:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 83)
21/11/26 20:02:22 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[483] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 20.3 KiB, free 363.1 MiB)
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 363.1 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on pes2ug19cs012:38829 (size: 9.9 KiB, free: 363.3 MiB)
21/11/26 20:02:22 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[483] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:22 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks resource profile 0
21/11/26 20:02:22 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 133) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75765 bytes) taskResourceAssignments Map()
21/11/26 20:02:22 INFO Executor: Running task 0.0 in stage 83.0 (TID 133)
21/11/26 20:02:22 INFO PythonRunner: Times: total = 2, boot = -411, init = 412, finish = 1
21/11/26 20:02:22 INFO Executor: Finished task 0.0 in stage 83.0 (TID 133). 2271 bytes result sent to driver
21/11/26 20:02:22 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 134) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84437 bytes) taskResourceAssignments Map()
21/11/26 20:02:22 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 133) in 21 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:22 INFO Executor: Running task 1.0 in stage 83.0 (TID 134)
21/11/26 20:02:22 INFO PythonRunner: Times: total = 2, boot = -10, init = 11, finish = 1
21/11/26 20:02:22 INFO Executor: Finished task 1.0 in stage 83.0 (TID 134). 2271 bytes result sent to driver
21/11/26 20:02:22 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 134) in 29 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:22 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
21/11/26 20:02:22 INFO DAGScheduler: ShuffleMapStage 83 (collect at StringIndexer.scala:204) finished in 0.062 s
21/11/26 20:02:22 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:02:22 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:02:22 INFO DAGScheduler: waiting: Set(ResultStage 84)
21/11/26 20:02:22 INFO DAGScheduler: failed: Set()
21/11/26 20:02:22 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[486] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 20.8 KiB, free 363.1 MiB)
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 363.1 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 363.3 MiB)
21/11/26 20:02:22 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[486] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:22 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
21/11/26 20:02:22 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 135) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:02:22 INFO Executor: Running task 0.0 in stage 84.0 (TID 135)
21/11/26 20:02:22 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:02:22 INFO Executor: Finished task 0.0 in stage 84.0 (TID 135). 3617 bytes result sent to driver
21/11/26 20:02:22 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 135) in 31 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:22 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
21/11/26 20:02:22 INFO DAGScheduler: ResultStage 84 (collect at StringIndexer.scala:204) finished in 0.045 s
21/11/26 20:02:22 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
21/11/26 20:02:22 INFO DAGScheduler: Job 73 finished: collect at StringIndexer.scala:204, took 0.112940 s
21/11/26 20:02:22 INFO BlockManagerInfo: Removed broadcast_79_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.3 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Removed broadcast_80_piece0 on pes2ug19cs012:38829 in memory (size: 23.0 KiB, free: 363.3 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Removed broadcast_82_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 363.4 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Removed broadcast_83_piece0 on pes2ug19cs012:38829 in memory (size: 9.9 KiB, free: 363.4 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Removed broadcast_84_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 363.4 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Removed broadcast_81_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 363.4 MiB)
21/11/26 20:02:22 INFO CodeGenerator: Code generated in 25.777125 ms
21/11/26 20:02:22 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:22 INFO DAGScheduler: Got job 74 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:22 INFO DAGScheduler: Final stage: ResultStage 85 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:22 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:22 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:22 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[488] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 63.0 KiB, free 363.2 MiB)
21/11/26 20:02:22 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 363.2 MiB)
21/11/26 20:02:22 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.4 MiB)
21/11/26 20:02:22 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (MapPartitionsRDD[488] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:22 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks resource profile 0
21/11/26 20:02:23 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 136) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75776 bytes) taskResourceAssignments Map()
21/11/26 20:02:23 INFO Executor: Running task 0.0 in stage 85.0 (TID 136)
21/11/26 20:02:23 INFO MemoryStore: Block input-0-1637937142800 stored as values in memory (estimated size 159.4 KiB, free 363.1 MiB)
21/11/26 20:02:23 INFO BlockManagerInfo: Added input-0-1637937142800 in memory on pes2ug19cs012:38829 (size: 159.4 KiB, free: 363.2 MiB)
21/11/26 20:02:23 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:23 WARN BlockManager: Block input-0-1637937142800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:23 INFO BlockGenerator: Pushed block input-0-1637937142800
21/11/26 20:02:23 INFO JobScheduler: Added jobs for time 1637937143000 ms
21/11/26 20:02:23 INFO PythonRunner: Times: total = 23, boot = -455, init = 477, finish = 1
21/11/26 20:02:23 INFO Executor: Finished task 0.0 in stage 85.0 (TID 136). 20397 bytes result sent to driver
21/11/26 20:02:23 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 137) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84448 bytes) taskResourceAssignments Map()
21/11/26 20:02:23 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 136) in 142 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:23 INFO Executor: Running task 1.0 in stage 85.0 (TID 137)
21/11/26 20:02:23 INFO PythonRunner: Times: total = 2, boot = -97, init = 99, finish = 0
21/11/26 20:02:23 INFO Executor: Finished task 1.0 in stage 85.0 (TID 137). 16291 bytes result sent to driver
21/11/26 20:02:23 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 137) in 102 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:23 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
21/11/26 20:02:23 INFO DAGScheduler: ResultStage 85 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.252 s
21/11/26 20:02:23 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
21/11/26 20:02:23 INFO DAGScheduler: Job 74 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.253879 s
21/11/26 20:02:24 INFO JobScheduler: Added jobs for time 1637937144000 ms
21/11/26 20:02:25 INFO JobScheduler: Added jobs for time 1637937145000 ms
21/11/26 20:02:26 INFO JobScheduler: Added jobs for time 1637937146000 ms
21/11/26 20:02:27 INFO JobScheduler: Added jobs for time 1637937147000 ms
21/11/26 20:02:27 INFO CodeGenerator: Code generated in 28.466751 ms
21/11/26 20:02:27 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:27 INFO DAGScheduler: Got job 75 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:27 INFO DAGScheduler: Final stage: ResultStage 86 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:27 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:27 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:27 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[500] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:27 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 57.2 KiB, free 363.0 MiB)
21/11/26 20:02:27 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 363.0 MiB)
21/11/26 20:02:27 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 363.2 MiB)
21/11/26 20:02:27 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 86 (MapPartitionsRDD[500] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:27 INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks resource profile 0
21/11/26 20:02:27 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 138) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75776 bytes) taskResourceAssignments Map()
21/11/26 20:02:27 INFO Executor: Running task 0.0 in stage 86.0 (TID 138)
21/11/26 20:02:28 INFO MemoryStore: Block input-0-1637937147800 stored as values in memory (estimated size 129.1 KiB, free 362.9 MiB)
21/11/26 20:02:28 INFO BlockManagerInfo: Added input-0-1637937147800 in memory on pes2ug19cs012:38829 (size: 129.1 KiB, free: 363.0 MiB)
21/11/26 20:02:28 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:28 WARN BlockManager: Block input-0-1637937147800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:28 INFO BlockGenerator: Pushed block input-0-1637937147800
21/11/26 20:02:28 INFO JobScheduler: Added jobs for time 1637937148000 ms
21/11/26 20:02:28 INFO PythonRunner: Times: total = 43, boot = -4824, init = 4826, finish = 41
21/11/26 20:02:28 INFO Executor: Finished task 0.0 in stage 86.0 (TID 138). 2161 bytes result sent to driver
21/11/26 20:02:28 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 139) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84448 bytes) taskResourceAssignments Map()
21/11/26 20:02:28 INFO Executor: Running task 1.0 in stage 86.0 (TID 139)
21/11/26 20:02:28 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 138) in 204 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:28 INFO PythonRunner: Times: total = 3, boot = -148, init = 151, finish = 0
21/11/26 20:02:28 INFO Executor: Finished task 1.0 in stage 86.0 (TID 139). 2161 bytes result sent to driver
21/11/26 20:02:28 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 139) in 139 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:28 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
21/11/26 20:02:28 INFO DAGScheduler: ResultStage 86 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.354 s
21/11/26 20:02:28 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
21/11/26 20:02:28 INFO DAGScheduler: Job 75 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.358023 s
21/11/26 20:02:28 INFO CodeGenerator: Code generated in 40.550399 ms
21/11/26 20:02:28 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:28 INFO DAGScheduler: Got job 76 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:28 INFO DAGScheduler: Final stage: ResultStage 87 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:28 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:28 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:28 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[504] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:28 INFO BlockManagerInfo: Removed broadcast_85_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.1 MiB)
21/11/26 20:02:28 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 63.0 KiB, free 362.9 MiB)
21/11/26 20:02:28 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 362.9 MiB)
21/11/26 20:02:28 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.0 MiB)
21/11/26 20:02:28 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 87 (MapPartitionsRDD[504] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:28 INFO TaskSchedulerImpl: Adding task set 87.0 with 2 tasks resource profile 0
21/11/26 20:02:28 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 140) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75776 bytes) taskResourceAssignments Map()
21/11/26 20:02:28 INFO BlockManagerInfo: Removed broadcast_86_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 363.1 MiB)
21/11/26 20:02:28 INFO Executor: Running task 0.0 in stage 87.0 (TID 140)
21/11/26 20:02:28 INFO PythonRunner: Times: total = 18, boot = -325, init = 343, finish = 0
21/11/26 20:02:28 INFO Executor: Finished task 0.0 in stage 87.0 (TID 140). 11764 bytes result sent to driver
21/11/26 20:02:28 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 141) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84448 bytes) taskResourceAssignments Map()
21/11/26 20:02:28 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 140) in 210 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:28 INFO Executor: Running task 1.0 in stage 87.0 (TID 141)
21/11/26 20:02:28 INFO PythonRunner: Times: total = 3, boot = -179, init = 182, finish = 0
21/11/26 20:02:28 INFO Executor: Finished task 1.0 in stage 87.0 (TID 141). 14870 bytes result sent to driver
21/11/26 20:02:28 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 141) in 212 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:28 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
21/11/26 20:02:28 INFO DAGScheduler: ResultStage 87 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.452 s
21/11/26 20:02:28 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
21/11/26 20:02:28 INFO DAGScheduler: Job 76 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.455346 s
21/11/26 20:02:29 INFO JobScheduler: Added jobs for time 1637937149000 ms
21/11/26 20:02:30 INFO JobScheduler: Added jobs for time 1637937150000 ms
21/11/26 20:02:31 INFO JobScheduler: Added jobs for time 1637937151000 ms
21/11/26 20:02:32 INFO JobScheduler: Added jobs for time 1637937152000 ms
21/11/26 20:02:32 INFO CodeGenerator: Code generated in 40.982986 ms
21/11/26 20:02:32 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:32 INFO DAGScheduler: Got job 77 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:32 INFO DAGScheduler: Final stage: ResultStage 88 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:32 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:32 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:32 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[514] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:32 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 57.2 KiB, free 362.9 MiB)
21/11/26 20:02:32 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 362.9 MiB)
21/11/26 20:02:32 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 363.0 MiB)
21/11/26 20:02:32 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 88 (MapPartitionsRDD[514] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:32 INFO TaskSchedulerImpl: Adding task set 88.0 with 2 tasks resource profile 0
21/11/26 20:02:32 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 142) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 75776 bytes) taskResourceAssignments Map()
21/11/26 20:02:32 INFO Executor: Running task 0.0 in stage 88.0 (TID 142)
21/11/26 20:02:33 INFO MemoryStore: Block input-0-1637937152800 stored as values in memory (estimated size 147.8 KiB, free 362.7 MiB)
21/11/26 20:02:33 INFO BlockManagerInfo: Added input-0-1637937152800 in memory on pes2ug19cs012:38829 (size: 147.8 KiB, free: 362.9 MiB)
21/11/26 20:02:33 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:33 WARN BlockManager: Block input-0-1637937152800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:33 INFO BlockGenerator: Pushed block input-0-1637937152800
21/11/26 20:02:33 INFO JobScheduler: Added jobs for time 1637937153000 ms
21/11/26 20:02:33 INFO PythonRunner: Times: total = 20, boot = -4248, init = 4268, finish = 0
21/11/26 20:02:33 INFO Executor: Finished task 0.0 in stage 88.0 (TID 142). 2160 bytes result sent to driver
21/11/26 20:02:33 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 143) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 84448 bytes) taskResourceAssignments Map()
21/11/26 20:02:33 INFO Executor: Running task 1.0 in stage 88.0 (TID 143)
21/11/26 20:02:33 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 142) in 180 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:33 INFO PythonRunner: Times: total = 44, boot = -127, init = 129, finish = 42
21/11/26 20:02:33 INFO Executor: Finished task 1.0 in stage 88.0 (TID 143). 2160 bytes result sent to driver
21/11/26 20:02:33 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 143) in 202 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:33 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
21/11/26 20:02:33 INFO DAGScheduler: ResultStage 88 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.407 s
21/11/26 20:02:33 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
21/11/26 20:02:33 INFO DAGScheduler: Job 77 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.413061 s
21/11/26 20:02:33 INFO JobScheduler: Finished job streaming job 1637937059000 ms.0 from job set of time 1637937059000 ms
21/11/26 20:02:33 INFO JobScheduler: Total delay: 94.409 s for time 1637937059000 ms (execution: 11.486 s)
21/11/26 20:02:33 INFO PythonRDD: Removing RDD 160 from persistence list
21/11/26 20:02:33 INFO JobScheduler: Starting job streaming job 1637937060000 ms.0 from job set of time 1637937060000 ms
21/11/26 20:02:33 INFO BlockRDD: Removing RDD 159 from persistence list
21/11/26 20:02:33 INFO BlockManager: Removing RDD 159
21/11/26 20:02:33 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[159] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937059000 ms
21/11/26 20:02:33 INFO ReceivedBlockTracker: Deleting batches: 1637937057000 ms
21/11/26 20:02:33 INFO BlockManager: Removing RDD 160
21/11/26 20:02:33 INFO InputInfoTracker: remove old batch metadata: 1637937057000 ms
21/11/26 20:02:33 INFO JobScheduler: Finished job streaming job 1637937060000 ms.0 from job set of time 1637937060000 ms
21/11/26 20:02:33 INFO JobScheduler: Total delay: 93.438 s for time 1637937060000 ms (execution: 0.028 s)
21/11/26 20:02:33 INFO PythonRDD: Removing RDD 162 from persistence list
21/11/26 20:02:33 INFO JobScheduler: Starting job streaming job 1637937061000 ms.0 from job set of time 1637937061000 ms
21/11/26 20:02:33 INFO BlockRDD: Removing RDD 161 from persistence list
21/11/26 20:02:33 INFO BlockManager: Removing RDD 162
21/11/26 20:02:33 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[161] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937060000 ms
21/11/26 20:02:33 INFO BlockManager: Removing RDD 161
21/11/26 20:02:33 INFO ReceivedBlockTracker: Deleting batches: 1637937058000 ms
21/11/26 20:02:33 INFO InputInfoTracker: remove old batch metadata: 1637937058000 ms
21/11/26 20:02:33 INFO BlockManagerInfo: Removed input-0-1637937057800 on pes2ug19cs012:38829 in memory (size: 153.8 KiB, free: 363.1 MiB)
21/11/26 20:02:33 INFO JobScheduler: Finished job streaming job 1637937061000 ms.0 from job set of time 1637937061000 ms
21/11/26 20:02:33 INFO PythonRDD: Removing RDD 166 from persistence list
21/11/26 20:02:33 INFO JobScheduler: Total delay: 92.466 s for time 1637937061000 ms (execution: 0.026 s)
21/11/26 20:02:33 INFO JobScheduler: Starting job streaming job 1637937062000 ms.0 from job set of time 1637937062000 ms
21/11/26 20:02:33 INFO BlockManager: Removing RDD 166
21/11/26 20:02:33 INFO BlockRDD: Removing RDD 165 from persistence list
21/11/26 20:02:33 INFO BlockManager: Removing RDD 165
21/11/26 20:02:33 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[165] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937061000 ms
21/11/26 20:02:33 INFO ReceivedBlockTracker: Deleting batches: 1637937059000 ms
21/11/26 20:02:33 INFO InputInfoTracker: remove old batch metadata: 1637937059000 ms
21/11/26 20:02:33 INFO JobScheduler: Finished job streaming job 1637937062000 ms.0 from job set of time 1637937062000 ms
21/11/26 20:02:33 INFO JobScheduler: Total delay: 91.523 s for time 1637937062000 ms (execution: 0.055 s)
21/11/26 20:02:33 INFO PythonRDD: Removing RDD 170 from persistence list
21/11/26 20:02:33 INFO JobScheduler: Starting job streaming job 1637937063000 ms.0 from job set of time 1637937063000 ms
21/11/26 20:02:33 INFO BlockRDD: Removing RDD 169 from persistence list
21/11/26 20:02:33 INFO BlockManager: Removing RDD 170
21/11/26 20:02:33 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[169] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937062000 ms
21/11/26 20:02:33 INFO ReceivedBlockTracker: Deleting batches: 1637937060000 ms
21/11/26 20:02:33 INFO InputInfoTracker: remove old batch metadata: 1637937060000 ms
21/11/26 20:02:33 INFO BlockManager: Removing RDD 169
21/11/26 20:02:33 INFO JobScheduler: Finished job streaming job 1637937063000 ms.0 from job set of time 1637937063000 ms
21/11/26 20:02:33 INFO JobScheduler: Total delay: 90.556 s for time 1637937063000 ms (execution: 0.031 s)
21/11/26 20:02:33 INFO JobScheduler: Starting job streaming job 1637937064000 ms.0 from job set of time 1637937064000 ms
21/11/26 20:02:33 INFO PythonRDD: Removing RDD 172 from persistence list
21/11/26 20:02:33 INFO BlockManager: Removing RDD 172
21/11/26 20:02:33 INFO BlockRDD: Removing RDD 171 from persistence list
21/11/26 20:02:33 INFO BlockManager: Removing RDD 171
21/11/26 20:02:33 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[171] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1637937063000 ms
21/11/26 20:02:33 INFO ReceivedBlockTracker: Deleting batches: 1637937061000 ms
21/11/26 20:02:33 INFO InputInfoTracker: remove old batch metadata: 1637937061000 ms
21/11/26 20:02:33 INFO SparkContext: Starting job: runJob at PythonRDD.scala:166
21/11/26 20:02:33 INFO DAGScheduler: Got job 78 (runJob at PythonRDD.scala:166) with 1 output partitions
21/11/26 20:02:33 INFO DAGScheduler: Final stage: ResultStage 89 (runJob at PythonRDD.scala:166)
21/11/26 20:02:33 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:33 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:33 INFO DAGScheduler: Submitting ResultStage 89 (PythonRDD[517] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:33 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 5.9 KiB, free 362.9 MiB)
21/11/26 20:02:33 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 362.8 MiB)
21/11/26 20:02:33 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on pes2ug19cs012:38829 (size: 3.6 KiB, free: 363.1 MiB)
21/11/26 20:02:33 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (PythonRDD[517] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:33 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
21/11/26 20:02:33 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 144) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:33 INFO Executor: Running task 0.0 in stage 89.0 (TID 144)
21/11/26 20:02:33 INFO BlockManager: Found block input-0-1637937062800 locally
21/11/26 20:02:33 INFO PythonRunner: Times: total = 13, boot = -409, init = 421, finish = 1
21/11/26 20:02:33 INFO PythonRunner: Times: total = 30, boot = 18, init = 10, finish = 2
21/11/26 20:02:33 INFO Executor: Finished task 0.0 in stage 89.0 (TID 144). 182574 bytes result sent to driver
21/11/26 20:02:33 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 144) in 48 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:33 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
21/11/26 20:02:33 INFO DAGScheduler: ResultStage 89 (runJob at PythonRDD.scala:166) finished in 0.060 s
21/11/26 20:02:33 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
21/11/26 20:02:33 INFO DAGScheduler: Job 78 finished: runJob at PythonRDD.scala:166, took 0.067358 s
21/11/26 20:02:33 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:33 INFO DAGScheduler: Got job 79 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/11/26 20:02:33 INFO DAGScheduler: Final stage: ResultStage 90 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:33 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:33 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:33 INFO DAGScheduler: Submitting ResultStage 90 (PythonRDD[190] at RDD at PythonRDD.scala:53), which has no missing parents
21/11/26 20:02:33 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 4.6 KiB, free 362.8 MiB)
21/11/26 20:02:33 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 362.8 MiB)
21/11/26 20:02:33 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on pes2ug19cs012:38829 (size: 3.1 KiB, free: 363.0 MiB)
21/11/26 20:02:33 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (PythonRDD[190] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:33 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
21/11/26 20:02:33 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 145) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/11/26 20:02:33 INFO Executor: Running task 0.0 in stage 90.0 (TID 145)
21/11/26 20:02:33 INFO BlockManager: Found block input-0-1637937062800 locally
21/11/26 20:02:33 INFO PythonRunner: Times: total = 26, boot = -60, init = 85, finish = 1
21/11/26 20:02:33 INFO Executor: Finished task 0.0 in stage 90.0 (TID 145). 182574 bytes result sent to driver
21/11/26 20:02:33 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 145) in 44 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:33 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
21/11/26 20:02:33 INFO DAGScheduler: ResultStage 90 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.053 s
21/11/26 20:02:33 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
21/11/26 20:02:33 INFO DAGScheduler: Job 79 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.056829 s
21/11/26 20:02:33 INFO BlockManagerInfo: Removed broadcast_87_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 363.1 MiB)
21/11/26 20:02:33 INFO BlockManagerInfo: Removed broadcast_88_piece0 on pes2ug19cs012:38829 in memory (size: 22.9 KiB, free: 363.1 MiB)
21/11/26 20:02:33 INFO BlockManagerInfo: Removed broadcast_90_piece0 on pes2ug19cs012:38829 in memory (size: 3.1 KiB, free: 363.1 MiB)
21/11/26 20:02:33 INFO BlockManagerInfo: Removed broadcast_89_piece0 on pes2ug19cs012:38829 in memory (size: 3.6 KiB, free: 363.1 MiB)
21/11/26 20:02:34 INFO JobScheduler: Added jobs for time 1637937154000 ms
21/11/26 20:02:34 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
21/11/26 20:02:34 INFO DAGScheduler: Registering RDD 527 (collect at StringIndexer.scala:204) as input to shuffle 11
21/11/26 20:02:34 INFO DAGScheduler: Got job 80 (collect at StringIndexer.scala:204) with 1 output partitions
21/11/26 20:02:34 INFO DAGScheduler: Final stage: ResultStage 92 (collect at StringIndexer.scala:204)
21/11/26 20:02:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
21/11/26 20:02:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
21/11/26 20:02:34 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[527] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:34 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 20.3 KiB, free 363.0 MiB)
21/11/26 20:02:34 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 363.0 MiB)
21/11/26 20:02:34 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on pes2ug19cs012:38829 (size: 10.0 KiB, free: 363.1 MiB)
21/11/26 20:02:34 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[527] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:34 INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks resource profile 0
21/11/26 20:02:34 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 146) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 102628 bytes) taskResourceAssignments Map()
21/11/26 20:02:34 INFO Executor: Running task 0.0 in stage 91.0 (TID 146)
21/11/26 20:02:34 INFO PythonRunner: Times: total = 2, boot = -443, init = 445, finish = 0
21/11/26 20:02:34 INFO Executor: Finished task 0.0 in stage 91.0 (TID 146). 2271 bytes result sent to driver
21/11/26 20:02:34 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 147) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79975 bytes) taskResourceAssignments Map()
21/11/26 20:02:34 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 146) in 37 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:34 INFO Executor: Running task 1.0 in stage 91.0 (TID 147)
21/11/26 20:02:34 INFO PythonRunner: Times: total = 2, boot = -18, init = 19, finish = 1
21/11/26 20:02:34 INFO Executor: Finished task 1.0 in stage 91.0 (TID 147). 2271 bytes result sent to driver
21/11/26 20:02:34 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 147) in 28 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:34 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
21/11/26 20:02:34 INFO DAGScheduler: ShuffleMapStage 91 (collect at StringIndexer.scala:204) finished in 0.080 s
21/11/26 20:02:34 INFO DAGScheduler: looking for newly runnable stages
21/11/26 20:02:34 INFO DAGScheduler: running: Set(ResultStage 0)
21/11/26 20:02:34 INFO DAGScheduler: waiting: Set(ResultStage 92)
21/11/26 20:02:34 INFO DAGScheduler: failed: Set()
21/11/26 20:02:34 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[530] at collect at StringIndexer.scala:204), which has no missing parents
21/11/26 20:02:34 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 20.8 KiB, free 363.0 MiB)
21/11/26 20:02:34 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 363.0 MiB)
21/11/26 20:02:34 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on pes2ug19cs012:38829 (size: 10.3 KiB, free: 363.1 MiB)
21/11/26 20:02:34 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[530] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
21/11/26 20:02:34 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0
21/11/26 20:02:34 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 148) (pes2ug19cs012, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/11/26 20:02:34 INFO Executor: Running task 0.0 in stage 92.0 (TID 148)
21/11/26 20:02:34 INFO ShuffleBlockFetcherIterator: Getting 2 (1078.0 B) non-empty blocks including 2 (1078.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/11/26 20:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/11/26 20:02:34 INFO Executor: Finished task 0.0 in stage 92.0 (TID 148). 3617 bytes result sent to driver
21/11/26 20:02:34 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 148) in 27 ms on pes2ug19cs012 (executor driver) (1/1)
21/11/26 20:02:34 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
21/11/26 20:02:34 INFO DAGScheduler: ResultStage 92 (collect at StringIndexer.scala:204) finished in 0.036 s
21/11/26 20:02:34 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
21/11/26 20:02:34 INFO DAGScheduler: Job 80 finished: collect at StringIndexer.scala:204, took 0.122168 s
21/11/26 20:02:34 INFO CodeGenerator: Code generated in 27.516043 ms
21/11/26 20:02:34 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:34 INFO DAGScheduler: Got job 81 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:34 INFO DAGScheduler: Final stage: ResultStage 93 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:34 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:34 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:34 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[532] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:34 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 63.0 KiB, free 362.9 MiB)
21/11/26 20:02:34 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 362.9 MiB)
21/11/26 20:02:34 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 363.1 MiB)
21/11/26 20:02:34 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 93 (MapPartitionsRDD[532] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:34 INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks resource profile 0
21/11/26 20:02:34 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 149) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 102639 bytes) taskResourceAssignments Map()
21/11/26 20:02:34 INFO Executor: Running task 0.0 in stage 93.0 (TID 149)
21/11/26 20:02:34 INFO PythonRunner: Times: total = 2, boot = -375, init = 376, finish = 1
21/11/26 20:02:34 INFO Executor: Finished task 0.0 in stage 93.0 (TID 149). 34740 bytes result sent to driver
21/11/26 20:02:34 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 150) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79986 bytes) taskResourceAssignments Map()
21/11/26 20:02:34 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 149) in 109 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:34 INFO Executor: Running task 1.0 in stage 93.0 (TID 150)
21/11/26 20:02:34 INFO PythonRunner: Times: total = 2, boot = -96, init = 97, finish = 1
21/11/26 20:02:34 INFO Executor: Finished task 1.0 in stage 93.0 (TID 150). 20554 bytes result sent to driver
21/11/26 20:02:34 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 150) in 88 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:34 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
21/11/26 20:02:34 INFO DAGScheduler: ResultStage 93 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.205 s
21/11/26 20:02:34 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
21/11/26 20:02:34 INFO DAGScheduler: Job 81 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.208667 s
21/11/26 20:02:35 INFO JobScheduler: Added jobs for time 1637937155000 ms
21/11/26 20:02:36 INFO JobScheduler: Added jobs for time 1637937156000 ms
21/11/26 20:02:37 INFO JobScheduler: Added jobs for time 1637937157000 ms
21/11/26 20:02:38 INFO MemoryStore: Block input-0-1637937157800 stored as values in memory (estimated size 157.0 KiB, free 362.7 MiB)
21/11/26 20:02:38 INFO BlockManagerInfo: Added input-0-1637937157800 in memory on pes2ug19cs012:38829 (size: 157.0 KiB, free: 362.9 MiB)
21/11/26 20:02:38 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/11/26 20:02:38 WARN BlockManager: Block input-0-1637937157800 replicated to only 0 peer(s) instead of 1 peers
21/11/26 20:02:38 INFO BlockGenerator: Pushed block input-0-1637937157800
21/11/26 20:02:38 INFO JobScheduler: Added jobs for time 1637937158000 ms
21/11/26 20:02:39 INFO JobScheduler: Added jobs for time 1637937159000 ms
21/11/26 20:02:39 INFO CodeGenerator: Code generated in 21.101978 ms
21/11/26 20:02:39 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:39 INFO DAGScheduler: Got job 82 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:39 INFO DAGScheduler: Final stage: ResultStage 94 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:39 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:39 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:39 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[544] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:39 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 57.2 KiB, free 362.7 MiB)
21/11/26 20:02:39 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 362.6 MiB)
21/11/26 20:02:39 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on pes2ug19cs012:38829 (size: 22.9 KiB, free: 362.9 MiB)
21/11/26 20:02:39 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 94 (MapPartitionsRDD[544] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:39 INFO TaskSchedulerImpl: Adding task set 94.0 with 2 tasks resource profile 0
21/11/26 20:02:39 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 151) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 102639 bytes) taskResourceAssignments Map()
21/11/26 20:02:39 INFO Executor: Running task 0.0 in stage 94.0 (TID 151)
21/11/26 20:02:39 INFO BlockManagerInfo: Removed broadcast_92_piece0 on pes2ug19cs012:38829 in memory (size: 10.3 KiB, free: 362.9 MiB)
21/11/26 20:02:39 INFO BlockManagerInfo: Removed broadcast_91_piece0 on pes2ug19cs012:38829 in memory (size: 10.0 KiB, free: 362.9 MiB)
21/11/26 20:02:39 INFO BlockManagerInfo: Removed broadcast_93_piece0 on pes2ug19cs012:38829 in memory (size: 23.8 KiB, free: 362.9 MiB)
21/11/26 20:02:39 INFO PythonRunner: Times: total = 4, boot = -4513, init = 4516, finish = 1
21/11/26 20:02:39 INFO Executor: Finished task 0.0 in stage 94.0 (TID 151). 2205 bytes result sent to driver
21/11/26 20:02:39 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 152) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79986 bytes) taskResourceAssignments Map()
21/11/26 20:02:39 INFO Executor: Running task 1.0 in stage 94.0 (TID 152)
21/11/26 20:02:39 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 151) in 155 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:39 INFO PythonRunner: Times: total = 47, boot = -141, init = 143, finish = 45
21/11/26 20:02:39 INFO Executor: Finished task 1.0 in stage 94.0 (TID 152). 2162 bytes result sent to driver
21/11/26 20:02:39 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 152) in 126 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:39 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
21/11/26 20:02:39 INFO DAGScheduler: ResultStage 94 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.291 s
21/11/26 20:02:39 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
21/11/26 20:02:39 INFO DAGScheduler: Job 82 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.295381 s
21/11/26 20:02:39 INFO CodeGenerator: Code generated in 41.611713 ms
21/11/26 20:02:39 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/11/26 20:02:39 INFO DAGScheduler: Got job 83 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/11/26 20:02:39 INFO DAGScheduler: Final stage: ResultStage 95 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/11/26 20:02:39 INFO DAGScheduler: Parents of final stage: List()
21/11/26 20:02:39 INFO DAGScheduler: Missing parents: List()
21/11/26 20:02:39 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[546] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/11/26 20:02:39 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 63.0 KiB, free 362.7 MiB)
21/11/26 20:02:39 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 362.7 MiB)
21/11/26 20:02:39 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on pes2ug19cs012:38829 (size: 23.8 KiB, free: 362.9 MiB)
21/11/26 20:02:39 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1388
21/11/26 20:02:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 95 (MapPartitionsRDD[546] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/11/26 20:02:39 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
21/11/26 20:02:39 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 153) (pes2ug19cs012, executor driver, partition 0, PROCESS_LOCAL, 102639 bytes) taskResourceAssignments Map()
21/11/26 20:02:39 INFO Executor: Running task 0.0 in stage 95.0 (TID 153)
21/11/26 20:02:39 INFO PythonRunner: Times: total = 3, boot = -232, init = 235, finish = 0
21/11/26 20:02:39 INFO Executor: Finished task 0.0 in stage 95.0 (TID 153). 7337 bytes result sent to driver
21/11/26 20:02:39 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 154) (pes2ug19cs012, executor driver, partition 1, PROCESS_LOCAL, 79986 bytes) taskResourceAssignments Map()
21/11/26 20:02:39 INFO Executor: Running task 1.0 in stage 95.0 (TID 154)
21/11/26 20:02:39 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 153) in 148 ms on pes2ug19cs012 (executor driver) (1/2)
21/11/26 20:02:39 INFO PythonRunner: Times: total = 3, boot = -127, init = 130, finish = 0
21/11/26 20:02:39 INFO Executor: Finished task 1.0 in stage 95.0 (TID 154). 11546 bytes result sent to driver
21/11/26 20:02:39 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 154) in 117 ms on pes2ug19cs012 (executor driver) (2/2)
21/11/26 20:02:39 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
21/11/26 20:02:39 INFO DAGScheduler: ResultStage 95 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.283 s
21/11/26 20:02:39 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/26 20:02:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished
21/11/26 20:02:39 INFO DAGScheduler: Job 83 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.286015 s
21/11/26 20:02:40 INFO JobScheduler: Added jobs for time 1637937160000 ms
21/11/26 20:02:40 INFO TaskSchedulerImpl: Cancelling stage 0
21/11/26 20:02:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled
21/11/26 20:02:40 INFO StreamingContext: Invoking stop(stopGracefully=false) from shutdown hook
21/11/26 20:02:40 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled
21/11/26 20:02:40 INFO TaskSchedulerImpl: Stage 0 was cancelled
21/11/26 20:02:40 INFO DAGScheduler: ResultStage 0 (start at NativeMethodAccessorImpl.java:0) failed in 154.542 s due to Job 0 cancelled as part of cancellation of all jobs
21/11/26 20:02:40 INFO ReceiverTracker: Sent stop signal to all 1 receivers
21/11/26 20:02:40 INFO ReceiverSupervisorImpl: Received stop signal
21/11/26 20:02:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Stopped by driver: 
21/11/26 20:02:40 INFO SocketReceiver: Closed socket to localhost:6100
21/11/26 20:02:40 INFO ReceiverSupervisorImpl: Called receiver onStop
21/11/26 20:02:40 INFO ReceiverTracker: All of the receivers have deregistered successfully
21/11/26 20:02:40 INFO ReceiverTracker: ReceiverTracker stopped
21/11/26 20:02:40 WARN ReceiverTracker: Receiver 0 exited but didn't deregister
21/11/26 20:02:40 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/11/26 20:02:40 ERROR ReceiverSupervisorImpl: Error stopping receiver 0 org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
	at org.apache.spark.streaming.receiver.ReceiverSupervisorImpl.onReceiverStop(ReceiverSupervisorImpl.scala:199)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:172)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisorImpl$$anon$1$$anonfun$receive$1.applyOrElse(ReceiverSupervisorImpl.scala:82)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Could not find ReceiverTracker.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:102)
	... 13 more

21/11/26 20:02:40 WARN SocketReceiver: Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.run(SocketInputDStream.scala:72)
21/11/26 20:02:40 INFO JobGenerator: Stopping JobGenerator immediately
21/11/26 20:02:40 INFO BlockGenerator: Stopping BlockGenerator
21/11/26 20:02:40 INFO RecurringTimer: Stopped timer for JobGenerator after time 1637937160000
21/11/26 20:02:40 INFO JobGenerator: Stopped JobGenerator
21/11/26 20:02:40 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.run(SocketInputDStream.scala:72)
21/11/26 20:02:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error receiving data: java.net.SocketException: Socket closed
21/11/26 20:02:40 WARN ReceiverSupervisorImpl: Receiver has been stopped
21/11/26 20:02:40 INFO JobScheduler: Finished job streaming job 1637937064000 ms.0 from job set of time 1637937064000 ms
21/11/26 20:02:40 INFO JobScheduler: Starting job streaming job 1637937065000 ms.0 from job set of time 1637937065000 ms
21/11/26 20:02:40 INFO JobScheduler: Finished job streaming job 1637937065000 ms.0 from job set of time 1637937065000 ms
21/11/26 20:02:40 INFO JobScheduler: Starting job streaming job 1637937066000 ms.0 from job set of time 1637937066000 ms
21/11/26 20:02:40 INFO JobScheduler: Finished job streaming job 1637937066000 ms.0 from job set of time 1637937066000 ms
21/11/26 20:02:40 INFO JobScheduler: Starting job streaming job 1637937067000 ms.0 from job set of time 1637937067000 ms
21/11/26 20:02:40 INFO JobScheduler: Finished job streaming job 1637937067000 ms.0 from job set of time 1637937067000 ms
21/11/26 20:02:40 INFO JobScheduler: Starting job streaming job 1637937068000 ms.0 from job set of time 1637937068000 ms
21/11/26 20:02:40 INFO JobScheduler: Finished job streaming job 1637937068000 ms.0 from job set of time 1637937068000 ms
21/11/26 20:02:40 INFO JobScheduler: Starting job streaming job 1637937069000 ms.0 from job set of time 1637937069000 ms
21/11/26 20:02:40 INFO JobScheduler: Finished job streaming job 1637937069000 ms.0 from job set of time 1637937069000 ms
21/11/26 20:02:40 INFO JobScheduler: Stopped JobScheduler
21/11/26 20:02:40 INFO SparkUI: Stopped Spark web UI at http://pes2ug19cs012:4040
21/11/26 20:02:40 INFO StreamingContext: StreamingContext stopped successfully
21/11/26 20:02:40 INFO DiskBlockManager: Shutdown hook called
21/11/26 20:02:40 INFO ShutdownHookManager: Shutdown hook called
21/11/26 20:02:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-55d83088-e49d-4cf3-a492-68b470eabae5
21/11/26 20:02:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-7c81def3-edcf-4ddb-9608-a17fc9dc0f96
21/11/26 20:02:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/11/26 20:02:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-7c81def3-edcf-4ddb-9608-a17fc9dc0f96/userFiles-42f42271-0c70-41de-b971-4f4620957332
21/11/26 20:02:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-7c81def3-edcf-4ddb-9608-a17fc9dc0f96/pyspark-108ea011-8f71-4bfc-8f33-75c31f15d396
21/11/26 20:02:40 INFO MemoryStore: MemoryStore cleared
21/11/26 20:02:40 INFO BlockManager: BlockManager stopped
21/11/26 20:02:40 INFO BlockManagerMaster: BlockManagerMaster stopped
21/11/26 20:02:41 INFO RecurringTimer: Stopped timer for BlockGenerator after time 1637937161000
21/11/26 20:02:41 INFO BlockGenerator: Waiting for block pushing thread to terminate
21/11/26 20:02:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/11/26 20:02:41 INFO BlockGenerator: Pushing out the last 0 blocks
21/11/26 20:02:41 INFO BlockGenerator: Stopped block pushing thread
21/11/26 20:02:41 INFO BlockGenerator: Stopped BlockGenerator
Exception in thread "receiver-supervisor-future-0" java.lang.Error: java.lang.InterruptedException: sleep interrupted
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:196)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	... 2 more
21/11/26 20:02:41 INFO ReceiverSupervisorImpl: Stopped receiver without error
21/11/26 20:02:41 ERROR TaskContextImpl: Error in TaskCompletionListener
java.lang.IllegalStateException: Block broadcast_0 not found
	at org.apache.spark.storage.BlockInfoManager.$anonfun$unlock$3(BlockInfoManager.scala:293)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:293)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1196)
	at org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:287)
	at org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:287)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:125)
	at org.apache.spark.TaskContextImpl.$anonfun$markTaskCompleted$1(TaskContextImpl.scala:124)
	at org.apache.spark.TaskContextImpl.$anonfun$markTaskCompleted$1$adapted(TaskContextImpl.scala:124)
	at org.apache.spark.TaskContextImpl.$anonfun$invokeListeners$1(TaskContextImpl.scala:137)
	at org.apache.spark.TaskContextImpl.$anonfun$invokeListeners$1$adapted(TaskContextImpl.scala:135)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:135)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:124)
	at org.apache.spark.scheduler.Task.run(Task.scala:147)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/11/26 20:02:41 INFO SparkContext: Successfully stopped SparkContext
